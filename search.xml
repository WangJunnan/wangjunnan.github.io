<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Sentinel源码解析二（slot总览）]]></title>
    <url>%2F2019%2F10%2F16%2FSentinel%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BA%8C%EF%BC%88slot%E6%80%BB%E8%A7%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[写在前面本文继续来分析Sentinel的源码，上篇文章对Sentinel的调用过程做了深入分析，主要涉及到了两个概念：插槽链和Node节点。那么接下来我们就根据插槽链的调用关系来依次分析每个插槽（slot）的源码。 默认插槽链的调用顺序，以及每种类型Node节点的关系都在上面文章开头分析过 NodeSelectorSlot123456789101112131415161718192021222324252627282930/** * 相同的资源但是Context不同，分别新建 DefaultNode，并以ContextName为key */private volatile Map&lt;String, DefaultNode&gt; map = new HashMap&lt;String, DefaultNode&gt;(10);public void entry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable &#123; // 根据ContextName尝试获取DefaultNode DefaultNode node = map.get(context.getName()); if (node == null) &#123; synchronized (this) &#123; node = map.get(context.getName()); if (node == null) &#123; // 初始化DefaultNode，每个Context对应一个 node = new DefaultNode(resourceWrapper, null); HashMap&lt;String, DefaultNode&gt; cacheMap = new HashMap&lt;String, DefaultNode&gt;(map.size()); cacheMap.putAll(map); cacheMap.put(context.getName(), node); map = cacheMap; &#125; // 构建 Node tree ((DefaultNode)context.getLastNode()).addChild(node); &#125; &#125; context.setCurNode(node); // 唤醒执行下一个插槽 fireEntry(context, resourceWrapper, node, count, prioritized, args);&#125; NodeSelectorSlot顾名思义是用来构建Node的。我们可以看到NodeSelectorSlot对于不同的上下文都会生成一个DefaultNode。这里还有一个要注意的点：相同的资源({@link ResourceWrapper#equals(Object)})将全局共享相同的{@link ProcessorSlotChain}，无论在哪个上下文中，因此不同的上下文可以进入到同一个对象的NodeSelectorSlot.entry方法中，那么这里要怎么区分不同的上下文所创建的资源Node呢？显然可以使用上下文名称作为映射键以区分相同的资源Node。 然后这里要考虑另一个问题。一个资源有可能创建多个DefaultNode（有多个上下文时），那么我们应该如何快速的获取总的统计数据呢？ 答案就在下一个Slot(ClusterBuilderSlot)中被解决了。 ClusterBuilderSlot上面有提到一个问题，我们要如何统计不同上下文相同资源的总量数据。ClusterBuilderSlot给了很好的解决方案：具有相同资源名称的共享一个ClusterNode。 1234567891011121314151617181920212223242526272829303132333435363738// 相同的资源共享一个 ClusterNodeprivate static volatile Map&lt;ResourceWrapper, ClusterNode&gt; clusterNodeMap = new HashMap&lt;&gt;();private static final Object lock = new Object();private volatile ClusterNode clusterNode = null;@Overridepublic void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // 判断本资源是否已经初始化过clusterNode if (clusterNode == null) &#123; synchronized (lock) &#123; if (clusterNode == null) &#123; // 没有初始化则初始化clusterNode clusterNode = new ClusterNode(resourceWrapper.getName(), resourceWrapper.getResourceType()); HashMap&lt;ResourceWrapper, ClusterNode&gt; newMap = new HashMap&lt;&gt;(Math.max(clusterNodeMap.size(), 16)); newMap.putAll(clusterNodeMap); newMap.put(node.getId(), clusterNode); clusterNodeMap = newMap; &#125; &#125; &#125; // 给相同资源的DefaultNode设置一样的ClusterNode node.setClusterNode(clusterNode); /* * 如果有来源则新建一个来源Node */ if (!"".equals(context.getOrigin())) &#123; Node originNode = node.getClusterNode().getOrCreateOriginNode(context.getOrigin()); context.getCurEntry().setOriginNode(originNode); &#125; fireEntry(context, resourceWrapper, node, count, prioritized, args);&#125; 上面的代码其实就是做了一件事情，为资源创建CluserNode。这里我又要提一嘴 相同的资源({@link ResourceWrapper#equals(Object)})将全局共享相同的{@link ProcessorSlotChain}，无论在哪个上下文中。也就是说，能进入到同一个ClusterBuilderSlot对象的entry方法的请求都是来自同一个资源的，所以这些相同资源需要初始化一个统一的CluserNode用来做流量的汇总统计。 LogSlot代码比较简单，逻辑就是打印异常日志，就不分析了 StatisticSlotStatisticSlot 是 Sentinel 的核心功能插槽之一，用于统计实时的调用数据。 12345678910111213141516171819202122232425public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; try &#123; // 先进行后续的check，包括规则的check，黑白名单check fireEntry(context, resourceWrapper, node, count, prioritized, args); // 统计默认qps 线程数 node.increaseThreadNum(); node.addPassRequest(count); if (context.getCurEntry().getOriginNode() != null) &#123; // 根据来源统计qps 线程数 context.getCurEntry().getOriginNode().increaseThreadNum(); context.getCurEntry().getOriginNode().addPassRequest(count); &#125; if (resourceWrapper.getEntryType() == EntryType.IN) &#123; // 统计入口 qps 线程数 Constants.ENTRY_NODE.increaseThreadNum(); Constants.ENTRY_NODE.addPassRequest(count); &#125; .... 省略其他代码 &#125;&#125; StatisticSlot主要做了4种不同维度的流量统计 资源在上下文维度（DefaultNode）的统计 clusterNode 维度的统计 Origin 来源维度的统计 入口全局流量的统计 关于流量的统计原理的本文就不深入分析了，接下来的文章中会单独分析 SystemSlotSystemSlot比较简单，其实就是根据StatisticSlot所统计的全局入口流量进行限流。 AuthoritySlot123456789101112131415161718192021222324public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; checkBlackWhiteAuthority(resourceWrapper, context); fireEntry(context, resourceWrapper, node, count, prioritized, args);&#125;void checkBlackWhiteAuthority(ResourceWrapper resource, Context context) throws AuthorityException &#123; Map&lt;String, Set&lt;AuthorityRule&gt;&gt; authorityRules = AuthorityRuleManager.getAuthorityRules(); if (authorityRules == null) &#123; return; &#125; // 根据资源获取黑白名单规则 Set&lt;AuthorityRule&gt; rules = authorityRules.get(resource.getName()); if (rules == null) &#123; return; &#125; // 对规则进行校验，只要有一条不通过 就抛异常 for (AuthorityRule rule : rules) &#123; if (!AuthorityRuleChecker.passCheck(rule, context)) &#123; throw new AuthorityException(context.getOrigin(), rule); &#125; &#125;&#125; AuthoritySlot会对资源的黑白名单做检查，并且只要有一条不通过就抛异常。 FlowSlot12345678910111213@Overridepublic void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; checkFlow(resourceWrapper, context, node, count, prioritized); fireEntry(context, resourceWrapper, node, count, prioritized, args);&#125;void checkFlow(ResourceWrapper resource, Context context, DefaultNode node, int count, boolean prioritized) throws BlockException &#123; // 检查限流规则 checker.checkFlow(ruleProvider, resource, context, node, count, prioritized);&#125; 这个slot主要根据预设的资源的统计信息，按照固定的次序，依次生效。如果一个资源对应两条或者多条流控规则，则会根据如下次序依次检验，直到全部通过或者有一个规则生效为止:并且同样也会根据三种不同的维度来进行限流： 资源在上下文维度（DefaultNode）的统计 clusterNode 维度的统计 Origin 来源维度的统计 关于流控规则源码的深入分析就不在本篇文章赘述了 DegradeSlot这个slot主要针对资源的平均响应时间（RT）以及异常比率，来决定资源是否在接下来的时间被自动熔断掉。 总结 相同的资源({@link ResourceWrapper#equals(Object)})将全局共享相同的{@link ProcessorSlotChain}，无论在哪个上下文中 流控有多个维度，分别包括：1.不同上下文中的资源 2.相同资源 3.入口流量 3.相同的来源]]></content>
      <categories>
        <category>java框架</category>
        <category>Sentinel</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>Sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sentinel源码解析一]]></title>
    <url>%2F2019%2F10%2F11%2FSentinel%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%80%2F</url>
    <content type="text"><![CDATA[引言Sentinel作为ali开源的一款轻量级流控框架，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。相比于Hystrix，Sentinel的设计更加简单，在 Sentinel中资源定义和规则配置是分离的，也就是说用户可以先通过Sentinel API给对应的业务逻辑定义资源（埋点），然后在需要的时候再配置规则，通过这种组合方式，极大的增加了Sentinel流控的灵活性。 引入Sentinel带来的性能损耗非常小。只有在业务单机量级超过25W QPS的时候才会有一些显著的影响（5% - 10% 左右），单机QPS不太大的时候损耗几乎可以忽略不计。 Sentinel提供两种埋点方式: try-catch 方式（通过 SphU.entry(...)），用户在 catch 块中执行异常处理 / fallback if-else 方式（通过 SphO.entry(...)），当返回 false 时执行异常处理 / fallback 写在前面在此之前，需要先了解一下Sentinel的工作流程在 Sentinel 里面，所有的资源都对应一个资源名称（resourceName），每次资源调用都会创建一个 Entry 对象。Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 SphU API 显式创建。Entry 创建的时候，同时也会创建一系列功能插槽（slot chain），这些插槽有不同的职责，例如默认情况下会创建一下7个插槽： NodeSelectorSlot 负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级； ClusterBuilderSlot 则用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据； StatisticSlot 则用于记录、统计不同纬度的 runtime 指标监控信息； FlowSlot 则用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制； AuthoritySlot 则根据配置的黑白名单和调用来源信息，来做黑白名单控制； DegradeSlot 则通过统计信息以及预设的规则，来做熔断降级； SystemSlot 则通过系统的状态，例如 load1 等，来控制总的入口流量 注意：这里的插槽链都是一一对应资源名称的 上面的所介绍的插槽（slot chain）是Sentinel非常重要的概念。同时还有一个非常重要的概念那就是Node，为了帮助理解，尽我所能画了下面这张图，可以看到整个结构非常的像一棵树： 简单解释下上图： 顶部蓝色的node节点为根节点，全局唯一 下面黄色的节点为入口节点，每个CentextName(上下文名称)一一对应一个 可以有多个子节点（对应多种资源） 中间绿色框框中的节点都是属于同一个资源的(相同的ResourceName) 最底下紫色的节点是集群节点，可以理解成绿色框框中Node资源的整合 以上2个概念务必要理清楚，之后再一步一步看源码会比较清晰 下面我们将从入口源码开始一步一步分析整个调用过程： 源码分析下面的是一个Sentinel使用的示例代码，我们就从这里切入开始分析 123456789// 创建一个名称为entrance1，来源为appA 的上下文ContextContextUtil.enter("entrance1", "appA");// 创建一个资源名称nodeA的Entry Entry nodeA = SphU.entry("nodeA"); if (nodeA != null) &#123; nodeA.exit(); &#125; // 清除上下文 ContextUtil.exit(); ContextUtil.enter(“entrance1”, “appA”)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public static Context enter(String name, String origin) &#123; // 判断上下文名称是否为默认的名称（sentinel_default_context） 是的话直接抛出异常 if (Constants.CONTEXT_DEFAULT_NAME.equals(name)) &#123; throw new ContextNameDefineException( "The " + Constants.CONTEXT_DEFAULT_NAME + " can't be permit to defined!"); &#125; return trueEnter(name, origin);&#125;protected static Context trueEnter(String name, String origin) &#123; // 先从ThreadLocal中尝试获取，获取到则直接返回 Context context = contextHolder.get(); if (context == null) &#123; Map&lt;String, DefaultNode&gt; localCacheNameMap = contextNameNodeMap; // 尝试从缓存中获取该上下文名称对应的 入口节点 DefaultNode node = localCacheNameMap.get(name); if (node == null) &#123; // 判断缓存中入口节点数量是否大于2000 if (localCacheNameMap.size() &gt; Constants.MAX_CONTEXT_NAME_SIZE) &#123; setNullContext(); return NULL_CONTEXT; &#125; else &#123; try &#123; // 加锁 LOCK.lock(); // 双重检查锁 node = contextNameNodeMap.get(name); if (node == null) &#123; // 判断缓存中入口节点数量是否大于2000 if (contextNameNodeMap.size() &gt; Constants.MAX_CONTEXT_NAME_SIZE) &#123; setNullContext(); return NULL_CONTEXT; &#125; else &#123; // 根据上下文名称生成入口节点（entranceNode） node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null); // 加入至全局根节点下 Constants.ROOT.addChild(node); // 加入缓存中 Map&lt;String, DefaultNode&gt; newMap = new HashMap&lt;&gt;(contextNameNodeMap.size() + 1); newMap.putAll(contextNameNodeMap); newMap.put(name, node); contextNameNodeMap = newMap; &#125; &#125; &#125; finally &#123; LOCK.unlock(); &#125; &#125; &#125; // 初始化上下文对象 context = new Context(node, name); context.setOrigin(origin); // 设置到当前线程中 contextHolder.set(context); &#125; return context;&#125; 主要做了2件事情 根据ContextName生成entranceNode，并加入缓存，每个ContextName对应一个入口节点entranceNode 根据ContextName和entranceNode初始化上下文对象，并将上下文对象设置到当前线程中 这里有几点需要注意： 入口节点数量不能大于2000，大于会直接抛异常 每个ContextName对应一个入口节点entranceNode 每个entranceNode都有共同的父节点。也就是根节点 Entry nodeA = SphU.entry(“nodeA”)123456789101112131415// SphU.classpublic static Entry entry(String name) throws BlockException &#123; // 默认为 出口流量类型，单位统计数为1 return Env.sph.entry(name, EntryType.OUT, 1, OBJECTS0);&#125;// CtSph.classpublic Entry entry(String name, EntryType type, int count, Object... args) throws BlockException &#123; // 生成资源对象 StringResourceWrapper resource = new StringResourceWrapper(name, type); return entry(resource, count, args);&#125;public Entry entry(ResourceWrapper resourceWrapper, int count, Object... args) throws BlockException &#123; return entryWithPriority(resourceWrapper, count, false, args);&#125; 上面的代码比较简单，不指定EntryType的话，则默认为出口流量类型，最终会调用entryWithPriority方法，主要业务逻辑也都在这个方法中 entryWithPriority方法 123456789101112131415161718192021222324252627282930313233343536373839404142private Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args) throws BlockException &#123; // 获取当前线程上下文对象 Context context = ContextUtil.getContext(); // 上下文名称对应的入口节点是否已经超过阈值2000，超过则会返回空 CtEntry if (context instanceof NullContext) &#123; return new CtEntry(resourceWrapper, null, context); &#125; if (context == null) &#123; // 如果没有指定上下文名称，则使用默认名称，也就是默认入口节点 context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME); &#125; // 全局开关 if (!Constants.ON) &#123; return new CtEntry(resourceWrapper, null, context); &#125; // 生成插槽链 ProcessorSlot&lt;Object&gt; chain = lookProcessChain(resourceWrapper); /* * 表示资源(插槽链)超过6000，因此不会进行规则检查。 */ if (chain == null) &#123; return new CtEntry(resourceWrapper, null, context); &#125; // 生成 Entry 对象 Entry e = new CtEntry(resourceWrapper, chain, context); try &#123; // 开始执行插槽链 调用逻辑 chain.entry(context, resourceWrapper, null, count, prioritized, args); &#125; catch (BlockException e1) &#123; // 清除上下文 e.exit(count, args); throw e1; &#125; catch (Throwable e1) &#123; // 除非Sentinel内部存在错误，否则不应发生这种情况。 RecordLog.info("Sentinel unexpected exception", e1); &#125; return e;&#125; 这个方法可以说是涵盖了整个Sentinel的核心逻辑 获取上下文对象，如果上下文对象还未初始化，则使用默认名称初始化。初始化逻辑在上文已经分析过 判断全局开关 根据给定的资源生成插槽链，插槽链是跟资源相关的，Sentinel最关键的逻辑也都在各个插槽中。初始化的逻辑在lookProcessChain(resourceWrapper);中，下文会分析 依顺序执行每个插槽逻辑 lookProcessChain(resourceWrapper)方法lookProcessChain方法为指定资源生成插槽链，下面我们来看下它的初始化逻辑 123456789101112131415161718192021222324ProcessorSlot&lt;Object&gt; lookProcessChain(ResourceWrapper resourceWrapper) &#123; // 根据资源尝试从全局缓存中获取 ProcessorSlotChain chain = chainMap.get(resourceWrapper); if (chain == null) &#123; // 非常常见的双重检查锁 synchronized (LOCK) &#123; chain = chainMap.get(resourceWrapper); if (chain == null) &#123; // 判断资源数是否大于6000 if (chainMap.size() &gt;= Constants.MAX_SLOT_CHAIN_SIZE) &#123; return null; &#125; // 初始化插槽链 chain = SlotChainProvider.newSlotChain(); Map&lt;ResourceWrapper, ProcessorSlotChain&gt; newMap = new HashMap&lt;ResourceWrapper, ProcessorSlotChain&gt;( chainMap.size() + 1); newMap.putAll(chainMap); newMap.put(resourceWrapper, chain); chainMap = newMap; &#125; &#125; &#125; return chain;&#125; 根据资源尝试从全局缓存中获取插槽链。每个资源对应一个插槽链（资源嘴多只能定义6000个） 初始化插槽链上的插槽（SlotChainProvider.newSlotChain()方法中） 下面我们看下初始化插槽链上的插槽的逻辑 SlotChainProvider.newSlotChain()123456789101112131415161718192021222324252627282930313233343536373839public static ProcessorSlotChain newSlotChain() &#123; // 判断是否已经初始化过 if (builder != null) &#123; return builder.build(); &#125; // 加载 SlotChain resolveSlotChainBuilder(); // 加载失败则使用默认 插槽链 if (builder == null) &#123; RecordLog.warn("[SlotChainProvider] Wrong state when resolving slot chain builder, using default"); builder = new DefaultSlotChainBuilder(); &#125; // 构建完成 return builder.build();&#125;/** * java自带 SPI机制 加载 slotChain */private static void resolveSlotChainBuilder() &#123; List&lt;SlotChainBuilder&gt; list = new ArrayList&lt;SlotChainBuilder&gt;(); boolean hasOther = false; // 尝试获取自定义SlotChainBuilder，通过JAVA SPI机制扩展 for (SlotChainBuilder builder : LOADER) &#123; if (builder.getClass() != DefaultSlotChainBuilder.class) &#123; hasOther = true; list.add(builder); &#125; &#125; if (hasOther) &#123; builder = list.get(0); &#125; else &#123; // 未获取到自定义 SlotChainBuilder 则使用默认的 builder = new DefaultSlotChainBuilder(); &#125; RecordLog.info("[SlotChainProvider] Global slot chain builder resolved: " + builder.getClass().getCanonicalName());&#125; 首先会尝试获取自定义的SlotChainBuilder来构建插槽链，自定义的SlotChainBuilder可以通过JAVA SPI机制来扩展 如果未配置自定义的SlotChainBuilder，则会使用默认的DefaultSlotChainBuilder来构建插槽链，DefaultSlotChainBuilder所构建的插槽就是文章开头我们提到的7种Slot。每个插槽都有其对应的职责，各司其职，后面我们会详细分析这几个插槽的源码，及所承担的职责。 总结文章开头的提到的两个点(插槽链和Node)，这是Sentinel的重点，理解这两点对于阅读源码来说事半功倍]]></content>
      <categories>
        <category>java框架</category>
        <category>Sentinel</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>Sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈常用的限流算法]]></title>
    <url>%2F2019%2F10%2F09%2F%E6%B5%85%E8%B0%88%E5%B8%B8%E7%94%A8%E7%9A%84%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流。今天我们要聊的就是限流（Rate Limit），限流的目的很简单，就是为了保护系统不被瞬时大流量冲垮，限流这个概念我其实很早之前就有去了解过，不过无奈之前工作所接触业务的并发量实在是谈不上限流。目前公司大促峰值QPS在2w往上，自然而然需要用到限流，特别是类似秒杀这种瞬时流量非常大但实际成单率低的业务场景。 目前比较常用的限流算法有三种 计数器固定窗口算法 计数器滑动窗口算法 漏桶算法 令牌桶算法 计数器固定窗口算法计数器固定窗口算法是最简单的限流算法，实现方式也比较简单。就是通过维护一个单位时间内的计数值，每当一个请求通过时，就将计数值加1，当计数值超过预先设定的阈值时，就拒绝单位时间内的其他请求。如果单位时间已经结束，则将计数器清零，开启下一轮的计数。 但是这种实现会有一个问题，举个例子: 假设我们设定1秒内允许通过的请求阈值是200，如果有用户在时间窗口的最后几毫秒发送了200个请求，紧接着又在下一个时间窗口开始时发送了200个请求，那么这个用户其实在一秒内成功请求了400次，显然超过了阈值但并不会被限流。其实这就是临界值问题，那么临界值问题要怎么解决呢？ 代码实现 – CounterRateLimit.java 计数器滑动窗口算法计数器滑动窗口法就是为了解决上述固定窗口计数存在的问题而诞生，学过TCP协议的同学应该对滑动窗口不陌生，其实还是不太一样的，下文我们要说的滑动窗口是基于时间来划分窗口的。而TCP的滑动窗口指的是能够接受的字节数，并且大小是可变的（拥塞控制） 滑动窗口是怎么做的？ 前面说了固定窗口存在临界值问题，要解决这种临界值问题，显然只用一个窗口是解决不了问题的。假设我们仍然设定1秒内允许通过的请求是200个，但是在这里我们需要把1秒的时间分成多格，假设分成5格（格数越多，流量过渡越平滑），每格窗口的时间大小是200毫秒，每过200毫秒，就将窗口向前移动一格。为了便于理解，可以看下图 图中将窗口划为5份，每个小窗口中的数字表示在这个窗口中请求数，所以通过观察上图，可知在当前时间快（200毫秒）允许通过的请求数应该是20而不是200（只要超过20就会被限流），因为我们最终统计请求数时是需要把当前窗口的值进行累加，进而得到当前请求数来判断是不是需要进行限流。 那么滑动窗口限流法是完美的吗？细心观察的我们应该能马上发现问题，滑动窗口限流法其实就是计数器固定窗口算法的一个变种。流量的过渡是否平滑依赖于我们设置的窗口格数也就是统计时间间隔，格数越多，统计越精确，但是具体要分多少格我们也说不上来呀… 代码实现 – SlidingWindowRateLimit.java 漏桶算法上面所介绍的两种算法都不能非常平滑的过渡，下面就是漏桶算法登场了什么是漏桶算法？漏桶算法以一个常量限制了出口流量速率，因此漏桶算法可以平滑突发的流量。其中漏桶作为流量容器我们可以看做一个FIFO的队列，当入口流量速率大于出口流量速率时，因为流量容器是有限的，当超出流量容器大小时，超出的流量会被丢弃。下图比较形象的说明了漏桶算法的原理，其中水龙头是入口流量，漏桶是流量容器，匀速流出的水是出口流量。 漏桶算法的特点 漏桶具有固定容量，出口流量速率是固定常量（流出请求） 入口流量可以以任意速率流入到漏桶中（流入请求） 如果入口流量超出了桶的容量，则流入流量会溢出（新请求被拒绝） 代码实现 – LeakyBucketRateLimit.java 不过因为漏桶算法限制了流出速率是一个固定常量值，所以漏桶算法不支持出现突发流出流量。但是在实际情况下，流量往往是突发的。 令牌桶算法令牌桶算法是漏桶算法的改进版，可以支持突发流量。不过与漏桶算法不同的是，令牌桶算法的漏桶中存放的是令牌而不是流量。那么令牌桶算法是怎么突发流量的呢？最开始，令牌桶是空的，我们以恒定速率往令牌桶里加入令牌，令牌桶被装满时，多余的令牌会被丢弃。当请求到来时，会先尝试从令牌桶获取令牌（相当于从令牌桶移除一个令牌），获取成功则请求被放行，获取失败则阻塞活拒绝请求。 令牌桶算法的特点 最多可以存发b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃 请求到来时，如果令牌桶中少于n个令牌，那么不会删除令牌。该请求会被限流（阻塞活拒绝） 算法允许最大b(令牌桶大小)个请求的突发 令牌桶算法限制的是平均流量，因此其允许突发流量（只要令牌桶中有令牌，就不会被限流） 代码实现 – TokenBucketRateLimit.java 总结至此，基本把以上4种限流算法的原理都解释清楚了。每种限流算法都有其固定特点，及各自适用的场景，其中计数器算法是其中最简单的，相当于滑动窗口算法的简化版，令牌桶算法相比漏桶算法对资源的利用率更高（允许突发流量）]]></content>
      <categories>
        <category>算法</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA中时间的表现形式]]></title>
    <url>%2F2019%2F09%2F26%2FJAVA%E4%B8%AD%E6%97%B6%E9%97%B4%E7%9A%84%E8%A1%A8%E7%8E%B0%E5%BD%A2%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引言大多数时候我们在表示时间的概念时，可能并不会去特意关注时区这个概念，毕竟在国内时区都是统一的，我们只需要使用默认时区 北京时间 就可以了。是的，在写这篇文章之前，我也没有过多的去关注时区的概念，以及在JAVA中的表现形式。但是因为目前所在的公司是跨境公司，公司主要业务在印度，印度时间跟北京时间显然是不同的。 时区的概念在这之前先说一下时区的概念，以及解释几个专有名词。时区是地球上的区域使用同一个时间定义，整个全球被分成24个时区。所以每差一个时区，区时相差一个小时，相差多少个时区，就相差多少个小时。东边的时区时间比西边的时区时间早。北京时间指的就是东八区的时间。 UTC时间和本地时间UTC时间又称协调世界时，是最主要的世界时间标准，其以原子时秒长为基础，在时刻上尽量接近于格林尼治标准时间(GMT)。对于大多数用途来说，UTC时间被认为能与GMT时间互换，但GMT时间已不再被科学界所确定。如果时间是以协调世界时（UTC）表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。 UTC偏移量和本地时间例如北京时间的UTC偏移量是 +8，则当UTC时间是 2:00 时，北京时间的 10:00。所以借助于UTC时间，我们可以把全球的时间都统一起来。 时间戳时区可以很好的表示各地的时间，但各个时区的字面时间显示仍然还是不同的，所以我们需要一种方式在来让世界各个角落的时间都有一样的表现形式。这引申出了时间戳，也被称为Unix时间(Unix time)，定义为从格林威治时间1970年01月01日00时00分00秒起至现在的总秒数。 Java8中的时间类型在JAVA8中，提供了新的时间日期操作类，相对于之前的 Date 类，可以说使用起来方便了许多，下面依次来介绍几个关键类。 Instant 用来表示时间戳 LocalDateTime 单纯表示字面时间，不带时区信息。也就是说 LocalDateTime = 2019-09-25 00:00:00，这个时间我们并不知道是北京时间还是东京时间，仅仅用作字面时间 ZonedDateTime 含有时区信息的时间，类似于北京时间，UTC+8 它们如何表示时间12345678System.out.println(LocalDateTime.now());System.out.println(Instant.now());System.out.println(ZonedDateTime.now());输出2019-09-26T14:50:43.7412019-09-26T06:50:43.742Z2019-09-26T14:50:43.803+08:00[Asia/Shanghai] 可以看到LocalDateTime 会根据UTC时间获取到本地时间显示，但是会把时区信息丢弃Instant 则直接表示的UTC世界标准时间ZonedDateTime 会根据UTC时间获取到本地时间显示，同时也会显示当前的时区信息 其实ZonedDateTime 是由 Instant 加上时区信息结合而来，通过ZonedDateTime可以直接获取到Instant时间戳信息 如何转换转换的核心其实都是往时间戳（世界标准时间）靠拢，试想是不是这样？只有转成了标准时间才能转成其他时区的时间 ZonedDateTime Instant 1234567// zonedDateTime -&gt; instantZonedDateTime zonedDateTime = ZonedDateTime.now();Instant instant = zonedDateTime.toInstant();// instant -&gt; zonedDateTime 要指定时区信息ZoneId DEFAULT_ZONE_ID = ZoneId.of("Asia/Shanghai");zonedDateTime = instant.atZone(DEFAULT_ZONE_ID); LocalDateTime Instant 12345678// LocalDateTime -&gt; InstantLocalDateTime localDateTime = LocalDateTime.now();Instant instant = localDateTime.toInstant(ZoneOffset.of("+08:00"));// Instant -&gt; ZonedDateTime -&gt; LocalDateTime// Instant 需要先转换成 ZonedDateTime 再转换成本地时间ZonedDateTime zonedDateTime = instant.atZone(ZoneId.of("Asia/Shanghai"));localDateTime = zonedDateTime.toLocalDateTime(); LocalDateTime ZonedDateTime 123456// LocalDateTime -&gt; ZonedDateTime 需要指定本地所在时区LocalDateTime localDateTime = LocalDateTime.now();ZonedDateTime zonedDateTime = localDateTime.atZone(ZoneId.of("Asia/Shanghai"));// 直接转换成本地时间localDateTime = zonedDateTime.toLocalDateTime(); 可以看到，在转换过程中，会频繁的手动指定时区，主要原因是LocalDateTime并不带有时区信息，如果我们要转换成标准时间，就需要手动指定时区。所以为了避免转换过程中的错误，我们应该尽量使用时间戳来来传输时间。 与其他api的转换 Timestamp LocalDateTime 123456789// Timestamp -&gt; LocalDateTimeTimestamp timestamp = Timestamp.from(Instant.now());LocalDateTime localDateTime = timestamp.toLocalDateTime();// LocalDateTime -&gt; Timestamp 有两种方式// 1. 直接按本地默认时区转时区timestamp = Timestamp.valueOf(localDateTime);// 2. 指定时区转timestamp = Timestamp.from(localDateTime.toInstant(ZoneOffset.of(&quot;+08:00&quot;))); Date LocalDateTime 123456// Date -&gt; LocalDateTimeDate date = new Date();LocalDateTime localDateTime = date.toInstant().atZone(ZoneId.of("Asia/Shanghai")).toLocalDateTime();// LocalDateTime -&gt; Datedate = Date.from(localDateTime.toInstant(ZoneOffset.of("+08:00"))); 更多例子DateTimeUtils.java 总结最后还是建议操作时间时使用时间戳，这样子没有时区的概念，也就不会产生歧义。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的@Configuration @Bean注解]]></title>
    <url>%2F2019%2F09%2F03%2FSpring%E7%9A%84-Configuration-Bean%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[引言之前Spring 一直用的xml配置文件比较多，现在发现新公司用的注解比较多。也就是通过定义一个配置类(以@Configuration注解的类)内部在方法上注解 @Bean 注解来完成Bean的依赖注入Spring容器。用注解来配置的话，其实就是减少了配置文件的工作，但总体来说代码可读性其实是会下降的。不过也省去了一大堆的xml配置文件 直接看源码下面就从源码层面来看看 通过注解配置有什么不同 之前有分析过Spring对Bean的解析，是通过把我们配置的Bean信息抽象成了一个BeanDefiniion对象。这个对象持有了我们配置的Bean的元数据 那么其实 @Bean 的注解的原理也是类似，也是通过将我们配置的Bean信息抽象成一个BeanDefiniion对象 这里我们分两种情况讨论，一种是 Spring 通过 xml文件配置实现注解配置，一种就是我们现在非常流行的 SpringBoot实现的注解配置。其实两者实现原理一致，只是配置入口略有不同。 先看 普通 Spring 应用的配置: 如果我们要在 普通 Spring 应用中实现注解配置。那么我们需要在Spring的配置文件中配置以下几个配置 1234&lt;context:annotation-config&gt;&lt;context:component-scan&gt; 这两个配置的意思是什么呢？ 我们直接看Spring是如何解析这两个标签的吧，通过在META-INF/spring.handlers目录下根据spring.handlers文件可以找到 Context 标签 解析入口类 ContextNamespaceHandler 1234567891011121314151617181920212223242526public class ContextNamespaceHandler extends NamespaceHandlerSupport &#123;@Overridepublic void init() &#123;registerBeanDefinitionParser("property-placeholder", new PropertyPlaceholderBeanDefinitionParser());registerBeanDefinitionParser("property-override", new PropertyOverrideBeanDefinitionParser());registerBeanDefinitionParser("annotation-config", new AnnotationConfigBeanDefinitionParser());registerBeanDefinitionParser("component-scan", new ComponentScanBeanDefinitionParser());registerBeanDefinitionParser("load-time-weaver", new LoadTimeWeaverBeanDefinitionParser());registerBeanDefinitionParser("spring-configured", new SpringConfiguredBeanDefinitionParser());registerBeanDefinitionParser("mbean-export", new MBeanExportBeanDefinitionParser());registerBeanDefinitionParser("mbean-server", new MBeanServerBeanDefinitionParser());&#125;&#125; 看了上面的解析源码，可以知道annotation-config由AnnotationConfigBeanDefinitionParser解析。component-scan由ComponentScanBeanDefinitionParser解析。这里就是Spring XML 注解配置的入口，下面我们来依次分析这两个解析类干了什么事情？ ComponentScanBeanDefinitionParser 1234567891011121314151617181920212223242526public BeanDefinition parse(Element element, ParserContext parserContext) &#123;String basePackage = element.getAttribute(BASE_PACKAGE_ATTRIBUTE);basePackage = parserContext.getReaderContext().getEnvironment().resolvePlaceholders(basePackage);String[] basePackages = StringUtils.tokenizeToStringArray(basePackage,ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS);// Actually scan for bean definitions and register them.ClassPathBeanDefinitionScanner scanner = configureScanner(parserContext, element); // 这里扫描了我们配置的 base-package 包下全部 beanDefinitions，并抽象成了 BeanDefinitionHolder类Set&lt;BeanDefinitionHolder&gt; beanDefinitions = scanner.doScan(basePackages); // 将抽象的 beanDefinitions 全部注册进 Spring容器中，注 这里包含了被@Configuration注解的类registerComponents(parserContext.getReaderContext(), beanDefinitions, element);return null;&#125; AnnotationConfigBeanDefinitionParser 主要逻辑在 AnnotationConfigUtils 工具类的 registerAnnotationConfigProcessors方法中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166public BeanDefinition parse(Element element, ParserContext parserContext) &#123;Object source = parserContext.extractSource(element);// 初始化一些 BeanFactoryPostProcessor 进Spring容器，会在getBean之前全部执行。 // 一般用来在容器实例化Bean前，对BeanDefinition做修改，或添加新的BeanDefinition等前置修改 // 主要逻辑就在这里Set&lt;BeanDefinitionHolder&gt; processorDefinitions =AnnotationConfigUtils.registerAnnotationConfigProcessors(parserContext.getRegistry(), source);// Register component for the surrounding &lt;context:annotation-config&gt; element.CompositeComponentDefinition compDefinition = new CompositeComponentDefinition(element.getTagName(), source);parserContext.pushContainingComponent(compDefinition);// Nest the concrete beans in the surrounding component.for (BeanDefinitionHolder processorDefinition : processorDefinitions) &#123;parserContext.registerComponent(new BeanComponentDefinition(processorDefinition));&#125;// Finally register the composite component.parserContext.popAndRegisterContainingComponent();return null;&#125;// AnnotationConfigUtils.class// 添加支持 annotation-config 配置的一些BeanFactoryPostProcessor 实现类public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors(BeanDefinitionRegistry registry, @Nullable Object source) &#123;DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry);if (beanFactory != null) &#123;if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123;beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE);&#125;if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123;beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver());&#125;&#125;Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8);// @Configuration 注解解析if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class);def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME));&#125; // @Autowired 注解解析if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class);def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME));&#125;// @Required 注解解析if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class);def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME));&#125;// Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. // 对 JSR-250做支持 解析注解 @Resource @PostConstruct @PreDestroy if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class);def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME));&#125;// Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor.if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition();try &#123;def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME,AnnotationConfigUtils.class.getClassLoader()));&#125;catch (ClassNotFoundException ex) &#123;throw new IllegalStateException("Cannot load optional framework class: " + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex);&#125;def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME));&#125;if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class);def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME));&#125;if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123;RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class);def.setSource(source);beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME));&#125;return beanDefs;&#125; 可以看到 annotation-config 配置其实就是添加了几个 BeanFactoryPostProcessor 实现类，以此来实现 Autowired Configuration @Resource @PostConstruct @PreDestroy 等注解的实现。其他的注解暂且不看，我们直接看今天的重点 Configuration 注解是如何解析，@Configuration是通过 BeanFactoryPostProcessor 的实现类 ConfigurationClassPostProcessor 类在Spring启动的时候执行的（具体BeanFactoryPostProcessor的执行时机可以看我另一篇博文[ 链接](https://www.yuque.com/wangjunnan/pnhnfo/bx15ai)） ConfigurationClassPostProcessor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123;int registryId = System.identityHashCode(registry); // 判断是否已经执行过if (this.registriesPostProcessed.contains(registryId)) &#123;throw new IllegalStateException("postProcessBeanDefinitionRegistry already called on this post-processor against " + registry);&#125;if (this.factoriesPostProcessed.contains(registryId)) &#123;throw new IllegalStateException("postProcessBeanFactory already called on this post-processor against " + registry);&#125;this.registriesPostProcessed.add(registryId); // 正式执行逻辑processConfigBeanDefinitions(registry);&#125;public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123;List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;();String[] candidateNames = registry.getBeanDefinitionNames();// 遍历所有 BeanDefinition namefor (String beanName : candidateNames) &#123;BeanDefinition beanDef = registry.getBeanDefinition(beanName); // 判断是否已经处理过if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) ||ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123;if (logger.isDebugEnabled()) &#123;logger.debug("Bean definition has already been processed as a configuration class: " + beanDef);&#125;&#125; // 条件筛选else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123;configCandidates.add(new BeanDefinitionHolder(beanDef, beanName));&#125;&#125;// 栓选完为空 直接返回if (configCandidates.isEmpty()) &#123;return;&#125;// 根据 @Order 注解排序configCandidates.sort((bd1, bd2) -&gt; &#123;int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition());int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition());return Integer.compare(i1, i2);&#125;);// Detect any custom bean name generation strategy supplied through the enclosing application context // 获取 BeanName 生成策略SingletonBeanRegistry sbr = null;if (registry instanceof SingletonBeanRegistry) &#123;sbr = (SingletonBeanRegistry) registry;if (!this.localBeanNameGeneratorSet) &#123;BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR);if (generator != null) &#123;this.componentScanBeanNameGenerator = generator;this.importBeanNameGenerator = generator;&#125;&#125;&#125;if (this.environment == null) &#123;this.environment = new StandardEnvironment();&#125;// Parse each @Configuration class // 解析 @Configuration 注解ConfigurationClassParser parser = new ConfigurationClassParser(this.metadataReaderFactory, this.problemReporter, this.environment,this.resourceLoader, this.componentScanBeanNameGenerator, registry);Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates);Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size());do &#123;parser.parse(candidates);parser.validate();Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses());configClasses.removeAll(alreadyParsed);// Read the model and create bean definitions based on its content // 读取并解析注册 BeanDefinitionif (this.reader == null) &#123;this.reader = new ConfigurationClassBeanDefinitionReader(registry, this.sourceExtractor, this.resourceLoader, this.environment,this.importBeanNameGenerator, parser.getImportRegistry());&#125;this.reader.loadBeanDefinitions(configClasses);alreadyParsed.addAll(configClasses);candidates.clear(); // 处理新加入的if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123;String[] newCandidateNames = registry.getBeanDefinitionNames();Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames));Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;();for (ConfigurationClass configurationClass : alreadyParsed) &#123;alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());&#125;for (String candidateName : newCandidateNames) &#123;if (!oldCandidateNames.contains(candidateName)) &#123;BeanDefinition bd = registry.getBeanDefinition(candidateName);if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;!alreadyParsedClasses.contains(bd.getBeanClassName())) &#123;candidates.add(new BeanDefinitionHolder(bd, candidateName));&#125;&#125;&#125;candidateNames = newCandidateNames;&#125;&#125;while (!candidates.isEmpty());// Register the ImportRegistry as a bean in order to support ImportAware @Configuration classesif (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123;sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());&#125;if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123;// Clear cache in externally provided MetadataReaderFactory; this is a no-op// for a shared cache since it'll be cleared by the ApplicationContext.((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();&#125;&#125; 具体的执行逻辑在ConfigurationClassParser 类的 parse 方法中 ConfigurationClassParser 核心解析方法是 doProcessConfigurationClass方法，下面直接看这个方法的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)throws IOException &#123;// Recursively process any member (nested) classes firstprocessMemberClasses(configClass, sourceClass);// Process any @PropertySource annotations // 解析 @PropertySource for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), PropertySources.class,org.springframework.context.annotation.PropertySource.class)) &#123;if (this.environment instanceof ConfigurableEnvironment) &#123;processPropertySource(propertySource);&#125;else &#123;logger.warn("Ignoring @PropertySource annotation on [" + sourceClass.getMetadata().getClassName() +"]. Reason: Environment must implement ConfigurableEnvironment");&#125;&#125;// Process any @ComponentScan annotations // 解析 @ComponentScan Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);if (!componentScans.isEmpty() &amp;&amp;!this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123;for (AnnotationAttributes componentScan : componentScans) &#123;// The config class is annotated with @ComponentScan -&gt; perform the scan immediatelySet&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions =this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName());// Check the set of scanned definitions for any further config classes and parse recursively if neededfor (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123;BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();if (bdCand == null) &#123;bdCand = holder.getBeanDefinition();&#125;if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123;parse(bdCand.getBeanClassName(), holder.getBeanName());&#125;&#125;&#125;&#125;// Process any @Import annotations // 解析 @ImportprocessImports(configClass, sourceClass, getImports(sourceClass), true);// Process any @ImportResource annotations // 解析 @ImportResourceAnnotationAttributes importResource =AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);if (importResource != null) &#123;String[] resources = importResource.getStringArray("locations");Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass("reader");for (String resource : resources) &#123;String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);configClass.addImportedResource(resolvedResource, readerClass);&#125;&#125;// Process individual @Bean methods // 解析 @BeanSet&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);for (MethodMetadata methodMetadata : beanMethods) &#123;configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));&#125;// Process default methods on interfacesprocessInterfaces(configClass, sourceClass);// Process superclass, if anyif (sourceClass.getMetadata().hasSuperClass()) &#123;String superclass = sourceClass.getMetadata().getSuperClassName();if (superclass != null &amp;&amp; !superclass.startsWith("java") &amp;&amp;!this.knownSuperclasses.containsKey(superclass)) &#123;this.knownSuperclasses.put(superclass, configClass);// Superclass found, return its annotation metadata and recursereturn sourceClass.getSuperClass();&#125;&#125;// No superclass -&gt; processing is completereturn null;&#125; 可以看到上面的代码依次解析了 @PropertySource，@ComponentScan @Bean @Import 等注解。这里我们重点关注 @Bean 的实现 123456789101112// 获取 @bean 注解修饰的 方法元数据信息Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);for (MethodMetadata methodMetadata : beanMethods) &#123; // 封装成 BeanMethod configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));&#125; 下面我们回到 ConfigurationClassPostProcessor ，解析完 元数据之后，就是加载注册 BeanDefinition了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354this.reader.loadBeanDefinitions(configClasses);public void loadBeanDefinitions(Set&lt;ConfigurationClass&gt; configurationModel) &#123;TrackedConditionEvaluator trackedConditionEvaluator = new TrackedConditionEvaluator();for (ConfigurationClass configClass : configurationModel) &#123;loadBeanDefinitionsForConfigurationClass(configClass, trackedConditionEvaluator);&#125;&#125;private void loadBeanDefinitionsForConfigurationClass(ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123;if (trackedConditionEvaluator.shouldSkip(configClass)) &#123;String beanName = configClass.getBeanName();if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123;this.registry.removeBeanDefinition(beanName);&#125;this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName());return;&#125;if (configClass.isImported()) &#123;registerBeanDefinitionForImportedConfigurationClass(configClass);&#125;for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123; // 解析之前 解析 @bean 加入的 beanMethod信息loadBeanDefinitionsForBeanMethod(beanMethod);&#125;loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());&#125; 看看 loadBeanDefinitionsForBeanMethod 方法的实现，其实就是从BeanMethod中提取信息组装成 BeanDefinition 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174private void loadBeanDefinitionsForBeanMethod(BeanMethod beanMethod) &#123;ConfigurationClass configClass = beanMethod.getConfigurationClass();MethodMetadata metadata = beanMethod.getMetadata();String methodName = metadata.getMethodName();// 判断是否需要跳过if (this.conditionEvaluator.shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN)) &#123;configClass.skippedBeanMethods.add(methodName);return;&#125;if (configClass.skippedBeanMethods.contains(methodName)) &#123;return;&#125;AnnotationAttributes bean = AnnotationConfigUtils.attributesFor(metadata, Bean.class);Assert.state(bean != null, "No @Bean annotation attributes");// 考虑别名 名称List&lt;String&gt; names = new ArrayList&lt;&gt;(Arrays.asList(bean.getStringArray("name")));String beanName = (!names.isEmpty() ? names.remove(0) : methodName);// 注册别名 for (String alias : names) &#123;this.registry.registerAlias(beanName, alias);&#125;// Has this effectively been overridden before (e.g. via XML)? // 判断是否在 xml配置文件中 已经配置过if (isOverriddenByExistingDefinition(beanMethod, beanName)) &#123;if (beanName.equals(beanMethod.getConfigurationClass().getBeanName())) &#123;throw new BeanDefinitionStoreException(beanMethod.getConfigurationClass().getResource().getDescription(),beanName, "Bean name derived from @Bean method '" + beanMethod.getMetadata().getMethodName() +"' clashes with bean name for containing configuration class; please make those names unique!");&#125;return;&#125;ConfigurationClassBeanDefinition beanDef = new ConfigurationClassBeanDefinition(configClass, metadata);beanDef.setResource(configClass.getResource());beanDef.setSource(this.sourceExtractor.extractSource(metadata, configClass.getResource())); // 这里可以知道 @bean 配置是 通过 FactoryMethod 来初始化的if (metadata.isStatic()) &#123;// static @Bean methodbeanDef.setBeanClassName(configClass.getMetadata().getClassName());beanDef.setFactoryMethodName(methodName);&#125;else &#123;// instance @Bean methodbeanDef.setFactoryBeanName(configClass.getBeanName());beanDef.setUniqueFactoryMethodName(methodName);&#125;beanDef.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_CONSTRUCTOR);beanDef.setAttribute(RequiredAnnotationBeanPostProcessor.SKIP_REQUIRED_CHECK_ATTRIBUTE, Boolean.TRUE);AnnotationConfigUtils.processCommonDefinitionAnnotations(beanDef, metadata); // 设置autowire属性Autowire autowire = bean.getEnum("autowire");if (autowire.isAutowire()) &#123;beanDef.setAutowireMode(autowire.value());&#125;// 设置initMethod 初始化方法String initMethodName = bean.getString("initMethod");if (StringUtils.hasText(initMethodName)) &#123;beanDef.setInitMethodName(initMethodName);&#125;// 设置destroyMethod 销毁方法String destroyMethodName = bean.getString("destroyMethod");beanDef.setDestroyMethodName(destroyMethodName);// 获取 scopeScopedProxyMode proxyMode = ScopedProxyMode.NO;AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(metadata, Scope.class);if (attributes != null) &#123;beanDef.setScope(attributes.getString("value"));proxyMode = attributes.getEnum("proxyMode");if (proxyMode == ScopedProxyMode.DEFAULT) &#123;proxyMode = ScopedProxyMode.NO;&#125;&#125;// Replace the original bean definition with the target one, if necessary // 如有必要，将原始Bean定义替换为目标Bean定义BeanDefinition beanDefToRegister = beanDef;if (proxyMode != ScopedProxyMode.NO) &#123;BeanDefinitionHolder proxyDef = ScopedProxyCreator.createScopedProxy(new BeanDefinitionHolder(beanDef, beanName), this.registry,proxyMode == ScopedProxyMode.TARGET_CLASS);beanDefToRegister = new ConfigurationClassBeanDefinition((RootBeanDefinition) proxyDef.getBeanDefinition(), configClass, metadata);&#125;if (logger.isDebugEnabled()) &#123;logger.debug(String.format("Registering bean definition for @Bean method %s.%s()",configClass.getMetadata().getClassName(), beanName));&#125;this.registry.registerBeanDefinition(beanName, beanDefToRegister);&#125; 代码解析到这里为止，@Bean配置的Bean信息就被全部抽象成了一个 BeanDefinition对象，接下来的Bean加载等等一大堆逻辑走的就是Spring的同一套逻辑了。 以上是通过在配置文件中配置 &lt;context:annotation-config&gt; &lt;context:component-scan&gt;。 Springboot怎么做的那么Spring Boot并不需要配置文件，它又是在哪里配置了入口呢？ 其实在之前的分析Spring boot的启动过程时 已经有提到了 链接 ，其实是在初始化 Spring容器的构造方法中进行了配置的加载，并且最终也是调用了 AnnotationConfigUtils 工具类的 registerAnnotationConfigProcessors方法 总结终于写完了，其实分析来分析去，不论是Spring Boot Spring mvc 其实最核心不变的还是 Spring Framework，只要把核心搞清楚了，下次Spring 又推出什么 Spring xxx 也能应付自如]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC-HttpRequestHandler接口静态资源的关系]]></title>
    <url>%2F2019%2F08%2F30%2FMVC-HttpRequestHandler%E6%8E%A5%E5%8F%A3%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[在Spring Mvc，一般我们都会配置对静态资源的拦截，因为静态资源处理有别与普通请求，需要进行特殊配置。 比较常用的配置有这几种 Tomcat defaultServelt 激活tomcat自带的defaultServelt 用来处理静态资源 123456789101112&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.jpg&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.js&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.css&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 使用 &lt;mvc:resources/&gt; Spring mvc自己提供的静态资源处理器 例如做如下配置，就可以将static开头的路径全部访问至static目录 1&lt;mvc:resources mapping="/static/**" location="/static/" /&gt; 那么这个配置的实现原理是什么？ 通过阅读源码其实可以知道实际上是 Spring mvc 自动帮我们注册了一个SimpleUrlHandlerMapping，在之前分析SimpleUrlHandlerMapping时也有提到它其实可以当成拦截器用，这里其实就是一个实例。注册了HandlerMapping必然要确定handler处理器，这里的handler处理器其实就是HttpRequestHandler接口的实现类（ResourceHttpRequestHandler） 使用 &lt;mvc:default-servlet-handler/&gt; 激活Spring mvc提供的默认静态资源处理器 使用这个配置其实原理与第二个配置非常相似，也是利用了SimpleUrlHandlerMapping，并且handler处理器也是HttpRequestHandler接口的实现类，只是把具体的实现类换成了DefaultServletHttpRequestHandler，相比第二种配置，此种配置无法自定义。 写在后面 不过我们要是使用Spring boot开发，也就省去了这一堆繁琐的配置，包括静态资源的配置也都是自动完成配置。只要按照约定将静态资源放置在classpath下的这几个目录下（public,resource,static），就不需要任何配置，不得不说，约定优于配置还是可以极大的提升开发效率的。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写一个starter]]></title>
    <url>%2F2019%2F08%2F28%2F%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AAstarter%2F</url>
    <content type="text"><![CDATA[引言前文说过，Spring Boot最大的优势在于自动配置，我么只需要引入一个个第三方提供的starter就可以快速集成第三方功能，既然starter这么方便，我们自己应该也可以写一个。 快速写一个starter 新建一个maven项目 123456789101112&lt;groupId&gt;com.walm&lt;/groupId&gt; &lt;artifactId&gt;boot-test-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 新建一个config类 12345678@Configurationpublic class HelloWorldConfig &#123; @Bean public HelloWorld HelloWord() &#123; return new HelloWorld(); &#125;&#125; 新建一个提供服务的service类 123456public class HelloWorld &#123; public void sayHello() &#123; System.out.println("hello world !!!!"); &#125;&#125; 最重要的是一步，需要让spring能够扫描到我们的 config HelloWorldConfig 类 在resource 文件夹下新建一个 META-INF 文件夹 新建一个 spring.factories 文件 在spring.factories文件中配置我们的写的HelloWorldConfig类 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.walm.boottest.HelloWorldConfig 这样一个简单的 springboot starter 就完成了，最后本地安装 install我们的starter jar包就可以在其他项目中引用了 引用starter，只需要在项目引用 该jar包即可 12345&lt;dependency&gt; &lt;groupId&gt;com.walm&lt;/groupId&gt; &lt;artifactId&gt;boot-test-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 下面我们简单分析一下 stater的原理 starter 自动配置原理首先自动配置的原理关键一定是在 spring.factories 文件是如何被加载到的这个点上去探究 需要从spring boot的启动过程一步一步的去看了 首先，我们启动一个spring-boot项目，肯定会有一个配置注解 SpringBootApplication 那么这个注解到底起什么作用呢？ SpringBootApplication.class 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; /** * Base packages to scan for annotated components. Use &#123;@link #scanBasePackageClasses&#125; * for a type-safe alternative to String-based package names. * @return base packages to scan * @since 1.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = "basePackages") String[] scanBasePackages() default &#123;&#125;; /** * Type-safe alternative to &#123;@link #scanBasePackages&#125; for specifying the packages to * scan for annotated components. The package of each class specified will be scanned. * &lt;p&gt; * Consider creating a special no-op marker class or interface in each package that * serves no purpose other than being referenced by this attribute. * @return base packages to scan * @since 1.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = "basePackageClasses") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 这里着重看 EnableAutoConfiguration 这个注解 12345678910111213141516171819202122232425@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; 可以看到 @Import(AutoConfigurationImportSelector.class)这个注解，这里就是我们自动配置的入口注意，解析Import注解其实是通过 BeanFactoryPostProcessor 接口来扩展的 下面我们来看下AutoConfigurationImportSelector.class 类的实现，AutoConfigurationImportSelector 实现了ImportSelector接口 ImportSelector 123456789public interface ImportSelector &#123; /** * Select and return the names of which class(es) should be imported based on * the &#123;@link AnnotationMetadata&#125; of the importing @&#123;@link Configuration&#125; class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);&#125; 在解析import注解的时候会调用指定ImportSelector 接口实现 的 selectImports方法。下面我们看下AutoConfigurationImportSelector的 selectImports方法实现 selectImports 12345678910111213141516171819public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); // 获取 META-INF/spring.factories 文件中的配置信息 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); // 触发事件 fireAutoConfigurationImportEvents(configurations, exclusions); return StringUtils.toStringArray(configurations); &#125; 总结写一个starter还是非常简单的，核心就是要让springboot自动扫描到我们的 配置类，核心逻辑其实就是通过扫描我们的自定义的META-INF/spring.factories文件来进行自动配置]]></content>
      <categories>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot的启动过程]]></title>
    <url>%2F2019%2F08%2F27%2FSpringBoot%E7%9A%84%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引言在我之前写的文章中有详细分析过Spring的启动过程，如何大家有深入阅读过Spring Framework的核心源码，那么阅读Spring Boot的源码会比较轻松。个人觉得Spring Boot核心的东西比较少，其核心还是Spring Framework。 启动入口还是一步到位，直接看源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public ConfigurableApplicationContext run(String... args) &#123; // 统计启动时间 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); // 设置 java.awt.headless 参数 configureHeadlessProperty(); // 获取监听器 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); // 创建 context容器 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 准备容器 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 刷新容器 refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context; &#125; createApplicationContext12345678910111213141516171819202122232425protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Unable create a default ApplicationContext, " + "please specify an ApplicationContextClass", ex); &#125; &#125; // 这里会引入一些BeanFactoryProcess，比如 ConfigurationClassPostProcessor 解析Configuration注解的 return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass); &#125; 注: 引入的BeanFactoryProcess 的逻辑在DEFAULT_SERVLET_WEB_CONTEXT_CLASS的构造方法中 1234567// 看下 AnnotationConfigServletWebServerApplicationContext 的构造方法public AnnotationConfigServletWebServerApplicationContext() &#123; // 相当于xml中配置了 &lt;context:annotation-config&gt; this.reader = new AnnotatedBeanDefinitionReader(this); // 相当于xml中配置了 &lt;context:component-scan&gt; this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; 我们在看下 AnnotatedBeanDefinitionReader 的构造方法 123456789101112131415161718192021public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; this(registry, getOrCreateEnvironment(registry)); &#125; /** * Create a new &#123;@code AnnotatedBeanDefinitionReader&#125; for the given registry and using * the given &#123;@link Environment&#125;. * @param registry the &#123;@code BeanFactory&#125; to load bean definitions into, * in the form of a &#123;@code BeanDefinitionRegistry&#125; * @param environment the &#123;@code Environment&#125; to use when evaluating bean definition * profiles. * @since 3.1 */ public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) &#123; Assert.notNull(registry, "BeanDefinitionRegistry must not be null"); Assert.notNull(environment, "Environment must not be null"); this.registry = registry; this.conditionEvaluator = new ConditionEvaluator(registry, environment, null); // 在这里 注册了一堆的 BeanFactoryProcess AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125; 下面主要prepareContext和refreshContext方法 prepareContext 1234567891011121314151617181920212223242526private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans context.getBeanFactory().registerSingleton("springApplicationArguments", applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton("springBootBanner", printedBanner); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, "Sources must not be empty"); // 这里引入了 启动类 load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context); &#125; 注： 这里的主要作用就是引入了启动类，加入到 BeanFactory中 refreshContext 后面其实 就是 Spring 统一的一套了 可以看我的之前写的 Spring 源码解析系列 总结Springboot的核心在于自动配置 快速集成 。一些原本需要在Spring xml文件配置的东西，Spring 只需要一个注解就帮我们都做了。不过前文也都说了，核心还是 Spring Framework。]]></content>
      <categories>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC源码解析-HandlerAdapter]]></title>
    <url>%2F2019%2F08%2F25%2FMVC%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-HandlerAdapter%2F</url>
    <content type="text"><![CDATA[引言上篇文章分析了handerMapping的实现。本篇文章会继续分析和handerMapping相辅相成的handerAdapter。 什么是handerAdapter？在理解了handerMapping的基础上，我们应该发现了一个问题。就是每个handerMapping所匹配的到的hander实现是不一样的。比如RequestMappingHandlerMapping的hander的实现是一个HandlerMethod实现，而BeanNameUrlHandlerMapping的hander则是一个Controller接口实现类。所以如果我们要是不引入handerAdapter的话，就无法统一的去执行各自的hander 上文所说handerAdapter和handerMapping是相辅相成的。以下列出了几个的对应关系 RequestMappingHandlerMapping -&gt; RequestMappingHandlerAdapter BeanNameUrlHandlerMapping -&gt; SimpleControllerHandlerAdapter SimpleUrlHandlerMapping -&gt; SimpleControllerHandlerAdapter SimpleUrlHandlerMapping -&gt; HttpRequestHandlerAdapter 其中SimpleUrlHandlerMapping比较特殊，可以对应多个Adapter，主要原因是SimpleUrlHandlerMapping中的handler类型也可以有多种，比较常见的有Controller接口实现类，HttpRequestHandler接口实现类。 HandlerAdapter接口先看下HandlerAdapter接口的几个方法 123456789101112131415161718192021222324252627282930public interface HandlerAdapter &#123; /*** * 判断指定hander是否可以被当前Adapter支持 * * @param handler handler object to check * @return whether or not this object can use the given handler */ boolean supports(Object handler); /** * 执行hander方法 * returned &#123;@code true&#125;. * @throws Exception in case of errors * @return ModelAndView object with the name of the view and the required * model data, or &#123;@code null&#125; if the request has been handled directly */ @Nullable ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; /** * 与HttpServlet的&#123;@code getLastModified&#125;方法的约定相同 * @param request current HTTP request * @param handler handler to use * @return the lastModified value for the given handler * @see javax.servlet.http.HttpServlet#getLastModified * @see org.springframework.web.servlet.mvc.LastModified#getLastModified */ long getLastModified(HttpServletRequest request, Object handler);&#125; 核心是supports和hander方法 supports用于判断指定hander是否可以被当前Adapter支持 hander方法用于执行指定的hander的核心逻辑 下面简单来看下各个HandlerAdapter接口的实现类，看一下对这两个核心方法的实现 RequestMappingHandlerAdapter supports 123public final boolean supports(Object handler) &#123; return (handler instanceof HandlerMethod &amp;&amp; supportsInternal((HandlerMethod) handler));&#125; 方法比较简单，判断handler的类型是不是HandlerMethod，如果是的话，则说明该handler可以被该adapter所适配，那么就会直接返回该Adapter。 hander 123456789101112131415161718192021222324252627282930313233343536373839protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; // 定义 ModelAndView ModelAndView mav; checkRequest(request); // 处于一个session时判断是否需要同步 if (this.synchronizeOnSession) &#123; // 获取当前session HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123; // 执行 handerMethod 实际逻辑 mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No HttpSession available -&gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // mav = invokeHandlerMethod(request, response, handlerMethod); &#125; if (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; prepareResponse(response); &#125; &#125; return mav;&#125; SimpleControllerHandlerAdapter supports 123public boolean supports(Object handler) &#123; return (handler instanceof Controller);&#125; 判断是否是handler的类型是否是Controller handler 12345public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return ((Controller) handler).handleRequest(request, response);&#125; 是的话，则直接执行Controller的handleRequest方法 HttpRequestHandlerAdapter supports 123public boolean supports(Object handler) &#123; return (handler instanceof HttpRequestHandler);&#125; handler 123456public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((HttpRequestHandler) handler).handleRequest(request, response); return null;&#125; 实现逻辑与SimpleControllerHandlerAdapter类似 对于以上几个Adapter的匹配顺序，Spring会根据各个Adapter的Order值来进行排序，依次匹配直到找到合适的为止。 总结HandlerAdapter的核心逻辑就是承接不同的HandlerMapping做适配。本身的逻辑并不复杂，其引入的适配中间层设计模式是一个非常好的案例。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC源码解析-HandlerMapping]]></title>
    <url>%2F2019%2F08%2F20%2FMVC%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-HandlerMapping%2F</url>
    <content type="text"><![CDATA[引言什么是Spring mvc 的 HanderMapping? **我们知道当一个http请求到服务器时，我们需要根据请求的上下文url来匹配到对应的处理类，而HanderMapping做的就是这个事情，它定义了我们的请求和对应的处理类的映射关系。 Spring mvc提供了多种HanderMapping类型，比较常用的有 RequestMappingHandlerMapping,BeanNameUrlHandlerMapping,SimpleUrlHandlerMapping 以下是这三个HanderMapping的继承结构： 先来看一下这几个HandlerMapping的配置入口，如果是普通Spring Mvc应用的话，当我们在配置文件中配置了annotation-driven后，便会自动帮我们注入这几个类。具体的源码入口在AnnotationDrivenBeanDefinitionParser中，这里的逻辑非常简单，就是帮我们自动注入这几个常用类的BeanDefinition元数据（包括HandlerMapping，handlerAdapter，ExceptionResolver等等） 下面通过阅读源码依次分别看一下这几个HanderMapping的作用及实现原理 RequestMappingHandlerMapping我们先来看下 RequestMappingHandlerMapping 的用法 123456789101112@Controllerpublic class TestAPI &#123; @RequestMapping(value = &quot;/api/sayHello&quot;) public String hello() &#123; return &quot;OK&quot;; &#125; @RequestMapping(value = &quot;/api/sayHello2&quot;) public String hello2() &#123; return &quot;OK&quot;; &#125;&#125; 如上面的代码，这是一个我们非常常用的用法，一个Controller定义多个处理方法，并且在方法上注解RequestMapping，如此做之后就可以实现一个Controller根据不同的路径分别可以处理多个请求。下面我们来看下其实现原理。我比较好奇的是，RequestMappingHandlerMapping是如何将请求路径与处理方法进行初始化映射的？ 通过观察RequestMappingHandlerMapping的继承体系，可以知道其实现了InitializingBean接口 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic void afterPropertiesSet() &#123; initHandlerMethods();&#125;/** * 初始化 HandlerMethods */protected void initHandlerMethods() &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Looking for request mappings in application context: " + getApplicationContext()); &#125; // 获取容器中所有的Bean String[] beanNames = (this.detectHandlerMethodsInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(obtainApplicationContext(), Object.class) : obtainApplicationContext().getBeanNamesForType(Object.class)); for (String beanName : beanNames) &#123; if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; Class&lt;?&gt; beanType = null; try &#123; beanType = obtainApplicationContext().getType(beanName); &#125; catch (Throwable ex) &#123; // An unresolvable bean type, probably from a lazy bean - let's ignore it. if (logger.isDebugEnabled()) &#123; logger.debug("Could not resolve target class for bean with name '" + beanName + "'", ex); &#125; &#125; // 判断该Bean是否被 @Controller 或则 @RequestMapping 所注解 if (beanType != null &amp;&amp; isHandler(beanType)) &#123; // 初始化 HandlerMethods detectHandlerMethods(beanName); &#125; &#125; &#125; handlerMethodsInitialized(getHandlerMethods());&#125; 上面的代码主要做了3件事情 获取容器中所有的Bean 筛选出被@Controller 或则 @RequestMapping 所注解的Bean 根据筛选出的Bean初始化HandlerMethod 可以看到这里有一个很重要的类叫做HandlerMethod，我们来看看这个类的结构 12345678910111213141516171819202122232425/** 目标Bean **/private final Object bean;@Nullableprivate final BeanFactory beanFactory;private final Class&lt;?&gt; beanType; /** 对应的目标方法 **/private final Method method;private final Method bridgedMethod;/** 方法参数类型 **/private final MethodParameter[] parameters;@Nullableprivate HttpStatus responseStatus;@Nullableprivate String responseStatusReason;@Nullableprivate HandlerMethod resolvedFromHandlerMethod;... 还提供了很多方法，像获取方法返回值等等 对于这个类我们现在可以不用深入去理解，只需知道它封装了处理类的目标方法 123456789101112131415161718192021222324252627protected void detectHandlerMethods(Object handler) &#123; Class&lt;?&gt; handlerType = (handler instanceof String ? obtainApplicationContext().getType((String) handler) : handler.getClass()); if (handlerType != null) &#123; Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType); // 获取目标Bean中被RequestMapping注解的方法 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, (MethodIntrospector.MetadataLookup&lt;T&gt;) method -&gt; &#123; try &#123; return getMappingForMethod(method, userType); &#125; catch (Throwable ex) &#123; throw new IllegalStateException("Invalid mapping on handler class [" + userType.getName() + "]: " + method, ex); &#125; &#125;); if (logger.isDebugEnabled()) &#123; logger.debug(methods.size() + " request handler methods found on " + userType + ": " + methods); &#125; // 注册 HandlerMethod methods.forEach((method, mapping) -&gt; &#123; Method invocableMethod = AopUtils.selectInvocableMethod(method, userType); registerHandlerMethod(handler, invocableMethod, mapping); &#125;); &#125;&#125; 上面的代码主要做了两件事情 获取目前Bean中被RequestMapping注解的方法 把获取到的Method 封装成HandlerMethod并完成注册 到这里为止RequestMappingHandlerMapping就完成初始化了，下面再来看下当一个请求来时其实如何处理的，并选择正确的 HandlerMethod 处理的. 当一个请求进来时，DispatcherServlet会分别调用每个HandlerMapping的getHandler的方法，直到有个HandlerMapping返回了一个hander getHandler方法在抽象父类AbstractHandlerMapping.class中 1234567891011121314151617181920212223public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 具体调用逻辑，由子类实现 Object handler = getHandlerInternal(request); if (handler == null) &#123; handler = getDefaultHandler(); &#125; if (handler == null) &#123; return null; &#125; if (handler instanceof String) &#123; String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); &#125; HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.globalCorsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; 看RequestMappingHandlerMapping的getHandlerInternal方法 1234567891011121314151617181920212223242526protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; // 根据 request获取到 path // 如请求是 localhost:8080/api/sayHello // 则这里返回 /api/sayHello String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); if (logger.isDebugEnabled()) &#123; logger.debug("Looking up handler method for path " + lookupPath); &#125; this.mappingRegistry.acquireReadLock(); try &#123; // 获取到请求对应的 handlerMethod HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); if (logger.isDebugEnabled()) &#123; if (handlerMethod != null) &#123; logger.debug("Returning handler method [" + handlerMethod + "]"); &#125; else &#123; logger.debug("Did not find handler method for [" + lookupPath + "]"); &#125; &#125; return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123; this.mappingRegistry.releaseReadLock(); &#125;&#125; 以上就是RequestMappingHandlerMapping在整个MVC流程中所起的作用 BeanNameUrlHandlerMapping下面我们再简单看下BeanNameUrlHandlerMapping的使用和原理顾名思义，BeanNameUrlHandlerMapping就是指通过BeanName和Url进行关联匹配，跟RequestMappingHandlerMapping不一样，BeanNameUrlHandlerMapping一个Bean就对应处理一个请求.先来看个使用的例子 123456789@Component(&quot;/test2API&quot;)public class Test2API implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; System.out.println(&quot;test2API&quot;); return null; &#125;&#125; 如此定义一个类，我们便能通过/test2API这个路径来访问这个类。如何实现的？我们还是打开BeanNameUrlHandlerMapping看看其实现，与RequestMappingHandlerMapping不同的是，它没有实现InitializingBean接口，不过它实现了ApplicationContextAware接口，在Spring容器完成初始化的时候回调用这个唤醒接口，也就是在这里进行了BeanNameUrlHandlerMapping的初始化。 初始化逻辑在 AbstractDetectingUrlHandlerMapping.detectHandlers() 方法中 12345678910111213141516171819202122232425protected void detectHandlers() throws BeansException &#123; ApplicationContext applicationContext = obtainApplicationContext(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Looking for URL mappings in application context: &quot; + applicationContext); &#125; String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class) : applicationContext.getBeanNamesForType(Object.class)); // Take any bean name that we can determine URLs for. for (String beanName : beanNames) &#123; // 获取BeanName或别名是 &quot;/&quot; 开头的 Bean名称 String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &#123; // URL paths found: Let&apos;s consider it a handler. // 把获取到的 urls 注册到 handler registerHandler(urls, beanName); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Rejected bean name &apos;&quot; + beanName + &quot;&apos;: no URL paths identified&quot;); &#125; &#125; &#125;&#125; determineUrlsForHandler是BeanNameUrlHandlerMapping类仅有实现的一个方法，主要逻辑就是获取BeanName或别名是 “/“ 开头的 Bean名称。所以这里也可以知道在上文的使用例子中，BeanName我为何要以斜杠开头。 当一个请求来时BeanNameUrlHandlerMapping的处理逻辑类似，只不过匹配的容器换成了handlerMap = new LinkedHashMap&lt;&gt;();，匹配逻辑更加的简单直接。 SimpleUrlHandlerMapping最后再看下 SimpleUrlHandlerMapping的用法及实现 定义一个SimpleUrlHandlerMapping 1234567891011121314@Configurationpublic class SampleConfig &#123; @Bean public SimpleUrlHandlerMapping simpleUrlHandlerMapping() &#123; SimpleUrlHandlerMapping simpleUrlHandlerMapping = new SimpleUrlHandlerMapping(); Map&lt;String, Object&gt; urlMap = new HashMap&lt;&gt;(); urlMap.put("/**", new Test2API()); // ... 可配置多个映射关系 simpleUrlHandlerMapping.setUrlMap(urlMap); simpleUrlHandlerMapping.setOrder(1); return simpleUrlHandlerMapping; &#125;&#125; 以上配置会拦截所有的请求，然后转交给 Test2API处理（Test2API可以是Controller接口实现类，也可以是一个 HttpRequestHandler接口实现类），可以看到这里SimpleUrlHandlerMapping起的作用非常像一个拦截器起的作用，其实也确实是这样，像对静态资源的拦截就可以采用SimpleUrlHandlerMapping来实现。 具体实现其实跟上文的两种mapping实现类似，简单看下源码 初始注册逻辑 123456789101112131415161718192021222324@Overridepublic void initApplicationContext() throws BeansException &#123; super.initApplicationContext(); registerHandlers(this.urlMap);&#125;protected void registerHandlers(Map&lt;String, Object&gt; urlMap) throws BeansException &#123; if (urlMap.isEmpty()) &#123; logger.warn("Neither 'urlMap' nor 'mappings' set on SimpleUrlHandlerMapping"); &#125; else &#123; urlMap.forEach((url, handler) -&gt; &#123; // 确保路径是以斜杠开头的 if (!url.startsWith("/")) &#123; url = "/" + url; &#125; // 去除空格 if (handler instanceof String) &#123; handler = ((String) handler).trim(); &#125; // 注册 registerHandler(url, handler); &#125;); &#125;&#125; 逻辑还是比较简单的，就是将我们手动配置的多个映射关系进行初始注册，以备后面逻辑使用。 总结总的来说HanderMapping的职责是非常清晰的，就是存储并匹配请求url和处理类的映射关系。整个处理流程的源码相对来说也比较直观，易阅读。读完其源码对MVC的url匹配流程会有更加深刻的认识]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务在积分商城里的应用]]></title>
    <url>%2F2019%2F07%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%9C%A8%E7%A7%AF%E5%88%86%E5%95%86%E5%9F%8E%E9%87%8C%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[引言最近在做会员体系的时候，涉及到了积分商城订单体系，既然设计到订单体系，因为现在的项目架构体系基本都是微服务分布式的，所以必然会涉及到分布式事务。事务问题在早些时候都是单机部署的时代依靠数据库本身提供的事务机制非常容易解决，但是一旦设计到分布式，各个独立的服务是无法感知其他事务执行状态的，所以我们需要借助一些其他手段来保证分布式事务 分布式理论 CAP C（一致性）一致性是指数据的原子性，在经典的数据库中通过事务来保障，事务完成时，无论成功或回滚，数据都会处于一致的状态，在分布式环境下，一致性是指多个节点数据是否一致； A（可用性）服务一直保持可用的状态，当用户发出一个请求，服务能在一定的时间内返回结果； P（分区容错性）机器故障、网络故障、机房停电等异常情况下仍然能够满足一致性和可用性，分布式应用一般都满足分区容错性分布式事务我们要解决的就是数据的一致性问题 一致性模型 基本可用（Basically Available） 软状态（Soft State） 最终一致性（Eventually Consistent） 其中最终一致性又可分为：会话一致性 单调一致性等等 2PC (Two/Three Phase Commit)2PC 我们又把它叫做两阶段提交，在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点（称作参与者）的操作结果并最终指示这些节点是否要把操作结果进行真正的提交（比如将更新后的数据写入磁盘等等）。因此，二阶段提交的算法思路可以概括为： 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 前提二阶段提交算法的成立基于以下假设： 该分布式系统中，存在一个节点作为协调者(Coordinator)，其他节点作为参与者(Participants)。且节点之间可以进行网络通信。 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上，即使节点损坏不会导致日志数据的消失。 所有节点不会永久性损坏，即使损坏后仍然可以恢复。 第一阶段(提交请求阶段) 协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 有时候，第一阶段也被称作投票阶段，即各参与者投票是否要继续接下来的提交操作。 第二阶段(提交执行阶段) 成功 当协调者节点从所有参与者节点获得的相应消息都为”同意”时： 协调者节点向所有参与者节点发出”正式提交”的请求。 参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”完成”消息。 协调者节点收到所有参与者节点反馈的”完成”消息后，完成事务。 失败 如果任一参与者节点在第一阶段返回的响应消息为”终止”，或者 协调者节点在第一阶段的询问超 时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出”回滚操作”的请求。 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”回滚完成”消息。 协调者节点收到所有参与者节点反馈的”回滚完成”消息后，取消事务。 有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务 缺点二阶段提交算法的最大缺点就在于: 它的执行过程中间，节点都处于阻塞状态。即节点之间在等待对方的响应消息时，它将什么也做不了。特别是，当一个节点在已经占有了某项资源的情况下，为了等待其他节点的响应消息而陷入阻塞状态时，当第三个节点尝试访问该节点占有的资源时，这个节点也将连带陷入阻塞状态。 TCC 补偿型上面大篇幅的介绍了2PC提交，但实际的应用中我们基本都不会使用这种方案，原因在上面的缺点中已经说明了，2PC这种传统的分布式事务解决方案性能实在是太差了，在互联网大并发的背景下显然是不行的，这就引申出了TCC补偿性分布式事务解决方案 TCC是(Try-Confirm-Cancel)的简称，从名字我们知道TCC有三个阶段 TryTry阶段主要做资源的预留，锁定操作 Confirm如果Try预留资源成功，则执行Confirm操作，对资源做最终的提交 Cancel如果Try预留资源失败，则执行Cancel取消对资源的锁定 通过上文的描述，可以发现TCC与2PC非常相似，但实际上两者在解决分布式事务的层面上不一样的，2PC主要还是借助数据库层面的事务来协调解决，相对于数据库事务的rollback，TCC在逻辑层面的Cancel操作，代价要小的多。并且TCC事务引入了中间状态（也就是资源的锁定），只要全部资源都锁定成功，我们就认为最终是执行成功的（最终一致性） 下图是积分下单用TCC事务解决的典型场景 TCC是如何解决最终一致性的？当我们在Try阶段预留资源成功的话，那么我们就认为最终这个事务是肯定可以完成的，即使因为某些原因(数据库down了等的)Confirm执行失败，TCC事务框架会不停的重试调用它的Confirm逻辑，务必会保证其最终一致性 典型应用场景订单系统 事务消息事务消息的应用场景是，事务参与方的资源已经锁定，只需要保持最终一致性的场景。比较典型的实例是银行转账，当A账户完成账户扣减后，B账户不需要锁定账户，只需要保证最终B账户可以增加指定金额 为何需要先发送 Prepare消息？试想一种场景，本地事务执行成功，准备发送消息的时候断网了，这时候就会造成数据不一致的情况 commit or rollback 消息发送失败？这时候需要消息中间件提供消息回查功能，也就是当间隔一段时间之后，Prepare消息没有收到 commit or rollback消息，需要发起消息回查，并且由业务方判断最终消息是否需要投递 对于事务消息的解决方案，阿里的RocketMq也提供了解决方案 总结总体来说，每种分布式事务解决方案都有其应用场景，但目前业界比较主流的还是TCC和事务消息，TCC事务需要业务实现Try-Confirm-Cancel逻辑，需要在Try阶段提前锁定资源，相对于事务消息来说成本较高，但是事务消息的适用场景也是有限的，如下单扣减库存这个场景因为需要提前锁定库存，事务消息就不适用了。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 你真的会用吗]]></title>
    <url>%2F2019%2F06%2F21%2Fgit-%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BC%9A%E7%94%A8%E5%90%97%2F</url>
    <content type="text"><![CDATA[记录原由最近因为公司新来的同事，在使用Git时犯了一些非常低级的错误，导致团队为了解决这些问题浪费了很多时间。究其原因其实还是对于Git内部实现不清晰，仅仅知道敲几个git命令，但是却不知道敲了这个命令Git会发生什么！这里根据git官方文档节选了一些重要概念分享出来。 几个重要概念三种状态 工作区状态 就是修改了文件还没有做 git add的文件状态 暂存区状态 已经git add但还未git commit的文件状态 已提交状态 已经git commit的文件状态，也就是真正存储到git仓库 Branch指针和HEAD指针Git的分支特性是其最强大最独特的功能，也正是因为这个特性让git得以在众多的版本控制系统中脱颖而出，在理解branch之前，有必要先对git commit命令做一个简单的介绍 当使用git commit进行提交操作时，Git便会创建一个提交对象，这个对象会包含一个指向本次提交的指针，指针指向本次commit的快照。指针也就是我们通常所说的commit id(长度为 40 的 SHA-1 值字符串)。如此一来，Git就可以在需要的时候根据commit id来回退版本 Branch的本质其实仅仅是指向提交对象的某一个可变指针。所以根据这个概念，我们可以知道master并不是一个特殊的分支，他跟我们众多自定义的分支没有任何不同，唯一区别是它是Git的默认分支(初始化的时候总得有一个默认分支) 下面的图是单个master分支时的结构，这里master仅仅是一个指向f30ab提交对象的指针 执行 $ git branch testing创建一个 testing分支，会在当前所在的提交对象上创建一个名为testing的指针，也就是testing分支 注意：此时两个指针指向了相同的提交那么Git是如何来知道当前处于哪个分支的呢？这就引出了Git中的另一个特殊的指针HEAD，HEAD用来指向当前所在的分支，也就是一个用来指向分支指针的指针（有点拗口），就像下图这样，当前是在master分支，因为git branch并不会移动HEAD指针切换分支 执行 $ git checkout testing命令才会将HEAD指针指向testing分支 当我们在testing分支上继续提交几个commit之后，testing指针和HEAD指针都会跟着向前移动，但是master指针并不会移动，依旧指向f30ab这个提交 现在执行git checkout master切回master分支，HEAD指针会重新指向master，也就是说现在又回到了一个旧的版本，这也是Git的神奇之处 接下来我们在master分支上做一些修改，提交一个commit，HEAD和master指针会继续向前移动，并且这个项目的提交（快照版本）已经产生了分叉 保存分支信息的目录在.git/refs/heads下，也可以在这个目录下查看或修改分支指针 merge 命令在上文的例子中，项目有两个分支，且已经产生了分叉，这时候需要把testing分支上的内容合并至master时需要用到merge命令在master执行git merge testing，会生成一个新的提交9c67a，并且HEAD和master指针继续向前移动 reset 命令假如上面的merge操作有问题，需要撤销，可以使用reset命令，但首先需要明确回退的版本是哪一个，例如要回退的版本是c2b9e，执行git reset --hard c2b9e后，HEAD和master指针会回退到版本c2b9e …]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA 泛型 你真的理解了吗？]]></title>
    <url>%2F2019%2F06%2F19%2FJAVA-%E6%B3%9B%E5%9E%8B-%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3%E4%BA%86%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[记录原由之前虽然泛型一直在使用，但使用的过程中总是没有那么得心应手，有些细节还是过于模糊。究其原因其实是一直都没有系统深入的去理解过，最近花了一点时间去深入的理解了一下java的泛型机制，也希望借这次记录能够彻底的理解java的泛型 为什么要有泛型泛型的本质是把 类型参数化，什么是类型参数化？举个例子，我们常用的集合类，要是没有类型参数化的话，我们就得实现装不同类型的集合类，会大大降低代码的可重用性！ 例如我们要设计一个装苹果的盘子和一个装香蕉的盘子，要怎么设计呢？非常简单，最简单的方式就是设计两个盘子类，一个是苹果盘子，一个香蕉盘子，就像下面的代码一样 12345678910111213141516171819202122232425public class ApplePlant &#123; private Apple apple; public Apple getApple() &#123; return apple; &#125; public void setApple(Apple apple) &#123; this.apple = apple; &#125;&#125;public class BananaPlant &#123; private Banana banana; public Banana getBanana() &#123; return banana; &#125; public void setBanana(Banana banana) &#123; this.banana = banana; &#125;&#125; 上面的代码的确能够满足我们的需求，但就像上文所说的，这样的代码降低了代码的可重用性，那么我们要怎么优化呢，聪明的程序员们马上想到了，可以用Object来代替盘子里所指代的具体类型，就像下面这样 123456789101112public class ObjectPlant &#123; private Object object; public Object getObject() &#123; return object; &#125; public void setObject(Object object) &#123; this.object = object; &#125;&#125; 上面的代码看似完美解决了代码不可重用的问题，但同时也隐含了很多其他问题，例如在我们取数据的时候，取出来的只能是Object类型，需要我们强转类型，而往盘子中加入数据的时候，也没有任何验证，有可能往放苹果的盘子中加入了香蕉也说不定，因为编译器并没有做任何限制，只要是Object类型，都可以验证通过。 上面的问题在Java 1.5引入了泛型之后得到了完美的解决，下面让我们来看看用泛型如何优雅的解决上述问题 123456789101112public class Plant &lt;T&gt;&#123; private T t; public T getT() &#123; return t; &#125; public void setT(T t) &#123; this.t = t; &#125;&#125; 在上面的代码中，我们定义了一个泛型类，它表示了一个可以T类型的篮子，而这个T类型需要到我们真正使用的时候才会去指定 例如现在我们要定义两种盘子，可以这样声明 123456Plant&lt;Apple&gt; applePlant = new Plant&lt;&gt;();Plant&lt;Banana&gt; bananaPlant = new Plant&lt;&gt;();Apple apple = new Apple();Banana banana = new Banana();applePlant.set(banana); // 编译报错bananaPlant.set(apple); // 编译报错 上面的代码之所以实际类型new Plant&lt;&gt;()的&lt;&gt;中没有指明具体类型，是因为Java7之后加了类型自动推断，也就不需要两侧都加上泛型类型 可以看到使用了泛型之后，既提高了代码的可重用性，在实际使用时也对类型进行了约束，装苹果的盘子是装不了香蕉的！ 不过要注意的是，java的泛型约束是在编译时生效的，一旦编译成了class字节码文件后，一切都打回原形了，泛型信息会被擦除，所以我们把JAVA的泛型称为伪泛型，跟C#等语言的真泛型有着本质区别，在C#中，List&lt;Integer&gt;和List&lt;String&gt; 就是两种不同的类型 如下面字节码文件的最后一行invokevirtual命令的方法描述符Method setT:(Ljava/lang/Object;)V，可知泛型类型已经被擦除成了Object类型，也就是在字节码层面实际上与我们直接用Object来实现是一样的 1234567890: new #3 // class com/sunshine/common/test/Plant 3: dup 4: invokespecial #4 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: new #5 // class com/sunshine/common/test/Apple 12: dup 13: invokespecial #6 // Method com/sunshine/common/test/Apple.&quot;&lt;init&gt;&quot;:()V 16: invokevirtual #7 // Method setT:(Ljava/lang/Object;)V 泛型进阶使用 &lt;T extends ?&gt; 定义泛型类头一次看到上面两个符号，是不是有点懵逼？它们在代码里也非常常见，那么它们究竟是表示什么意思呢？还是通过上文的plant盘子来举例吧，举一种情况，我们只希望这个盘子用来装一些水果，而不希望它被用来装肉，那么我们该怎么做呢？现在的情况是，它既可以实例化成一个装香蕉的盘子，也可以被实例化成一个装肉的盘子 12Plant&lt;Apple&gt; applePlant = new Plant&lt;&gt;(); // Plant&lt;Meat&gt; meatPlant = new Plant&lt;&gt;(); // 都是Ok的 现在让我们来重新设计一个盘子类，通过&lt;T extends Firut&gt;来限制泛型，其实如果我们直接用&lt;T&gt;的编译成字节码后也会自动编译成&lt;T extends Object&gt; 123456789101112public class FirutPlant &lt;T extends Firut&gt;&#123; private T t; public T getT() &#123; return t; &#125; public void setT(T t) &#123; this.t = t; &#125;&#125; 使用 123FirutPlant&lt;Apple&gt; appleFirutPlant = new FirutPlant&lt;&gt;(); // OKFirutPlant&lt;Firut&gt; firutPlant = new FirutPlant&lt;&gt;(); // OKFirutPlant&lt;Meat&gt; meatFirutPlant = new FirutPlant&lt;&gt;(); // 编译无法通过 通过上面的代码可知我们成功的限制了泛型，水果盘子就只能装水果，盘子中的类型只能是水果或则它的子类型。 &lt;? extends T&gt; &lt;? super T&gt;注意这里的T是泛型参数，跟上面的 T不一样 看完上面的 &lt;T extends ?&gt;，接下来我们再来看&lt;? extends T&gt; &lt;? super T&gt;，可能这里你会非常疑惑，哇 这两个有什么区别？其实简单理解的话，&lt;T extends ?&gt;是在类文件层面就限制了泛型的范围，而&lt;? extends T&gt; &lt;? super T&gt;是在使用泛型的时候再去做限制。明白了这个之后接下来我们就来看下&lt;? extends T&gt; &lt;? super T&gt;的使用。 让我们回到Firut.class 123456789101112public class Plant &lt;T&gt;&#123; private T t; public T getT() &#123; return t; &#125; public void setT(T t) &#123; this.t = t; &#125;&#125; 我们现在不在定义泛型类的时候做限制，(使用&lt;T&gt;，其实这里还是相当于&lt;T extends Object&gt;)，而是在使用的是去做限制 下面我们来看下&lt;? extends T&gt;的使用 12345678Plant&lt;Apple&gt; applePlant = new Plant&lt;Apple&gt;();applePlant.setT(new Apple());// 使用 &lt;? extends T&gt;Plant&lt;? extends Firut&gt; plant = applePlant;plant.setT(new Apple()); // 无法存 编译报错plant.setT(new Firut()); // 无法存 编译报错Firut apple = plant.getT(); // 可以获取 可以看到当&lt;? extends T&gt;做为接收参数时，因为其必然是Firut的子类，这里实例类型是Apple，所以getT()方法仍然可以使用，因为会进行一次隐式的类型转换（向上转型是安全的），但是setT()方法是失效的，这是因为编译器不能确定你一定会往里面添加Apple类型，因为你还可以往里面添加Banana类型，显然Banana类型无法强转Apple类型，所以这里的setT()方法是失效的 下面我们来看下&lt;? super T&gt;的使用有了上面&lt;? extends T&gt;的使用经验，顾明思议，&lt;? super T&gt;必然表示T的全部父类型，还是再来看下&lt;? super T&gt;的使用吧 12345678Plant&lt;Firut&gt; firutPlant = new Plant&lt;&gt;();Plant&lt;? super Apple&gt; plant = firutPlant;plant.setT(new Apple()); // 可以存成功，不过这里只能存 Apple类型Apple apple = plant.getT(); // 编译报错Firut firut = firutPlant.getT(); 上面可以存成功的原因和上面&lt;? extends T&gt;可以取成功的原因一样，也是因为存在一个隐式的向上转型，而获取失败的原因 也很容易理解，因为实际类型肯定是Apple的父类（这里是Firut），所以要将Firut转成Apple显然是不可行的！ &lt;?&gt;&lt;?&gt;其实等价与&lt;? extends Object&gt;，这样子我相信就比较好理解了，跟&lt;? extends T&gt;类似，也是取可以，存被限制 &lt;T&gt;一般都是在定义泛型类或则泛型方法时出现，实际使用时都以?或具体类型替代T Type 与 Class 的区别和联系说起泛型，不得不提JDK在1.5之后引入的Type类型，显然Type是Java为了实现泛型而引入的。那么Type到底是什么呢，它表示的范围有多大？其实我们可以直接理解把Class当成是Type的子集，Class对应着jdk1.5之前不是泛型的原始类型 Type下包含了几种不同的类型 Class 原始类型，我这里直接理解成我们常用的Class类型，Class是Type的直接子类 ParameterizedType 参数化类型类似 List&lt;String&gt; list 获取list的类型 TypeVariable 类似 T t GenericArrayType 类似 List&lt;String&gt;[] 或则 List&lt;T&gt; [] GenericArrayType 接口只有一个方法getGenericComponentType，用户返回ParameterizedType或则TypeVariable类型 WildcardType 类似 &lt;? super T&gt; 要得到这个类型，首先需要得到ParameterizedType类型，然后通过getActualTypeArguments方法获取WildcardType类型 说了这么多，还是通过实际的代码来详细解释吧 123456789public class TypeTest &#123; public void testOne(Plant&lt;Apple&gt; plant, Plant&lt;Apple&gt; [] plants, Plant&lt;? extends Apple&gt; applePlant) &#123; &#125; public &lt;T&gt; void testOne(T t) &#123; &#125;&#125; 写段测试代码 12345678910111213141516171819202122232425262728293031323334353637Method [] methods = TypeTest.class.getMethods();for (Method method : methods) &#123; if (method.getName().equals("testOne")) &#123; Type [] parameterTypes = method.getGenericParameterTypes(); System.out.println("methodOne start --------&gt; "); for (Type type : parameterTypes) &#123; if (type instanceof Class) &#123; System.out.println("Class ---- " + type.getTypeName()); &#125; if (type instanceof ParameterizedType) &#123; System.out.println("ParameterizedType ---- " + type.getTypeName()); Type ytpe3[] = ((ParameterizedType) type).getActualTypeArguments(); for (Type type2 : ytpe3) &#123; if (type2 instanceof WildcardType) &#123; System.out.println("ParameterizedType-WildcardType ---- " + type2.getTypeName()); &#125; &#125; &#125; if (type instanceof GenericArrayType) &#123; System.out.println("GenericArrayType ---- " + type.getTypeName()); Type type2 = ((GenericArrayType) type).getGenericComponentType(); &#125; if (type instanceof TypeVariable) &#123; System.out.println("TypeVariable ---- " + type.getTypeName()); &#125; &#125; &#125; else if (method.getName().equals("testTwo")) &#123; Type [] parameterTypes = method.getGenericParameterTypes(); System.out.println("methodTwo start --------&gt; "); for (Type type : parameterTypes) &#123; if (type instanceof TypeVariable) &#123; System.out.println("TypeVariable ---- " + type.getTypeName()); &#125; &#125; &#125;&#125; 输出 1234567methodTwo start --------&gt; TypeVariable ---- TmethodOne start --------&gt; ParameterizedType ---- com.sunshine.common.test.Plant&lt;com.sunshine.common.test.Apple&gt;GenericArrayType ---- com.sunshine.common.test.Plant&lt;com.sunshine.common.test.Apple&gt;[]ParameterizedType ---- com.sunshine.common.test.Plant&lt;? extends com.sunshine.common.test.Apple&gt;ParameterizedType-WildcardType ---- ? extends com.sunshine.common.test.Apple 什么情况可以拿到泛型类型先看可以拿到泛型的情形，与上面的例子一样，我们可以获取方法入参，超类的参数化类型，举个例子 123456789101112131415class SuperPlant extend Plant&lt;Apple&gt; &#123; public void addAll(List&lt;Apple&gt; apples) &#123; // do something &#125; public static void main(String[] args) &#123; // 获取父类参数化类型 Type type = SuperPlant.class.getGenericSuperclass(); Method[] methods = SuperPlant.class.getMethods(); for (Method method : methods) &#123; // 获取方法参数化类型 Type[] types = method.getGenericParameterTypes(); &#125; &#125;&#125; 可以发现以上代码是可以获取到泛型类型。通过getGenericSuperclass获取到父类的参数化类型，method的getGenericParameterTypes获取到入参的参数化类型数组。 再看一种情况1234public void testMethod() &#123; Plant&lt;Firut&gt; firutPlant = new Plant&lt;&gt;(); // 这里可以拿到 firutPlant 对象的泛型吗?&#125; 上面的例子中，我们是拿不到 firutPlant 的泛型的，因为JAVA 在将其编译成字节码的时候，实际上会变成 Plant&lt;Object&gt;类型，泛型会被擦除。 所以我们其实是无法在运行时通过泛型对象本身拿到泛型类型的，那么有没有黑科技可以拿到运行时泛型本身的泛型信息？上面有提到，我们拿泛型可以通过子类来获取父类的泛型我们依据这个思路将上面例子修改一下 123public void testMethod() &#123; Type type = new Plant&lt;Firut&gt;() &#123;&#125;.getClass().getGenericSuperclass();&#125; 其实就是将Plant改成了匿名类方式实现，这种方式可以拿到Plant的泛型信息吗？答案是可以的这里通过getGenericSuperclass拿到的就是Plant 的泛型类型信息。其实这种方式在很多框架源码里很常见，通过匿名类方式获取参数类型，感兴趣的可以看下Gson的TypeToken的实现，也是一样的原理。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java字节码方法表]]></title>
    <url>%2F2019%2F04%2F25%2FJava%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%B9%E6%B3%95%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[引言因为字段表和方法表的结构类似，所以我们直接分析Java字节码的方法表内容，理解了方法表，自然就理解了字段表 方法表方法表在Class文件中的位置是在字段表之后的，具体的结构我们根据下表再来回顾一下 类型 名称 数量 u2 access_flas 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info 属性表 attributes_count 还是跟上篇文章一样，我们写一个简单的Java类 1234567891011121314151617181920public class Test &#123; public String sayHello() &#123; String sayStr = "hello world"; return sayStr; &#125; public static void main(String[] args) &#123; Test test = new Test(); System.out.println(test.sayHello()); &#125;&#125; 使用javap翻译字节码文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206public class com.ymm.agent.Test minor version: 0 major version: 52 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #3 // com/ymm/agent/Test super_class: #8 // java/lang/Object interfaces: 0, fields: 0, methods: 3, attributes: 1Constant pool: #1 = Methodref #8.#27 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = String #28 // hello world #3 = Class #29 // com/ymm/agent/Test #4 = Methodref #3.#27 // com/ymm/agent/Test.&quot;&lt;init&gt;&quot;:()V #5 = Fieldref #30.#31 // java/lang/System.out:Ljava/io/PrintStream; #6 = Methodref #3.#32 // com/ymm/agent/Test.sayHello:()Ljava/lang/String; #7 = Methodref #33.#34 // java/io/PrintStream.println:(Ljava/lang/String;)V #8 = Class #35 // java/lang/Object #9 = Utf8 &lt;init&gt; #10 = Utf8 ()V #11 = Utf8 Code #12 = Utf8 LineNumberTable #13 = Utf8 LocalVariableTable #14 = Utf8 this #15 = Utf8 Lcom/ymm/agent/Test; #16 = Utf8 sayHello #17 = Utf8 ()Ljava/lang/String; #18 = Utf8 sayStr #19 = Utf8 Ljava/lang/String; #20 = Utf8 main #21 = Utf8 ([Ljava/lang/String;)V #22 = Utf8 args #23 = Utf8 [Ljava/lang/String; #24 = Utf8 test #25 = Utf8 SourceFile #26 = Utf8 Test.java #27 = NameAndType #9:#10 // &quot;&lt;init&gt;&quot;:()V #28 = Utf8 hello world #29 = Utf8 com/ymm/agent/Test #30 = Class #36 // java/lang/System #31 = NameAndType #37:#38 // out:Ljava/io/PrintStream; #32 = NameAndType #16:#17 // sayHello:()Ljava/lang/String; #33 = Class #39 // java/io/PrintStream #34 = NameAndType #40:#41 // println:(Ljava/lang/String;)V #35 = Utf8 java/lang/Object #36 = Utf8 java/lang/System #37 = Utf8 out #38 = Utf8 Ljava/io/PrintStream; #39 = Utf8 java/io/PrintStream #40 = Utf8 println #41 = Utf8 (Ljava/lang/String;)V&#123; public com.ymm.agent.Test(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 9: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/ymm/agent/Test; public java.lang.String sayHello(); descriptor: ()Ljava/lang/String; flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=2, args_size=1 0: ldc #2 // String hello world 2: astore_1 3: aload_1 4: areturn LineNumberTable: line 12: 0 line 13: 3 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/ymm/agent/Test; 3 2 1 sayStr Ljava/lang/String; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: new #3 // class com/ymm/agent/Test 3: dup 4: invokespecial #4 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 11: aload_1 12: invokevirtual #6 // Method sayHello:()Ljava/lang/String; 15: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 18: return LineNumberTable: line 17: 0 line 18: 8 line 19: 18 LocalVariableTable: Start Length Slot Name Signature 0 19 0 args [Ljava/lang/String; 8 11 1 test Lcom/ymm/agent/Test;&#125;SourceFile: &quot;Test.java&quot; 通过上文的interfaces: 0, fields: 0, methods: 3, attributes: 1，我们可以知道该文件一共包含3个方法，分别对应着无参构造,sayHello,main三个方法 好了，现在让我们直接略过前面的一大推常量池项， 直接阅读我们自己写的sayHello方法的字节码内容 1234567891011121314151617181920212223242526272829303132public java.lang.String sayHello(); descriptor: ()Ljava/lang/String; /* 方法描述符 */ flags: (0x0001) ACC_PUBLIC /* 访问标识 */ Code: /* code属性 也就是我们写的具体代码翻译成的字节码指令内容 */ stack=1, locals=2, args_size=1 /* 分别指操作数栈深度；本地变量所需的存储空间（slot为单位）；参数个数 */ 0: ldc #2 // String hello world /*将一个常量加载到操作数栈*/ 2: astore_1 /* 将一个数值从操作数栈存储到局部变量表 */ 3: aload_1 /* 将一个数值从局部变量表加载到操作数栈 */ 4: areturn /* 将栈顶第一个元素返回 */ LineNumberTable: /* 字节码与java代码行数对应关系 一般用于调试 */ line 12: 0 line 13: 3 LocalVariableTable: /* 局部变量表 */ Start Length Slot Name Signature 0 5 0 this Lcom/ymm/agent/Test; 3 2 1 sayStr Ljava/lang/String; 根据上表我们知道方法表的第一个内容的是access_flas，占一个字节。表中的access_flas其实就对应着上文中的 flags: (0x0001) ACC_PUBLIC，标识这个方法是public的，接下在的name_index和descriptor_index，在上文中的体现分别对应着sayHello和()Ljava/lang/String;。 这里解释一下描述符的概念，在介绍Class文件结构的文章中有提到，这里再提一遍: 描述符的作用是用来描述字段的数据类型，方法的参数列表和返回值，根据描述符规则，基本数据类型（byte,char,int,long,float,double,short,boolean）以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用L加对象的全限定名来表示 最重要的内容其实还是在attribute_info属性表中的code内容，也就是我们写的具体代码翻译成的字节码指令内容，这块内容是我们阅读字节码文件的重中之重。下面我们就来阅读一下上文的字节码内容 ldc #2 将常量池中索引为2的字符串加载到操作数栈顶 astore_1 将一个数值从操作数栈存储到局部变量表 aload_1 将一个数值从局部变量表加载到操作数栈 areturn 将栈顶第一个元素返回 可以看到上面的四个步骤的操作其实都是基于栈的操作，这里提一下java虚拟机栈的栈帧结构 关于字节码子令集可以参考java字节码子令集 有趣的例子 —下面我们再来看一个有趣的例子，大家思考一下这个执行这个方法的返回值会是多少？ 12345678910111213141516171819202122232425262728public class Test &#123; public int inc() &#123; int x; try &#123; x = 1; return x; &#125; catch (Exception e) &#123; x = 2; return x; &#125; finally &#123; x = 3; &#125; &#125;&#125; 代码非常简单，我想大家应该也都知道正确答案，当没有出现异常的时候，返回值为1，出现异常的话则为2（当然这里不会抛异常）。可是如果我们在finally快里加句代码System.out.prinln(&quot;do it&quot;)，然后再执行这个方法，其实是可以看到do it被打印了，也就是说在执行return之前，finally快中的代码是被执行了的，那么这里就有一个有趣的问题了，为何返回仍然是2而不是3呢？ 下面我们就从字节码文件中来找出答案 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public int inc(); descriptor: ()I flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=5, args_size=1 0: iconst_1 // 将int = 1的值压入栈顶 1: istore_1 // 弹出栈顶元素，存入位置为1的局部变量表 2: iload_1 // 从位置为1的局部变量中取出元素压入栈顶 3: istore_2 // 弹出栈顶元素，存入位置2的局部变量中 4: iconst_3 // 将int = 3的值压入栈顶 （这里执行finally块中的代码了） 5: istore_1 // 弹出栈顶元素，存入位置1的局部变量中 6: iload_2 // 从位置为2的局部变量中取出元素压入栈顶 7: ireturn // 返回栈顶元素2 (哈哈哈 看到没有，这里返回的是2，没有异常的话，这里方法就返回了) 8: astore_2 // 将栈顶的异常引用，存入位置2的局部变量中 （这里就是异常捕获的代码了） 9: iconst_2 // 将int = 2的值压入栈顶 10: istore_1 // 弹出栈顶元素，存入位置1的局部变量中 11: iload_1 // 从位置为1的局部变量中取出元素压入栈顶 12: istore_3 // 弹出栈顶元素，存入位置3的局部变量中 13: iconst_3 // 将int = 3的值压入栈顶 14: istore_1 // 弹出栈顶元素，存入位置1的局部变量中 15: iload_3 // 从位置为3的局部变量中取出元素压入栈顶 16: ireturn // 返回栈顶元素 2 17: astore 4 // 将栈顶异常引用存入位置为4的局部变量表中 19: iconst_3 // 将int = 3的值压入栈顶 20: istore_1 // 弹出栈顶元素，存入位置1的局部变量中 21: aload 4 将位置为4的局部变量引用压入栈顶 23: athrow // 将栈顶的异常抛出 Exception table: // 异常表 from to target type 0 4 8 Class java/lang/Exception 0 4 17 any 8 13 17 any 17 19 17 any 如果你已经看懂了上面的字节码，你应该会豁朗开朗。原因其实就是在于这里开辟了两个局部变量，finally块中的代码也确实执行了，只是将变量存入了局部变量表中的另一个位置，并且通过这个例子，也可以发现，无论什么情况finally块中的代码都会执行。 尾言好了，本文到这里就差不多结束了。对于字节码的探索个人觉的还是非常有意思的，之后应该也会探索更多有意思的东西]]></content>
      <categories>
        <category>java基础</category>
        <category>JVM</category>
        <category>java字节码</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>java字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Java NIO实现一个HTTP服务器]]></title>
    <url>%2F2019%2F04%2F19%2F%E4%BD%BF%E7%94%A8Java-NIO%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AAHTTP%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引言一直以来都想写一个自己的http服务器，这次趁着稍微空闲了一些，赶紧码了一个mini版的。在这里跟大家分享一下编写的整个思路，总体来说，整个应用非常简单，目前也只是实现了最基本的静态资源访问，但对于想学习Http协议的同学来说，应该还是有所帮助 HTTP协议先简单介绍一下HTTP协议，HTTP协议是构建于TCP/IP协议之上的一个应用层协议，并且是无连接无状态的。 http请求报文http的请求报文由三部分组成 状态行 &lt;method&gt; &lt;request-URL&gt; &lt;version&gt; method包含GET，POST，PUT，DELETE等 请求头 消息主体 下面是典型的http请求报文示例 123456789101112131415161718GET /static/home.html HTTP/1.1Host: localhost:8080Connection: keep-aliveCache-Control: max-age=0Upgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3Accept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9 http响应报文响应报文跟请求报文类似，也由三部分组成 状态行 这里需要关注下响应的各个状态所代表的含义，以及浏览器识别这些状态码会相应的做哪些事情 响应头 响应正文 12345678HTTP/1.1 200 OKServer: cloud http v1.0Content-Type: text/html;charset=UTF-8&lt;html&gt;... ## 动手 前面简单介绍了一下http协议的基本信息，下面就是源码实现了，我这里直接使用了Java NIO作为底层通信支撑，在实际的生产代码中，大多会选择封装良好的netty来作为稳定的底层通信 这里先放上项目源码 CloudHttp 定义Request和Response Request 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Request &#123; /** * method */ private String method; /** * http协议版本 */ private String httpVersion; /** * 请求uri */ private String uri; /** * 请求相对路径 */ private String path; /** * 请求头信息 */ private Map&lt;String, String&gt; headers; /** * 请求参数 */ private Map&lt;String, String&gt; attribute;&#125; Response 12345678910111213141516171819202122232425262728public class Response &#123; private Integer code; private String protocol = "HTTP/1.1"; private String msg; private Map&lt;String, String&gt; headers; private ByteArrayOutputStream outPutStream = new ByteArrayOutputStream(); public Response() &#123; this.code = HttpCode.STATUS_200.getCode(); this.msg = HttpCode.STATUS_200.getMsg(); headers = new HashMap&lt;&gt;(); headers.put("Content-Type", "text/html;charset=UTF-8"); headers.put("Server", "cloud http v1.0"); &#125;&#125; 定义请求响应解析类 HttpParser 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176public class HttpParser &#123; private final static Logger logger = LoggerFactory.getLogger(HttpParser.class); /** * &lt;p&gt;解析http请求体&lt;/p&gt; * * @param buffers * @return */ public static Request decodeReq(byte [] buffers) &#123; Request request = new Request(); if (buffers != null) &#123; String resString = new String(buffers); logger.info(resString); String[] headers = resString.trim().split("\r\n"); if (headers.length &gt; 0) &#123; String firstline = headers[0]; // 按空格分割字符串 // 解析 method uri 协议版本 String mainInfo [] = firstline.split("\\s+"); request.setMethod(mainInfo[0]); try &#123; request.setUri(URLDecoder.decode(mainInfo[1], "UTF-8")); &#125; catch (UnsupportedEncodingException e) &#123; logger.error("error_HttpParser_URLDecode, uri = &#123;&#125;", mainInfo[1], e); &#125; request.setHttpVersion(mainInfo[2]); // 解析header Map&lt;String, String&gt; headersMap = new HashMap&lt;&gt;(); for (int i = 1; i &lt; headers.length; i++) &#123; String entryStr = headers[i]; String entry [] = entryStr.trim().split(":"); headersMap.put(entry[0].trim(), entry[1].trim()); &#125; request.setHeaders(headersMap); // 解析参数 String uri = request.getUri(); Map&lt;String, String&gt; attribute = new HashMap&lt;&gt;(); request.setPath(uri); if (StringUtils.isNotEmpty(uri)) &#123; int indexOfParam = uri.indexOf("?"); if (indexOfParam &gt; 0) &#123; // 设置path request.setPath(uri.substring(0, indexOfParam)); String queryString = uri.substring(indexOfParam + 1, uri.length()); String paramEntrys [] = queryString.split("&amp;"); for (String paramEntry : paramEntrys) &#123; String [] entry = paramEntry.split("="); if (entry.length &gt; 0) &#123; String key = entry[0]; String value = entry.length &gt; 1 ? entry[1] : ""; attribute.put(key, value); &#125; &#125; &#125; &#125; request.setAttribute(attribute); &#125; &#125; return request; &#125; /** * &lt;p&gt;返回http响应字节流&lt;/p&gt; * * @param response * @return */ public static byte[] encodeResHeader(Response response) &#123; StringBuilder resBuild = new StringBuilder(); resBuild.append(response.getProtocol() + " " + response.getCode() + " " + response.getMsg()); resBuild.append("\r\n"); Map&lt;String, String&gt; headers = response.getHeaders(); headers.entrySet().forEach(entry -&gt; &#123; resBuild.append(entry.getKey()); resBuild.append(": "); resBuild.append(entry.getValue()); resBuild.append("\r\n"); &#125;); resBuild.append("\r\n"); String resString = resBuild.toString(); byte [] bytes = null; try &#123; bytes = resString.getBytes("UTF-8"); &#125; catch (UnsupportedEncodingException e) &#123; logger.error("error_encodeResHeader", e); &#125; return bytes; &#125;&#125; 使用Java nio 启动服务器 NioServer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246public class NioServer implements Server, Runnable &#123; private final static Logger logger = LoggerFactory.getLogger(NioServer.class); private Thread serverThread; private Integer port; private boolean running = false; private static volatile NioServer server; private CloudService cloudService; private ServerSocketChannel serverSocketChannel; private ByteBuffer readBuffer = ByteBuffer.allocate(8192); public static final ExecutorService requestWork = Executors.newCachedThreadPool(); public static NioServer getServerInstance () &#123; if (server == null) &#123; synchronized (NioServer.class) &#123; if (server == null) &#123; server = new NioServer(); &#125; &#125; &#125; return server; &#125; public NioServer() &#123; this.cloudService = new CloudService(); port = Integer.valueOf(CloudHttpConfig.getValue("port", "8080")); &#125; @Override public synchronized void start() &#123; if (running) &#123; logger.info("服务器已经启动"); return; &#125; serverThread = new Thread(this); serverThread.start(); this.running = true; &#125; @Override public void stop() &#123; try &#123; serverSocketChannel.close(); serverThread.stop(); &#125; catch (IOException e) &#123; logger.error("error_NioServer_stop", e); &#125; &#125; @Override public void run() &#123; try &#123; //打开ServerSocketChannel通道 serverSocketChannel = ServerSocketChannel.open(); //得到ServerSocket对象 serverSocketChannel.socket().bind(new InetSocketAddress(port)); Selector selector = Selector.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; selector.select(); Iterator&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys().iterator(); SelectionKey key = null; while (selectedKeys.hasNext()) &#123; key = selectedKeys.next(); selectedKeys.remove(); if (!key.isValid()) &#123; continue; &#125; if (key.isAcceptable()) &#123; accept(key); &#125; if (key.isReadable()) &#123; read(key); &#125; if (key.isWritable()) &#123; write(key); &#125; &#125; &#125; &#125; catch (IOException e) &#123; logger.error("error_NioServer_run", e); &#125; &#125; private void accept(SelectionKey key) &#123; try &#123; ServerSocketChannel serverSocketChannel = (ServerSocketChannel)key.channel(); SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); socketChannel.register(key.selector(), SelectionKey.OP_READ); &#125; catch (IOException e) &#123; logger.error("error_NioServer_accept", e); &#125; &#125; private Request read(SelectionKey key) &#123; Request request = null; SocketChannel socketChannel = (SocketChannel) key.channel(); try &#123; int readNum = socketChannel.read(readBuffer); if (readNum == -1) &#123; socketChannel.close(); key.cancel(); return null; &#125; readBuffer.flip(); byte [] buffers = new byte[readBuffer.limit()]; readBuffer.get(buffers); readBuffer.clear(); request = HttpParser.decodeReq(buffers); requestWork.execute(new RequestWorker(request, key, cloudService)); &#125; catch (IOException e) &#123; logger.error("error_NioServer_read", e); &#125; return request; &#125; private void write(SelectionKey key) throws IOException &#123; ByteBuffer buffer = (ByteBuffer) key.attachment(); if(buffer == null || !buffer.hasRemaining()) &#123; return; &#125; SocketChannel socketChannel = (SocketChannel) key.channel(); socketChannel.write(buffer); if(!buffer.hasRemaining())&#123; key.interestOps(SelectionKey.OP_READ); buffer.clear(); &#125; socketChannel.close(); &#125;&#125; 处理请求的 RequestWork类对于每一个进入的请求。都会单独启动一个线程来进行处理 RequestWorker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public class RequestWorker implements Runnable &#123; private final static Logger logger = LoggerFactory.getLogger(RequestWorker.class); private Request request; private SelectionKey key; private SocketChannel channel; private CloudService cloudService; public RequestWorker(Request request, SelectionKey key, CloudService cloudService) &#123; this.request = request; this.key = key; this.channel = (SocketChannel) key.channel(); this.cloudService = cloudService; &#125; @Override public void run() &#123; Response response = new Response(); try &#123; cloudService.doService(request, response); &#125; catch (ViewNotFoundException e) &#123; response.setCode(HttpCode.STATUS_404.getCode()); response.setMsg(HttpCode.STATUS_404.getMsg()); ByteArrayOutputStream outputStream = response.getOutPutStream(); InputStream inputStream = this.getClass().getClassLoader().getResourceAsStream("404.html"); byte bytes [] = new byte [1024]; int len; try &#123; while ((len = inputStream.read(bytes)) &gt; -1) &#123; outputStream.write(bytes, 0, len); &#125; &#125; catch (IOException e1) &#123; logger.error("error_requestWork_write404", e); &#125; &#125; byte [] resHeader = HttpParser.encodeResHeader(response); byte [] body = response.getOutPutStream().toByteArray(); ByteBuffer byteBuffer = ByteBuffer.allocate(resHeader.length + body.length); byteBuffer.put(resHeader); byteBuffer.put(body); byteBuffer.flip(); // 将输出流绑定至附件 key.attach(byteBuffer); // 注册写事件 key.interestOps(SelectionKey.OP_WRITE); key.selector().wakeup(); &#125;&#125; 定义Servlet接口 CloudServlet 12345678910111213141516171819202122232425262728293031323334353637383940public interface CloudServlet &#123; /** * 判断当前请求是否匹配 handler * * @param request * @return */ boolean match(Request request); /** * 执行初始化 */ void init(Request request, Response response); /** * 执行请求 * * @param request * @param response */ void doService(Request request, Response response);&#125; StaticViewServlet 定义一个处理静态资源的StaticViewServlet实现CloudServlet接口 该静态资源处理器会自动拦截static路径下的请求 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class StaticViewServlet implements CloudServlet &#123; private final static Logger logger = LoggerFactory.getLogger(StaticViewServlet.class); private String staticRootPath; public static Pattern p = Pattern.compile("^/static/\\S+"); @Override public boolean match(Request request) &#123; String path = request.getPath(); Matcher matcher = p.matcher(path); return matcher.matches(); &#125; @Override public void init(Request request, Response response) &#123; staticRootPath = CloudHttpConfig.getValue("static.resource.path"); &#125; @Override public void doService(Request request, Response response) &#123; String path = request.getPath(); String fileRelativePath = path.substring(8); String absolutePath = staticRootPath + "/" + fileRelativePath; RandomAccessFile randomAccessFile = null; try &#123; randomAccessFile = new RandomAccessFile(absolutePath, "r"); FileChannel fileChannel = randomAccessFile.getChannel(); ByteBuffer htmBuffer = ByteBuffer.allocate((int)fileChannel.size()); fileChannel.read(htmBuffer); htmBuffer.flip(); byte [] htmByte = new byte[htmBuffer.limit()]; htmBuffer.get(htmByte); response.getOutPutStream().write(htmByte); &#125; catch (FileNotFoundException e) &#123; throw new ViewNotFoundException(); &#125; catch (IOException e) &#123; logger.error("error_StaticViewServlet_doService 异常", e); &#125; &#125;&#125; 定义 CloudServiceCloudService是用于盛放Servlet的容器 12345678910111213141516171819202122232425262728293031323334353637383940public class CloudService &#123; private List&lt;CloudServlet&gt; cloudServlets = new ArrayList&lt;&gt;(); public CloudService() &#123; cloudServlets.add(new StaticViewServlet()); cloudServlets.add(new MappingUrlServlet()); &#125; public void doService(Request request, Response response) &#123; CloudServlet servlet = doSelect(request); servlet.init(request, response); servlet.doService(request, response); &#125; private CloudServlet doSelect(Request request) &#123; for (CloudServlet cloudServlet : cloudServlets) &#123; if (cloudServlet.match(request)) &#123; return cloudServlet; &#125; &#125; return new MappingUrlServlet(); &#125;&#125; 最后 编写启动类12345678910111213141516171819202122public class CloudHttpServer &#123; /** * 启动服务器 */ public static void startServer() &#123; NioServer.getServerInstance().start(); &#125; public static void main(String[] args) &#123; startServer(); &#125;&#125; 测试 启动服务器 浏览器访问 http://localhost:8080/static/home.html 响应页面 尾言本文只是一个示例，仅仅实现了静态资源访问。做为自娱自乐的项目 +——=]]></content>
      <categories>
        <category>NIO</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>NIO</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java字节码常量池]]></title>
    <url>%2F2019%2F04%2F17%2FJava%E5%AD%97%E8%8A%82%E7%A0%81%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[引言上篇文章简单介绍了java Class 字节码文件的基本格式。本文我们直接通过阅读字节码文件来进一步理解字节码中的常量池结构 首先我们新建一个最简单的Java文件 12345public class Test &#123; public static void main(String[] args) &#123; System.out.println("hello world"); &#125;&#125; 编译之后使用文本编辑器打开，可以看到Class文件最原始的16进制格式。最明显的Class文件的魔数cafe babe一眼就能看到 12345678910111213141516171819202122232425262728293031323334cafe babe 0000 0034 0022 0a00 0600 14090015 0016 0800 170a 0018 0019 0700 1a07001b 0100 063c 696e 6974 3e01 0003 28295601 0004 436f 6465 0100 0f4c 696e 654e756d 6265 7254 6162 6c65 0100 124c 6f63616c 5661 7269 6162 6c65 5461 626c 65010004 7468 6973 0100 144c 636f 6d2f 796d6d2f 6167 656e 742f 5465 7374 3b01 00046d61 696e 0100 1628 5b4c 6a61 7661 2f6c616e 672f 5374 7269 6e67 3b29 5601 00046172 6773 0100 135b 4c6a 6176 612f 6c616e67 2f53 7472 696e 673b 0100 0a53 6f757263 6546 696c 6501 0009 5465 7374 2e6a6176 610c 0007 0008 0700 1c0c 001d 001e0100 0b68 656c 6c6f 2077 6f72 6c64 07001f0c 0020 0021 0100 1263 6f6d 2f79 6d6d2f61 6765 6e74 2f54 6573 7401 0010 6a617661 2f6c 616e 672f 4f62 6a65 6374 0100106a 6176 612f 6c61 6e67 2f53 7973 74656d01 0003 6f75 7401 0015 4c6a 6176 612f696f 2f50 7269 6e74 5374 7265 616d 3b010013 6a61 7661 2f69 6f2f 5072 696e 74537472 6561 6d01 0007 7072 696e 746c 6e010015 284c 6a61 7661 2f6c 616e 672f 53747269 6e67 3b29 5600 2100 0500 0600 00000000 0200 0100 0700 0800 0100 0900 00002f00 0100 0100 0000 052a b700 01b1 00000002 000a 0000 0006 0001 0000 0009 000b0000 000c 0001 0000 0005 000c 000d 00000009 000e 000f 0001 0009 0000 0037 00020001 0000 0009 b200 0212 03b6 0004 b1000000 0200 0a00 0000 0a00 0200 0000 0b000800 0c00 0b00 0000 0c00 0100 0000 09001000 1100 0000 0100 1200 0000 0200 13 如何从上面的文件中找到常量池所在的位置呢在上篇文章中我们已经分析过Class文件文件格式了，常量池的位置紧随在版本号之后，也就是从第9个字节开始就是常量池的内容了，下面就让我们一起来看下常量池的具体内容 constant_pool_count u2从第9个字节开始往后的两个字节，是constant_pool_count，我们把它叫做常量计数器，比较特殊的是它的下标是从1开始的，也就是说真正的常量池数量是constant_pool_count - 1个，那好现在让我们来看看上面的那个普通Class文件包含了多少个常量表（cp_info） 可以看到constant_pool_count标识位是0022，转为10进制就是34。也就是说包含34 - 1 = 33个常量表内容 cp_info上文经过分析我们已经确定了字节码文件包含的常量表个数，那么接下来我们要具体怎么看呢？ 下面让我们来具体分析下cp_info的结构 可以看到每个cp_info的第一个字节位都是tag，用于标识常量表所属的具体类型，上篇文章我们说过，常量表之所以非常复杂，就是因为它的类型众多，有多大14种类型。那么这些类型的区分就是通过tag来区分。我们会逐个分析这14种类型 先来看下这14常量池类型 还是回到上述字节码的16进制文件，我们接着往下看 可以看到tag = 10，根据上文我们列出的细分类型可以确定这第一个出现的常量表类型是constant_Methodref_info。那好现在我们再去具体的看下constant_Methodref_info表的具体内容 可以看到紧跟在tag之后其实是两项index索引值，分别指向constant_Class_info和constant_NameAndType_info。 继续往下阅读，可以知道具体的索引值分别为0006，0014。也就是指向常量池的第6项和第20项 下面为了方便阅读，我们直接使用javap -v Test命令生成方便我们阅读的字节码文件，当然如果有兴趣的话，直接阅读源文件也是oK的 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class com.ymm.agent.Test minor version: 0 major version: 52 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #5 // com/ymm/agent/Test super_class: #6 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1Constant pool: #1 = Methodref #6.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #21.#22 // java/lang/System.out:Ljava/io/PrintStream; #3 = String #23 // hello world #4 = Methodref #24.#25 // java/io/PrintStream.println:(Ljava/lang/String;)V #5 = Class #26 // com/ymm/agent/Test #6 = Class #27 // java/lang/Object #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/ymm/agent/Test; #14 = Utf8 main #15 = Utf8 ([Ljava/lang/String;)V #16 = Utf8 args #17 = Utf8 [Ljava/lang/String; #18 = Utf8 SourceFile #19 = Utf8 Test.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = Class #28 // java/lang/System #22 = NameAndType #29:#30 // out:Ljava/io/PrintStream; #23 = Utf8 hello world #24 = Class #31 // java/io/PrintStream #25 = NameAndType #32:#33 // println:(Ljava/lang/String;)V #26 = Utf8 com/ymm/agent/Test #27 = Utf8 java/lang/Object #28 = Utf8 java/lang/System #29 = Utf8 out #30 = Utf8 Ljava/io/PrintStream; #31 = Utf8 java/io/PrintStream #32 = Utf8 println #33 = Utf8 (Ljava/lang/String;)V&#123; public com.ymm.agent.Test(); descriptor: ()V.... 省略其他字节码 通过javap 生成的字节码文件，看起来就舒服多了。现在继续回到第一个常量池项constant_Methodref_info，可以知道它是由constant_Class_info，constant_NameAndType_info两项的索引值组成，根据索引值6,20我们可以找到具体常量池项内容。 先找到索引值为6的constant_Class_info的内容，可以发现其具体内容也是指向了一个索引值27，继续找索引值为27常量项 找到索引值为27的常量项，可以发现是一个constant_utf8_info类型的字符串(java/lang/Object)，这也就是我们之前提到的类的全限定名称 到目前为止大家应该已经找到了阅读常量池的感觉了，那么我们去查看索引项为20的constant_NameAndType_info的方法也是一样的 constant_NameAndType_info指向索引值为7和8的内容 可以知道方法名称为init，类型为void方法 到目前为止我们大概可以知道此常量池的第一项表示其实是一个无参的构造方法，并且是编译器为我们自动生成的 其实大多数复杂的常量池内容最终都会索引到一个constant_utf8_info字符串类型，用于描述类全限定名，方法或字段名称及描述符等等 .. 尾言本篇文章我们只是通过一个示例来阅读Class文件的常量池内容，具体的常量池结构在上篇文章中我们都有列出，并且阅读的方法也是与本文类似。]]></content>
      <categories>
        <category>java基础</category>
        <category>JVM</category>
        <category>java字节码</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>java字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Class文件结构]]></title>
    <url>%2F2019%2F04%2F04%2FJava-Class%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[引言我们都知道java是跨平台的，原因就在于各个平台的java虚拟机可以载入和执行同一种平台无关的字节码文件，也就是说java虚拟机不与包括Java在内的任何语言绑定，只于Class文件这种二进制格式文件所关联。 基于这样的设计，到目前为止已经出现了很多基于Java虚拟机的语言 如groovy最终都会编译成class文件 Class文件结构一个Class文件唯一对应一个类或接口 现在让我们来看下Class文件的基本结构 Class文件以8位字节为基本单位的二进制文件，各个数据项目严格的按照顺序紧凑的排列在Class文件之中，中间没有任何分隔符，这使得整个Class文件中存储的内容几乎全部是运行时的必要数据 Class文件的二进制文件只有两种数据类型：无符号数和表，后面的解析都会以这两种数据类型为基础 无符号数 无符号数是最基本的数据类型，以u1,u2,u4,u8来分别代表1个字节，2个字节，4个字节，8个字节的无符号数，无符号数用来描述数字，索引引用，数量值，以及以UTF-8编码的字符串 表 表则是由多个无符号数或其他表组成的复合数据结构，表的名称一般以_info结尾。所以整个Class文件其实就是一张特殊的表 下面表中所列的就是一个Class按顺序排列的数据结构 类型 名称 数量 u4 magic 魔数 标识Class文件 1 u2 minor_version 次版本号 1 u2 major_version 主版本号 1 u2 constant_pool_count 常量表集合数量 1 cp_info constant_pool 常量表 constant_pool_count - 1 u2 access_flag 访问标识 1 u2 this_class 类索引 1 u2 super_class 父类索引 1 u2 interfaces_count 接口索引数量 1 u2 interfaces 接口索引 interfaces_count u2 fields_count 字段表集合数量 1 field_info fields 字段表 fields_count u2 methods_count 方法表集合数量 1 method_info methods 方法表 methods_count u2 attributes_count 属性表集合数量 1 attribute_info attributes 属性表 attributes_count 下面依次来解读表中每个类型 魔数和版本号头4个字节称为Class文件的魔数，魔数的作用是标识此文件能被Java虚拟机接受的Class文件，其实不止Class文件有魔数这个概念，包括其他很多文件格式出于安全的考虑也都会有魔数这个概念，魔数都是固定不变的，如Class文件的魔数就是cafebabe 紧接着魔数之后的是版本号，第5 6个字节表示的是次版本号，第7 8个字节表示的是主版本号。版本号都是向下兼容的 常量池表读懂常量池表对于阅读Class字节码非常重要，下面我们将以大篇幅分析常量池表 常量池是Class文件中出现的第一个表结构类型，同时也是占用Class文件最大空间的类型之一。由于常量池表的数量不是固定的，所以在常量池的入口有一项u2类型的数据，来代表常量池的数量。并且常量池比较特殊，容量计数是从1开始而不是从0开始，所以实际的常量池数量是constant_pool_count - 1 常量池中主要存放两大类变量: 字面量和符号引用。字面量类似常量的概念，而符号引用则引至编译原理的概念，包括三类(类和接口的全限定名，字段的名称和描述符，方法的名称和描述符)，这里要注意的是，Java在javac编译的时候不会进行Class文件的动态连接，只有在运行时才会进行具体的Class文件的解析操作 常量池表结构上文两大类的常量池类型细分之后，到JDK1.7之后增加到了14种。之所以说常量池是最复杂的结构，就是因为这14种不同的类型都有不同的表结构，下面我们来简单看下这14种结构 每种常量类型的起始位都有一个u1类型的tag标识符，用于标识当前的常量类型 访问标志访问标志用于识别类或接口层面的信息，标识是否为public，abstract，final，注解，枚举等 类索引 父类索引 接口索引类索引和父类索引都是一个u2类型的数据，而接口索引则是一组u2类型的集合，所以接口索引入口的第一项为一个u2类型的计数，表示有几个接口索引 类索引和接口索引的具体值是一个u2的数据项，并且指向一个CONSTANT_Class_info常量池表类型在常量池中的偏移量 字段表集合字段表用于描述接口或类中声明的变量，包括类级变量和实际级变量，不包括在方法内部声明的局部变量 包含的信息主要有这几种: 字段作用域(private,protact,public)，是否static修饰，可变性，volatile 修饰，可否被序列化，字段类型(基本类型，引用，数组)，字段名称 字段表结构 类型 名称 数量 u2 access_flas 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info 属性表 attributes_count access_flas我们来看下字段access_flas访问标识可选的类型 标志名称 标志值 含义 ACC_PUBLIC 0x0001 字段是否public ACC_PRIVARE 0x0002 字段是否private ACC_PROTECTED 0x0004 字段是否protected ACC_STATIC 0x0008 字段是否static ACC_FINAL 0x0010 字段是否final ACC_VOLATILE 0x0040 字段是否volatile ACC_TRANSIENT 0x0080 是否 transient ACC_SYNTHETIC 0x1000 字段由编译器自动产生 ACC_ENUM 0x4000 字段是否为枚举类型 看个例子，如果access_flas为0x0019，则标识了ACC_PUBLIC，ACC_STATIC，ACC_FINAL三种类型 name_index和descriptor_index跟在access_flas之后是name_index(简单名称)和descriptor_index(描述符)。包括之前出现的全限定名，这里解释一下这几个名称。全限定名称一般来说是指org/xxx/TestClass这种类型的名称，可以理解为类的路径，简单名称就更加容易理解了，例如方法inc()的简单名称值的就是inc 描述符相对于上面的两种稍复杂一些，描述符的作用是用来描述字段的数据类型，方法的参数列表和返回值，根据描述符规则，基本数据类型（byte,char,int,long,float,double,short,boolean）以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用L加对象的全限定名来表示 具体的列在了下表中 标识字符 含义 B byte C char D double F float I int J long S short Z boolean V void L 对象类型 如 Ljava/lang/Object 对于数组类型，每一纬度使用一个前置的[来表示，如定义一个java.lang.String []的数组类型，将被记录为[[Ljava/lang/String; 用描述符来描述方法时，按照先参数列表后返回值的顺序描述，参数列表严格按照顺序放在()内，如方法void inc()的描述符为()V，方法int inc(int i, double)的描述符为(ID)I 在描述符之后，紧跟着是一个属性表集合，属性表集合可以为空， 方法表方法表的组成与属性表的组成是完全一致的，访问标识符的取值略有不同 标志名称 标志值 含义 ACC_PUBLIC 0x0001 方法是否public ACC_PRIVARE 0x0002 方法是否private ACC_PROTECTED 0x0004 方法是否protected ACC_STATIC 0x0008 方法是否static ACC_FINAL 0x0010 方法是否final ACC_SYNCHRONIZED 0x0020 方法是否同步 ACC_BRIDGE 0x0040 方法是否由编译器产生的桥接方法 ACC_VARARGS 0x0080 方法是否接受不定蚕食 ACC_NATIVE 0x0100 方法是否为native ACC_ABSTRACT 0x0400 方法是否为abstract ACC_STRICTFP 0x0800 方法是否为strictfp SYNTHETIC 0x1000 方法由编译器自动产生 那么这里大家可能会有疑问，方法里的java代码去哪了呢？ 答案就是在方法表的属性表集合中，有一个code属性，那里存放了编译成字节码的Java代码。对于属性表，在下文会提到 属性表属性表，前文已经提到了多次。包括Class文件本身，方法表，字段表都有携带自己的属性表集合，用于描述专有场景信息 并且属性表与Class文件其他数据项要求不同，各个属性不要求严格的顺序，并且只要不与已有属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息 下面我们来看几个关键属性 code 属性java程序方法体中的代码javac编译器处理后，最终变为字节码子令存储在Code属性内 Exceptions 属性列举方法可能会抛出的异常 LineNumberTable 属性描述java源码行数和字节码行数的对应关系，前者是字节码行，后者是源码行 LocalVariableTable 属性描述栈局部变量和源码中定义的变量的关系.这项是可选的，可使用javac -g:none或javac -g:vars命令关闭生成这项信息 SourceFile 属性用于记录Class源码文件的文件名称，这个属性是可选的。可使用javac -g:none或javac -g:source命令关闭生成这项信息 ConstantValue 属性通知虚拟机为静态变量赋值 InnerClasses 属性用于记录内部类与宿主类之间的关系 Deprecated Synthetic 属性Deprecated 标识某个类，字段或方法过期Synthetic 标识此字段不由Java源码直接产生，由编译器自动添加 StackMapTable 属性这个属性会在虚拟机加载完字节码后的验证阶段被使用 Signature 属性Signature在JDK1.5之后被添加，用于记录泛型签名信息。之所以要用这么一个属性去记录泛型信息，是因为Java语言的泛型采用的是擦除法实现的伪泛型，在Code属性中，泛型信息在编译之后统统都被擦除掉了。使用的擦除法的原因是这样子实现比较简单，只需要修改javac编译器就可以实现了，运行时也可以节省一些空间。坏处就是运行时无法拿到泛型信息。Signature就是为了弥补这个缺陷而设置的，现在的Java API反射能够获取到的泛型信息也来自这个属性 BootStrapMathods 属性BootStrapMathods是JDK 1.7之后增加到规范中的，这个属性用于保存invokedynamic指令引用的引导方法限定符。本篇文章暂不赘述这个指令]]></content>
      <categories>
        <category>java基础</category>
        <category>JVM</category>
        <category>java字节码</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>java字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java类加载机制]]></title>
    <url>%2F2019%2F04%2F02%2FJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[引言介绍一下java类加载的过程 类加载的时机类从被加载到java虚拟机内存中开始，被分为7个阶段，包括加载，验证，准备，解析，初始化，使用，卸载 这里我们暂且主要看加载阶段和初始化阶段，java虚拟机主要是做了三件事情 加载 通过类的全限定名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的Class对象 注意这里虚拟机并没有规定类的二进制字节流的来源，所以我们其实通过自定义类加载器来实现从其他途径（如网络中获取）中获取Class文件的二进制字节流 初始化初始化阶段是类加载的最后一个阶段，可以理解成初始静态块及静态变量，在准备阶段，静态变量已经赋了初始值，初始化阶段赋的就是具体的值。 初始化的必要条件，并且有且只有这5种情况才会触发类的初始化 遇到new,getstatic,putstatic,invokestatic这四个字节码时，如果还未执行类的初始化则会执行初始化 使用java.lang.reflect包进行反射调用时，如果还没有进行初始化，则会执行初始化 当初始化一个类时，发现其父类还没有初始化，则会初始化其父类 当虚拟机启动时，用户需要指定一个主类，这个主类会被初始化 使用jdk7动态语言支持时，会执行初始化 以上5中场景，称为对一个类的主动引用。除这5种方式之外，任何其他引用都被称为被动引用，并且都不会触发类的初始化。 下面举三种情况来说明被动引用 通过子类引用父类静态字段，不会触发父类的初始化 1234567891011121314151617181920public class BoshiCat extends Cat &#123; static &#123; System.out.println(&quot;BoshiCat init&quot;); &#125;&#125;public class Cat &#123; static &#123; System.out.println(&quot;Cat init&quot;); &#125; public static int value = 10;&#125;public class Test &#123; public static void main(String[] args) &#123; System.out.println(BoshiCat.value); &#125;&#125;// 输出 10 通过数组来引用类，不会触发引用类的初始化 1234567public class Test &#123; public static void main(String[] args) &#123; Cat [] cats = new Cat[10]; &#125;&#125;// 输出 10 引用static final修饰的常量，因为常量在编译阶段就被写进了常量池 12345678910111213public class Cat &#123; static &#123; System.out.println(&quot;Cat init&quot;); &#125; public static final int value = 10;&#125;public class Test &#123; public static void main(String[] args) &#123; System.out.println(Cat.value); &#125;&#125;// 输出 10]]></content>
      <categories>
        <category>java基础</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock可重入锁源码分析]]></title>
    <url>%2F2019%2F03%2F25%2FReentrantLock%E5%8F%AF%E9%87%8D%E5%85%A5%E9%94%81%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[引言ReentrantLock可重入锁，也是日常使用除了synchronized关键字最多的锁。从字面上理解可重入的意思就是同一个线程可以重复加锁，当然synchronized关键字也是支持可重入的，其实它们的主要功能也是类似的，但是相比较来说，ReentrantLock功能更灵活丰富，例如ReentrantLock支持设置公平锁或非公平锁，支持分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 整个ReentrantLock的实现基于AQS独占锁，这个在上篇文章已经详细分析过 类结构 ReentrantLock.class ReentrantLock实现了Lock接口，但是通过查看源码可知ReentrantLock的具体实现其实都委托给了NonfairSyns（非公平锁）或则FairSync（公平锁）两个类实现，NonfairSyns和FairSync继承了抽象静态类Sync，Sync则是AQS的子类 公平锁 非公平锁ReentrantLock支持公平锁，那么什么是公平锁呢？简单的理解就是多个线程获取锁的顺序应该是按照时间的先后，先来的先获取。也就是说公平锁绝对满足先进先出的队列形式。 我们从AQS同步队列来理解的话，可以认为公平锁每次都是从同步队列中的第一个节点获取到锁，而非公平锁则不一定，有可能占据锁的线程刚释放锁，同步队列中的线程还未来得及获取到锁，就被新请求锁的线程获取了。当然这里要注意，对于已经加入AQS同步队列的线程来说，无论公平锁还是非公平锁都是一样的，按照队列先后顺序获取。 下面我们来看下ReentrantLock的构造方法 1234567public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; ReentrantLock无参构造默认是非公平锁 可以通过设置参数将ReentrantLock设置为公平锁 从代码层面看实现区别 1234567891011121314151617/** * 非公平锁获取锁 */final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;/** * 公平锁获取锁 */final void lock() &#123; acquire(1);&#125; 可以看到很明显的区别，非公平锁获取锁，只要当前没有持锁线程，新加入的线程都有机会获取到锁 可重入上文说过，可重入的概念只针对同一个线程，那么ReentrantLock是如何实现同一个线程可重入的呢？ 这就又要涉及到AQS state的概念，在AQS内部维护了一个状态值state，当有一个线程获取到锁，state值就会+1，对于独占锁来说，不同的线程要想获取锁，state值必须为0。下面我们就通过源码来看看ReentrantLock是如何实现可重入性的 以非公平锁为例 123456789101112131415161718192021222324252627282930313233343536373839/** * 尝试获取锁 */final void lock() &#123; // 如果当前获取锁的线程为0，则直接获取 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 调用AQS模板方法，会调用子类的tryAcquire acquire(1);&#125;protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125;/** * 非公平方法尝试获取锁 */final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 如果当前获取锁的线程为0，则直接获取锁 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果当前获取锁的线程为当前请求线程，则将state + 1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 首先会判断state状态是否为0(也就是当时还没有持锁线程)，如果为0的话则直接获取锁 state状态不为0.则判断与当前持锁线程是否为同一个线程，是的话，则state自增1.获取锁成功 总结总的来说，ReentrantLock和synchronized非常相似，但是也还是比较大的区别，ReentrantLock的功能更丰富灵活，synchronized只支持非公平锁，ReentrantLock可以支持公平锁，并且ReentrantLock支持Condition等，可以批量分组唤醒等待线程。 `]]></content>
      <categories>
        <category>java基础</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java AQS 源码解析]]></title>
    <url>%2F2019%2F03%2F12%2FJava-AQS-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[引言AQS全称java.util.concurrent.locks.AbstractQueuedSynchronizer，是Java 并发包中的一个抽象类，我们一般把它叫做抽象队列同步器，如我们常用的可重入锁ReentrantLock的内部实现就是基于AQS，理解AQS的内部源码实现对于我们深入理解使用java并发包中的各个功能非常重要。 实现原理AQS内部维护了一个双向链表队列来管理多个线程。简单介绍一下就是，当有一个新的线程去尝试获取锁，这是如果获取失败，AQS则会将此线程封装成一个Node节点，并将此节点加入到内部维护的队列中。 上面简单的描述了线程获取锁的过程，那么AQS是使用什么来确认当前线程是否可以尝试获取锁呢？ 其实AQS内部为了一个volatile int state变量来表示当前资源是否已经被其他线程占有，对于独占锁来说，只有当state = 0时才说明该资源当前没有线程占有，后续线程可以开始争抢改资源，后续线程需要通过CAS操作来确保修改state变量成功才能成功抢占该资源。 重要方法AQS内部提供了三组核心方法用来实现一个同步组件。三组方法从字面意思上区分可以分为两种类型：独占锁相关，共享锁相关 访问state有三种方法 getState() 获取同步状态 setState() 设置同步状态（非CAS操作） compareAndSetState() 通过CAS操作修改 一组抽象方法，需要子类实现，主要是获取同步锁并判断是否成功的操作 方法 描述 boolean tryAcquire(int arg) 独占式获取同步状态 boolean tryRelease(int arg) 独占式释放同步状态 int tryAcquireShared(int arg) 共享式获取同步状态 boolean tryReleaseShared(int arg) 共享式释放同步状态 boolean isHeldExclusively() 检测当前线程是否获取独占锁 模板方法，用于子类直接调用 方法 描述 void acquire(int arg) 获取独占锁。会调用tryAcquire方法，如果未获取成功，则会进入同步队列等待 void acquireInterruptibly(int arg) 响应中断版的 acquire boolean tryAcquireNanos(int arg,long nanos) 超时+响应中断版的 acquire void acquireShared(int arg) 获取共享锁。共享式获取同步状态，同一时刻可能会有多个线程获得同步状态。比如读写锁的读锁就是就是调用这个方法获取同步状态的 void acquireSharedInterruptibly(int arg) 响应中断版的acquireShared boolean tryAcquireSharedNanos(int arg,long nanos) 超时+响应中断版的acquireShared boolean release(int arg) 独占式释放同步状态 boolean releaseShared(int arg) 释放共享锁 Collection getQueuedThreads() 获取同步队列上的线程集合 源码分析上文有提到，进入同步队列的线程会被封装成一个Node节点，下面我们先来看下Node.class 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158static final class Node &#123; /** * 用于标记一个节点在共享模式下等待 */ static final Node SHARED = new Node(); /** * 用于标记一个节点在独占模式下等待 */ static final Node EXCLUSIVE = null; /** * 等待状态：取消状态 */ static final int CANCELLED = 1; /** * 等待状态：通知(指示后继线程需要阻塞) */ static final int SIGNAL = -1; /** * 等待状态：条件等待 */ static final int CONDITION = -2; /** * 等待状态：传播 */ static final int PROPAGATE = -3; /** * 等待状态 */ volatile int waitStatus; /** * 前驱节点 */ volatile Node prev; /** * 后继节点 */ volatile Node next; /** * 节点对应的线程 */ volatile Thread thread; /** * 等待队列中的后继节点 */ Node nextWaiter; /** * 当前节点是否处于共享模式等待 */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * 获取前驱节点，如果为空的话抛出空指针异常 */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) &#123; throw new NullPointerException(); &#125; else &#123; return p; &#125; &#125; Node() &#123; &#125; /** * addWaiter会调用此构造函数 */ Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; /** * Condition会用到此构造函数 */ Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 这里解释几个重要的属性 属性 意义 prev 前置节点 next 后置节点 CANCELLED 状态值 表示节点被取消 SIGNAL 状态值 表示后置节点需要被阻塞 CONDITION 状态值 表示节点进入 CONDITION PROPAGATE 状态值 共享锁传播状态 独占锁的获取在AQS中包含了head和tail两个Node引用，其中head在逻辑上的含义是当前持有锁的线程，tail指示队尾节点。head和tail可以相等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372/*** 获取独占锁，该方法会首先调用tryAcquire（由子类实现）来获取锁，* 如果获取成功会直接返回，失败则会将当前抢锁失败的线程封装为Node节点加入队尾 */public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;/*** 增加一个 * */private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 快速执行一次加入队列尾部的操作，如果失败的话则执行 enq // 获取队尾节点 Node pred = tail; if (pred != null) &#123; // 获取队尾的前驱节点 node.prev = pred; // CAS设置新的队尾，有可能失败 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 如果还没有队尾（初始状态），或则入队失败，则执行下面的方法 enq(node); return node;&#125;private Node enq(final Node node) &#123; // 通过CAS 自旋设置新的队尾 for (;;) &#123; Node t = tail; // 队尾节点为空，说明是初始状态，必须初始化头尾节点 if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 这里注意一个细节 // node.prev = t 操作是设置当前节点的前驱节点为现在的队尾节点 // 但是该操作没有放到compareAndSetTail操作成功以后，也就是说代码为何不这样写 // if (compareAndSetTail(t, node)) &#123; // node.prev = t; // t.next = node; // return t; // &#125;// 如果这样子写的话，队尾节点在某一瞬间会是一个孤立的节点，但是如果先// 执行 node.prev = t 就把当前节点的前驱指向了还未设置前的队尾，这样子当我们从后往前遍历的时候，就不会出现队列断裂的情况 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;/*** 节点加入队列之后操作，这里分两种情况* 1\. 如果当前节点的前驱节点为head 头节点，则尝试获取锁，并设置新的头节点 * 2\. 阻塞自己 */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; // 循环尝试获取锁 for (;;) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 前驱节点为head节点 则尝试获取锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 判断是否需要阻塞自己 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 如果抛异常失败，则调用 cancelAcquire 取消该节点 if (failed) cancelAcquire(node); &#125;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 如果前驱节点的 waitStatus 为 -1，则说明当前线程需要阻塞 if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // waitStatus大于0，说明前驱节点为取消状态，需要重新设置前驱节点 if (ws &gt; 0) &#123; // 向前寻找waitStatus&lt;=0的节点，并设置为新的前驱节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * 如果前驱节点状态为 0 -2 -3，则设置前驱节点 WaitStatus = -1，并重新循环 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;/** * 调用 LockSupport.park(this) 阻塞当前线程 */private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125;/*** 取消节点，也就是当前线程放弃获取锁 */private void cancelAcquire(Node node) &#123; if (node == null) return; node.thread = null; // 获取前驱节点，会跳过状态为取消状态的节点 Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 获取后继节点 Node predNext = pred.next; // 设置节点状态为取消 node.waitStatus = Node.CANCELLED; // 如果当前节点是队尾节点，则设置前驱节点为队尾，并设置前驱节点的后继节点为null if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; // 如果前驱节点不是头结点，且前驱节点的 WaitStatus = -1 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; // 将前置节点和后继节点相连 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; // 唤醒后继节点 // 这里为何要唤醒后继节点？ // 因为如果当前节点的前置节点为head节点，但是此时head节点的状态为0（当前节点还未来得及设置前置节点状态为 -1），这时head节点释放了锁因为状态还为0，所以不会去唤醒后继线程。这时队列就失去活性了！所以这里需要唤醒后继线程 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125;/*** 唤醒后继节点 */private void unparkSuccessor(Node node) &#123; /* * 如果节点 waitStatus &lt; 0，则尝试将状态设为0 */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * 获取当前节点的后继节点 * 如果 s!=null 且 s未被取消 则直接唤醒 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从尾节点向前查找离node最近的非取消节点 // 注意这里为何要从后向前查找 // 在 enq方法中有段注释，如果从前往后的话，有可能出现队列断裂 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 上文基本完成了对独占锁获取锁的流程的分析，这里简单画个图来更清晰的展示整个获取锁的过程： 独占锁的释放12345678910111213141516171819202122232425262728293031323334/** * 释放锁 */public final boolean release(int arg) &#123; // 如果释放锁成功 if (tryRelease(arg)) &#123; Node h = head; // 且当前持锁的头结点状态不等于0，就去唤醒后继线程 // 思考这里等于0 为何不行？ // 因为当 waitStatus == 0时，说明后继线程还在运行中，还未来得及将waitStatus 状态设为-1 if (h != null &amp;&amp; h.waitStatus != 0) // 与上文unparkSuccessor方法一致 unparkSuccessor(h); return true; &#125; return false;&#125; 共享锁共享锁与独占锁最大的区别在于，共享锁允许多个线程持有锁，而独占锁在同一时间只有一个线程可以获取到锁 共享锁的获取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166/*** 获取共享锁 */public final void acquireShared(int arg) &#123; // 如果tryAcquireShared(arg) &lt; 0表示获取共享锁失败 // 获取失败的原因一般是由于该资源正由独占锁占有 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; // 加入到队列尾部 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); // 一旦共享获取成功，设置新的头结点，并且唤醒后继线程 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // 判断是否需要阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/*** 在获取共享锁成功后，设置head节点* 跟据调用tryAcquireShared返回的状态以及节点本身的等待状态来判断是否要需要唤醒后继线程。 */private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; setHead(node); /* * propagate是tryAcquireShared的返回值，这是决定是否传播唤醒的依据之一。 * h.waitStatus为SIGNAL或者PROPAGATE时也根据node的下一个节点共享来决定是否传播唤醒， * 思考，这里为什么不能只用propagate &gt; 0来决定是否可以传播 * 因为此时有可能有其他线程释放了锁，但propagate还未更新，所以还需要判断h.waitStatus &lt; 0 */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; // 后继节点为共享锁类型 if (s == null || s.isShared()) doReleaseShared(); &#125;&#125;/*** 这是共享锁中的核心唤醒函数，主要做的事情就是唤醒下一个线程或者设置传播状态。 */private void doReleaseShared() &#123; for (;;) &#123; Node h = head; // 如果队列中存在后继线程。 if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h); &#125; // 如果h节点的状态为0，需要设置为PROPAGATE用以保证唤醒的传播。 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head) break; &#125;&#125; 共享锁的释放12345678910111213141516public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; // 与上文doReleaseShared一样 doReleaseShared(); return true; &#125; return false;&#125; 总结AQS的整体理念相对比较容易理解，但是AQS真正难懂的其实是它的细节，因为一个很简单的问题一旦被放在并发环境中就会变的非常抽象，难以理解。要理解AQS的细节实现，还是需要多看，我是前前后后看了有一周，对于有些细节还是略模糊。 本篇文章参考了 AbstractQueuedSynchronizer源码解读]]></content>
      <categories>
        <category>java基础</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java CAS]]></title>
    <url>%2F2019%2F03%2F02%2FJava-CAS%2F</url>
    <content type="text"><![CDATA[引言在介绍CAS之前，我们有必要先理解线程安全的三大特性 原子性: 对于涉及共享变量访问的操作，该操作从其执行线程以外的任意线程来看是不可分割的，从而可以让各个线程依次串行访问，但是原子性并不保证可见性 可见性: 修改共享变量时，立即将工作内存中的值同步到主存中，并使该修改对其他线程可见 有序性: 禁止读取共享变量后的代码、修改共享变量前的代码重排序 CAS即compare and swap的缩写，中文翻译成比较并交换。是一种用于在多线程环境下实现同步功能的机制。调用Java CAS需要三个操作数 内存中值的内存位置 预期值 新值 具体实现是通过值的内存位置取到内存中的值并与预期值比较，若相等，则将内存位置处的值替换为新值，若不相等，则不做任何操作返回false。如果大家有了解过悲观锁和乐观锁，可以发现CAS其实是一种乐观锁的实现。 使用CAS的目的对于实现线程安全，我们用的比较多的应该是synchronized关键字，synchronized其实是一种悲观锁，锁被占用的情况会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。CAS是一种乐观锁，每次取数据都不会加锁，更新的时候会进行数据比对，有冲突的话则会自旋重试。可以看到在读操作频繁，更新频率低，冲突概率低的情况下，用CAS的话会更加合理。当然JDK1.6之后，Java对synchronized关键字来了一大波优化（自旋锁，锁消除，锁粗化，偏向锁，轻量级锁），一般情况下使用synchronized是非常稳定的。 CAS的底层实现现在的CPU都是多核心的，多个核心通过总线来操作内存。那么这里就存在一个问题，就是如果多个核心同时操作一块内存区域，会发生什么问题呢？是的，这里数据就会出现混乱。不过这里我们可以从intel的使用手册中找到答案，对指令加lock前缀可以保证操作的原子性，可见性以及有序性。好了，底层的就不多说了，我们直接去看一下java.util.concurrent.atomic包下的原子类 AtomicInteger的源码实现 AtomicInteger源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); // value值的内存位置 private static final long valueOffset; static &#123; try &#123; // 获取value的内存位置 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; // value值 volatile 修饰 保证可见性 private volatile int value; public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; public AtomicInteger() &#123; &#125; /** * 获取value在内存中当前的值 * * @return the current value */ public final int get() &#123; return value; &#125; /** * 比较并替换 实现在unsafe.compareAndSwapInt中 * @param expect 期望值 * @param update 新值 */ public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; /** * 自增 实现在unsafe.getAndAddInt中 */ public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125;&#125; Unsafe.class 12345678910111213public final native boolean compareAndSwapInt(Object o, long valueOffset, int expected, int value);/** * 获取当前值 并加1，返回的是加1前的值 */public final int getAndAddInt(Object o, long valueOffset, int addValue) &#123; int currentValue; do &#123; currentValue = this.getIntVolatile(o, valueOffset); // 比较当前内存的值和预期值currentValue是否一致，一致的话则设置新值。但是因为当前内存中的值有可能被其他线程修改，会有和预期值不一致的情况，所以这里会循环直到 compareAndSwapInt 返回成功为止，这里的操作也称为CAS自旋 &#125; while(!this.compareAndSwapInt(o, valueOffset, currentValue, value + addValue)); return value;&#125; AtomicInteger是Java对Integer类型原子性操作的实现，可以看到底层都是调用了CAS compareAndSwapIntnative方法。这里主要看一下compareAndSwapInt(Object o, long valueOffset, int expect, int update)的四个参数 o 当前操作的对象 valueOffset 操作值所在的内存位置 expect 期望值 update 新值 具体实现是将内存位置处的数值与预期数值相比较，若相等，则将内存位置处的值替换为新值。若不相等，则不做任何操作。CAS自旋指的是替换新值失败时会进入循环，重新获取期望值，直到期望值和内存位置处的数值相等。 CAS的问题ABA问题提到CAS存在的问题，就不得不提ABA问题，什么是ABA问题呢？举个例子，A是个共享变量，原值是10，线程1从内存中拿到了A，此时值为10，当线程1要对变量A进行CAS操作前，因为其他线程的操作，A从10变为了11，又从11变回了10。此时线程1对变量A执行CAS操作照道理应该是要失败的，但实际却是成功的。这是因为经过了上面的流程，在线程1看来，变量A没有发生任何变化，所以它执行CAS操作是会成功的。 要解决ABA问题，通常的解决方案给对象加上版本号，每经过一次CAS操作就更新一次版本号 总结本文的目的主要是让自己对java并发包的基础CAS有个简单的了解，以便进行后续的源码分析]]></content>
      <categories>
        <category>java基础</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码解析三 Connector连接器]]></title>
    <url>%2F2019%2F02%2F13%2FTomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%89-Connector%E8%BF%9E%E6%8E%A5%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引言上文分析了Tomcat的启动流程，我们已经大致理清了Tomcat启动的整个流程，本文将会对Connector连接器的创建进行分析 整体架构 上图完整了概括了整个Connector的架构体系，先简单的介绍一下各个组件的功能 Endpoint 用来处理底层Socket的网络连接 Processor 用来实现HTTP协议的 Adapter 将请求适配到Servlet容器进行具体的处理 org.apache.catalina.connector.Connector我们先来看下org.apache.catalina.connector.Connector这个主体类的构造方法，Connector类初始化是在Tomcat读取配置文件时就完成的 1234567891011121314151617181920212223242526272829303132333435public Connector(String protocol) &#123; boolean aprConnector = AprLifecycleListener.isAprAvailable() &amp;&amp; AprLifecycleListener.getUseAprConnector(); // 判断协议类型 if (&quot;HTTP/1.1&quot;.equals(protocol) || protocol == null) &#123; if (aprConnector) &#123; protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11AprProtocol&quot;; &#125; else &#123; protocolHandlerClassName = &quot;org.apache.coyote.http11.Http11NioProtocol&quot;; &#125; &#125; else if (&quot;AJP/1.3&quot;.equals(protocol)) &#123; if (aprConnector) &#123; protocolHandlerClassName = &quot;org.apache.coyote.ajp.AjpAprProtocol&quot;; &#125; else &#123; protocolHandlerClassName = &quot;org.apache.coyote.ajp.AjpNioProtocol&quot;; &#125; &#125; else &#123; protocolHandlerClassName = protocol; &#125; // Instantiate protocol handler ProtocolHandler p = null; try &#123; Class&lt;?&gt; clazz = Class.forName(protocolHandlerClassName); p = (ProtocolHandler) clazz.getConstructor().newInstance(); &#125; catch (Exception e) &#123; log.error(什么.getString( &quot;coyoteConnector.protocolHandlerInstantiationFailed&quot;), e); &#125; finally &#123; this.protocolHandler = p; &#125; // Default for Connector depends on this system property setThrowOnFailure(Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;));&#125; 这里其实是拿到server.xml中Connector的协议配置，利用反射创建ProtocolHandle，Connector就是使用ProtocolHandler来处理请求的，不同的ProtocolHandler代表不同的连接类型。 因为我这里使用的是tomcat9的源码版本，可以看到其已经淘汰了BIO。默认的http1.1协议处理类已经是org.apache.coyote.http11NioProtocol了，下面我们就以http11NioProtocol继续往下分析 org.apache.coyote.http11NioProtocol通过查看Http11NioProtocol的构造方法，可知Endpoint的实现类是NioEndpoint123public Http11NioProtocol() &#123; super(new NioEndpoint());&#125; Endpoint上文有说过是用来处理底层Socket网络连接的，下面就让我们来看下NioEndpoint的实现 NioEndpoint还是先看下启动方法 startInternal中的实现123456789101112131415public void startInternal() throws Exception &#123; ..... // 初始化Poller数组，启动Poller线程 pollers = new Poller[getPollerThreadCount()]; for (int i=0; i&lt;pollers.length; i++) &#123; pollers[i] = new Poller(); Thread pollerThread = new Thread(pollers[i], getName() + &quot;-ClientPoller-&quot;+i); pollerThread.setPriority(threadPriority); pollerThread.setDaemon(true); pollerThread.start(); &#125; // 启动 Acceptor 线程 startAcceptorThreads(); &#125;&#125; 这里我省略了其他代码，可以看到在这里初始化了多个Poller类，并单独启动了线程，这里的每个Poller其实都绑定了一个Selector选择器（）。并且调用startAcceptorThreads方法启动了Acceptor线程，用来接收新的请求。下面我们继续看startAcceptorThreads方法 12345678910111213141516protected void startAcceptorThreads() &#123; // 获取Acceptor线程数 默认是1 int count = getAcceptorThreadCount(); acceptors = new ArrayList&lt;&gt;(count); for (int i = 0; i &lt; count; i++) &#123; Acceptor&lt;U&gt; acceptor = new Acceptor&lt;&gt;(this); String threadName = getName() + &quot;-Acceptor-&quot; + i; acceptor.setThreadName(threadName); acceptors.add(acceptor); Thread t = new Thread(acceptor, threadName); t.setPriority(getAcceptorThreadPriority()); t.setDaemon(getDaemon()); t.start(); &#125;&#125; 上面的代码根据配置启动了多个Acceptor线程，下面就去看下Acceptor类的run方法 Acceptor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public void run() &#123; int errorDelay = 0; // Loop until we receive a shutdown command while (endpoint.isRunning()) &#123; .... try &#123; // 接收新的请求 socket = endpoint.serverSocketAccept(); &#125; catch (Exception ioe) &#123; // We didn&apos;t get a socket endpoint.countDownConnection(); if (endpoint.isRunning()) &#123; // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); // re-throw throw ioe; &#125; else &#123; break; &#125; &#125; // Successful accept, reset the error delay errorDelay = 0; // Configure the socket if (endpoint.isRunning() &amp;&amp; !endpoint.isPaused()) &#123; // 设置新的Socket连接与Poller绑定，并设置相关参数 if (!endpoint.setSocketOptions(socket)) &#123; endpoint.closeSocket(socket); &#125; &#125; else &#123; endpoint.destroySocket(socket); &#125; &#125; catch (Throwable t) &#123; &#125; state = AcceptorState.ENDED;&#125;// NioEndpoint.class 中protected boolean setSocketOptions(SocketChannel socket) &#123; // Process the connection try &#123; // 设置此Socket连接未非阻塞 socket.configureBlocking(false); Socket sock = socket.socket(); // 设置此Socket的相关参数值 socketProperties.setProperties(sock); NioChannel channel = nioChannels.pop(); if (channel == null) &#123; SocketBufferHandler bufhandler = new SocketBufferHandler( socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); // 判断是否开启ssl if (isSSLEnabled()) &#123; channel = new SecureNioChannel(socket, bufhandler, selectorPool, this); &#125; else &#123; channel = new NioChannel(socket, bufhandler); &#125; &#125; else &#123; channel.setIOChannel(socket); channel.reset(); &#125; // 绑定 Poller 其实就是绑定选择器 Selector getPoller0().register(channel); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); try &#123; log.error(sm.getString(&quot;endpoint.socketOptionsError&quot;), t); &#125; catch (Throwable e) &#123; ExceptionUtils.handleThrowable(e); &#125; // Tell to close the socket return false; &#125; return true;&#125; 上面代码逻辑主要做了两件事情 调用NioEndpoint的serverSocketAccept方法来接收新的请求，注意这里是阻塞的 调用NioEndpoint的setSocketOptions方法对新接收的Socket请求，配置相关信息，并绑定Poller(绑定选择器 Selector) Poller接下来我们将会分析Poller类，是NioEndpoint的内部类 123456789101112131415public void register(final NioChannel socket) &#123; socket.setPoller(this); NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this); socket.setSocketWrapper(ka); ka.setPoller(this); ka.setReadTimeout(getConnectionTimeout()); ka.setWriteTimeout(getConnectionTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); PollerEvent r = eventCache.pop(); ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); addEvent(r);&#125; register方法就是将新的Socket连接与Selector进行绑定，并注册监听读事件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public void run() &#123; // Loop until destroy() is called while (true) &#123; boolean hasEvents = false; try &#123; if (!close) &#123; hasEvents = events(); if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; //if we are here, means we have other stuff to do //do a non blocking select keyCount = selector.selectNow(); &#125; else &#123; keyCount = selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOException ioe) &#123; log.error(什么.getString(&quot;endpoint.nio.selectorCloseFail&quot;), ioe); &#125; break; &#125; &#125; catch (Throwable x) &#123; ExceptionUtils.handleThrowable(x); log.error(什么.getString(&quot;endpoint.nio.selectorLoopError&quot;), x); continue; &#125; //either we timed out or we woke up, process events first if ( keyCount == 0 ) hasEvents = (hasEvents | events()); Iterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null; // Walk through the collection of ready keys and dispatch // any active event. while (iterator != null &amp;&amp; iterator.hasNext()) &#123; SelectionKey sk = iterator.next(); NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment(); // Attachment may be null if another thread has called // cancelledKey() if (attachment == null) &#123; iterator.remove(); &#125; else &#123; iterator.remove(); processKey(sk, attachment); &#125; &#125;//while //process timeouts timeout(keyCount,hasEvents); &#125;//while getStopLatch().countDown();&#125; run方法中的一大堆代码，多是与NIO相关，主要逻辑就是调用selector的select()函数，监听就绪事件。这里我们可以直接看processKey方法，这里是根据SelectionKey来分别执行具体逻辑 12345678910111213141516171819202122232425262728293031323334353637383940protected void processKey(SelectionKey sk, NioSocketWrapper attachment) &#123; try &#123; if ( close ) &#123; cancelledKey(sk); &#125; else if ( sk.isValid() &amp;&amp; attachment != null ) &#123; if (sk.isReadable() || sk.isWritable() ) &#123; if ( attachment.getSendfileData() != null ) &#123; processSendfile(sk,attachment, false); &#125; else &#123; unreg(sk, attachment, sk.readyOps()); boolean closeSocket = false; // 如果是可读事件就绪 if (sk.isReadable()) &#123; // 执行具体逻辑的地方 if (!processSocket(attachment, SocketEvent.OPEN_READ, true)) &#123; closeSocket = true; &#125; &#125; // 如果是可写事件就绪 if (!closeSocket &amp;&amp; sk.isWritable()) &#123; if (!processSocket(attachment, SocketEvent.OPEN_WRITE, true)) &#123; closeSocket = true; &#125; &#125; if (closeSocket) &#123; cancelledKey(sk); &#125; &#125; &#125; &#125; else &#123; //invalid key cancelledKey(sk); &#125; &#125; catch ( CancelledKeyException ckx ) &#123; cancelledKey(sk); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); log.error(sm.getString(&quot;endpoint.nio.keyProcessingError&quot;), t); &#125;&#125; processKey方法也是直接调用了AbstractEndpoint的processSocket方法 1234567891011121314151617181920212223242526272829303132public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper, SocketEvent event, boolean dispatch) &#123; try &#123; if (socketWrapper == null) &#123; return false; &#125; SocketProcessorBase&lt;S&gt; sc = processorCache.pop(); if (sc == null) &#123; // 创建一个 SocketProcessor 实例 sc = createSocketProcessor(socketWrapper, event); &#125; else &#123; sc.reset(socketWrapper, event); &#125; Executor executor = getExecutor(); if (dispatch &amp;&amp; executor != null) &#123; executor.execute(sc); &#125; else &#123; // 执行 sc.run(); &#125; &#125; catch (RejectedExecutionException ree) &#123; getLog().warn(什么.getString(&quot;endpoint.executor.fail&quot;, socketWrapper) , ree); return false; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); // This means we got an OOM or similar creating a thread, or that // the pool and its queue are full getLog().error(什么.getString(&quot;endpoint.process.fail&quot;), t); return false; &#125; return true;&#125; SocketProcessor123456789101112131415161718192021222324252627protected void doRun() &#123; NioChannel socket = socketWrapper.getSocket(); SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); .... 省略 if (handshake == 0) &#123; SocketState state = SocketState.OPEN; // Process the request from this socket if (event == null) &#123; // 获取 ConnectionHandler并调用process执行具体逻辑 state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ); &#125; else &#123; state = getHandler().process(socketWrapper, event); &#125; if (state == SocketState.CLOSED) &#123; close(socket, key); &#125; &#125; else if (handshake == -1 ) &#123; close(socket, key); &#125; else if (handshake == SelectionKey.OP_READ)&#123; socketWrapper.registerReadInterest(); &#125; else if (handshake == SelectionKey.OP_WRITE)&#123; socketWrapper.registerWriteInterest(); &#125; &#125; &#125;&#125; SocketProcessor逻辑比较简单，doRun方法继续会往下调用，最终http协议的解析是在Http11Processor的service中进行，Http11Processor就对应上文架构图的Process模块，在Process完成Http协议解析之后，会由适配器进行适配后再交给Servlet容器进行具体处理 总结本文分析Tomcat的Connector连接器的部分源码，Connector是Tomcat的核心组件，Connector组件用于等待用户的请求，包括支持http1.1，http2等协议，解析用户请求，封装请求信息，最后才交给我们熟悉的 Servlet处理。阅读此源码对于理解http协议也有很大的帮助。]]></content>
      <categories>
        <category>web容器</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码解析二 启动过程]]></title>
    <url>%2F2019%2F02%2F12%2FTomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BA%8C-%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引言上文介绍了Tomcat设计的整体架构，对于接下来的源码分析非常重要。接下来我们将从Tomcat的入口启动开始分析Tomcat的源码 Tomcat的启动入口我们可以从其启动脚本catalina.sh中发现，是由org.apache.catalina.startup.Bootstrap.java的main方法启动的。现在我们就从Bootstrap.java开始分析tomcat的源码 Bootstrap在看Main函数之前，我们先看下静态块中的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061static &#123; String userDir = System.getProperty(&quot;user.dir&quot;); // 获取 catalina.home 的配置目录 String home = System.getProperty(Globals.CATALINA_HOME_PROP); File homeFile = null; if (home != null) &#123; File f = new File(home); try &#123; homeFile = f.getCanonicalFile(); &#125; catch (IOException ioe) &#123; homeFile = f.getAbsoluteFile(); &#125; &#125; // 如果未配置 则取bootstrap.jar所在目录的上一级 if (homeFile == null) &#123; // First fall-back. See if current directory is a bin directory // in a normal Tomcat install File bootstrapJar = new File(userDir, &quot;bootstrap.jar&quot;); if (bootstrapJar.exists()) &#123; File f = new File(userDir, &quot;..&quot;); try &#123; homeFile = f.getCanonicalFile(); &#125; catch (IOException ioe) &#123; homeFile = f.getAbsoluteFile(); &#125; &#125; &#125; if (homeFile == null) &#123; // Second fall-back. Use current directory File f = new File(userDir); try &#123; homeFile = f.getCanonicalFile(); &#125; catch (IOException ioe) &#123; homeFile = f.getAbsoluteFile(); &#125; &#125; catalinaHomeFile = homeFile; System.setProperty( Globals.CATALINA_HOME_PROP, catalinaHomeFile.getPath()); // 未配置catalina.base的情况下，catalina.base的目录和catalina.home一致 String base = System.getProperty(Globals.CATALINA_BASE_PROP); if (base == null) &#123; catalinaBaseFile = catalinaHomeFile; &#125; else &#123; File baseFile = new File(base); try &#123; baseFile = baseFile.getCanonicalFile(); &#125; catch (IOException ioe) &#123; baseFile = baseFile.getAbsoluteFile(); &#125; catalinaBaseFile = baseFile; &#125; System.setProperty( Globals.CATALINA_BASE_PROP, catalinaBaseFile.getPath());&#125; 上面的代码设置了Tomcat的安装目录和实际工作目录 catalina.base tomcat工作目录 指conf、logs、temp、webapps和work文件夹的父目录 catalina.home 安装目录 其实是指bin和lib文件夹的父目录 利用这个特性，我们可以不必复制多个tomcat来启动多个实例 Main 函数入口继续往下看，就是Tomcat启动的最终入口了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public static void main(String args[]) &#123; // 为何这里要加锁？？ synchronized (daemonLock) &#123; if (daemon == null) &#123; // Don&apos;t set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try &#123; // 执行初始化方法 bootstrap.init(); &#125; catch (Throwable t) &#123; handleThrowable(t); t.printStackTrace(); return; &#125; daemon = bootstrap; &#125; else &#123; // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to // prevent a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); &#125; &#125; try &#123; String command = &quot;start&quot;; if (args.length &gt; 0) &#123; // 获取命令参数 command = args[args.length - 1]; &#125; if (command.equals(&quot;startd&quot;)) &#123; args[args.length - 1] = &quot;start&quot;; daemon.load(args); daemon.start(); &#125; else if (command.equals(&quot;stopd&quot;)) &#123; args[args.length - 1] = &quot;stop&quot;; daemon.stop(); &#125; else if (command.equals(&quot;start&quot;)) &#123; // 启动 daemon.setAwait(true); daemon.load(args); daemon.start(); if (null == daemon.getServer()) &#123; System.exit(1); &#125; &#125; else if (command.equals(&quot;stop&quot;)) &#123; daemon.stopServer(args); &#125; else if (command.equals(&quot;configtest&quot;)) &#123; daemon.load(args); if (null == daemon.getServer()) &#123; System.exit(1); &#125; System.exit(0); &#125; else &#123; log.warn(&quot;Bootstrap: command \&quot;&quot; + command + &quot;\&quot; does not exist.&quot;); &#125; &#125; catch (Throwable t) &#123; .... &#125;&#125; 上面的代码是整个tomcat的统一入口。可以看到，在Main方法中，执行了init方法，那么在init方法中肯定做了很多事情 1234567891011121314151617181920212223242526272829public void init() throws Exception &#123; // 初始化类加载器 initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method if (log.isDebugEnabled()) log.debug(&quot;Loading startup class&quot;); // 获取容器类 org.apache.catalina.startup.Catalina Class&lt;?&gt; startupClass = catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;); // 实例化一个Servlet容器 Object startupInstance = startupClass.getConstructor().newInstance(); if (log.isDebugEnabled()) log.debug(&quot;Setting startup class properties&quot;); String methodName = &quot;setParentClassLoader&quot;; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance;&#125; 在init方法中初始化了类加载器，并且初始化了一个org.apache.catalina.startup.Catalina实例，main方法中调用Catalina的start方法来启动容器。 start12345678910111213141516171819202122232425262728293031323334public void start() &#123; // 如果 Server为空，则初始化一个 if (getServer() == null) &#123; load(); &#125; if (getServer() == null) &#123; log.fatal(什么.getString(&quot;catalina.noServer&quot;)); return; &#125; long t1 = System.nanoTime(); // Start the new server try &#123; // 启动Server getServer().start(); &#125; catch (LifecycleException e) &#123; try &#123; getServer().destroy(); &#125; catch (LifecycleException e1) &#123; log.debug(&quot;destroy() failed for failed Server &quot;, e1); &#125; return; &#125; long t2 = System.nanoTime(); if(log.isInfoEnabled()) &#123; &#125; if (await) &#123; await(); stop(); &#125;&#125; 可以看到Start方法中依赖调用了Server的start方法，看到这里我们可以知道为何Tomcat容器这么多的组件为何可以统一启动，统一销毁，其实这些组件都是org.apache.catalina .Lifecycle的实现类，Lifecycle接口包含了start启动，init初始化，destory销毁，stop停止等方法，并且都继承了抽象类LifecycleBase，其中具体的initInternal()、startInternal() 和stopInternal() 方法，交由子类自己实现通过实现该接口，达到统一启动关闭的效果，这里其实体现了模板方法的设计模式。 再回到上面的方法，我们着重看一下load方法，该方法初始化了一个新的Server 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public void load() &#123; if (loaded) &#123; return; &#125; loaded = true; long t1 = System.nanoTime(); initDirs(); // Before digester - it may be needed initNaming(); // Set configuration source ConfigFileLoader.setSource(new CatalinaBaseConfigurationSource(Bootstrap.getCatalinaBaseFile(), getConfigFile())); File file = configFile(); // 解析配置文件 server.xml ，创建一个解析器 Digester digester = createStartDigester(); try (ConfigurationSource.Resource resource = ConfigFileLoader.getSource().getServerXml()) &#123; InputStream inputStream = resource.getInputStream(); InputSource inputSource = new InputSource(resource.getURI().toURL().toString()); inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; catch (Exception e) &#123; if (file == null) &#123; log.warn(什么.getString(&quot;catalina.configFail&quot;, getConfigFile() + &quot;] or [server-embed.xml&quot;), e); &#125; else &#123; log.warn(什么.getString(&quot;catalina.configFail&quot;, file.getAbsolutePath()), e); if (file.exists() &amp;&amp; !file.canRead()) &#123; log.warn(什么.getString(&quot;catalina.incorrectPermissions&quot;)); &#125; &#125; return; &#125; getServer().setCatalina(this); getServer().setCatalinaHome(Bootstrap.getCatalinaHomeFile()); getServer().setCatalinaBase(Bootstrap.getCatalinaBaseFile()); // Stream redirection initStreams(); // Start the new server try &#123; getServer().init(); &#125; catch (LifecycleException e) &#123; if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;)) &#123; throw new java.lang.Error(e); &#125; else &#123; log.error(什么.getString(&quot;catalina.initError&quot;), e); &#125; &#125; long t2 = System.nanoTime(); if(log.isInfoEnabled()) &#123; log.info(什么.getString(&quot;catalina.init&quot;, Long.valueOf((t2 - t1) / 1000000))); &#125;&#125; load方法其实做的主要事情就是解析server.xml文件，server.xml是tomcat关键配置文件，上篇文章我们聊过Tomcat的整体架构，整个架构体系其实非常完整的体现在了server.xml文件上。这里解析server.xml文件用的xml解析工具是SAX，是一种以事件驱动的XMl API，具体解析的机制这里就不说了这里其实依次通过解析配置文件创建了 StandardServer、StandardService、StandardEngine、StandardHost。然后调用StandardServer的init()方法初始化Tomcat容器的一系列组件，容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。上面提到的是init的调用过程，start方法的启动过程其实也是类似，由父容器启动子容器层层调用。 总结本文分析了Tomcat启动部分的源码，这是阅读其源码的入口]]></content>
      <categories>
        <category>web容器</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码解析一 架构初窥]]></title>
    <url>%2F2019%2F01%2F20%2FTomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%80-%E6%9E%B6%E6%9E%84%E5%88%9D%E7%AA%A5%2F</url>
    <content type="text"><![CDATA[引言Tomcat是一个非常复杂的Servlet容器，也是在日常工作中与我们接触非常多的Http服务器，作为一个成熟的软件，它的整体设计，代码结构都十分的优秀，作为开发者，非常有必要研读Tomcat源码。阅读源码总是开头难，但是一旦对整体设计理念有一定了解后，再进行深入分析，就会有不一样的收获。 整体架构先上一张总体架构图 这张图可以说每篇介绍Tomcat的博客都是必放，既然每个人都认可这张图，说明此图非常重要。接下来我们就围绕这张图对Tomcat的整体架构进行分析。 Server服务器：可以看成代表Tomcat服务器本身，一个Tomcat实例只会有一个Server Service查看上图，可知一个Server可以包含多个Service，在这里可以把Service看成是Connector和Container组合层，Connector和Container是Tomcat两个主要的模块 Connector 连接器，一个Service可以有多个Connector（http AJP 等），监听用户请求端口 Container 按照层级有Engine，Host，Context，Wrapper四种，一个Service只有一个Engine，其主要作用是执行业务逻辑 这里我再贴一个Tomcat的配置文件，可以根据此配置文件再回过头去看上图 12345678910111213141516171819202122232425&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt; 配置文件的第一个节点就是Server，并且配置了shutdown端口为8005，然后就配置了一个名为Catalina的Service，这里其实可以配置多个Service。再看Service节点中，配置了多个Connector连接器，并且配置了一个Engine，Engine对应Container的最顶层，一个Service只有一个Engine。 下面我们再进行逐个分析 ServerServer是Tomcat最顶层的容器，一个Tomcat实例只会有一个Server。一个Server至少需要包含一个Service，在配置文件中的体现就是至少需要包含一个Service节点。这里我们可以看下Tomcat对于Server的标准实现类org.apache.catalina.core.StandardServer，其中Lifecycle这个接口是Tomcat对于生命周期维护的重要接口，每个组件都必须实现，从而保证了统一启动/统一关闭的效果 Service前文说过，Service就是用于组装Connector和Container的对应关系的。通过查看配置文件，可知Service节点包含了Connector和Container，其中Connector监听用户请求，并解析请求参数，Container执行具体业务逻辑 ConnectorConnector是连接器，用于接受请求并将请求封装成Request和Response，然后交给Container进行处理，Container处理完之后再交给Connector返回给客户端 ContainerTomcat中的Servlet容器必须实现Container接口，也就是说Servlet容器都是Container接口的实例，接下来将会介绍四种类型的容器 Engine: 表示整个Servlet引擎 Host: 表示包含一个或多个Context容器的虚拟主机 Contetx: 表示一个Web应用程序。一份Context可以有多个Wrapper Wrapper: 表示一个独立的servlet 上述的每一个概念都是实现了org.apache.catalina.Container接口的，这四个实现的标准类分别对应StandardEngine,StandardHost,StandardContetx,StandardWrapper。我们可以通过下图理清它们的层次关系。一般情况下，一个容器可以有0个或多个低层次的子容器 EngineEngine容器表示Tomcat的整个servlet引擎。如果使用了Engine容器，那么它总是处于容器层级的最顶层。添加到Engine容器中的子容器通常是Host或Context的实现。默认情况下，tomcat会使用Engine容器，并且有一个Host容器作为其子容器。 HostHost表示虚拟主机，如果你想在同一个Tomcat部署上运行多个Context容器的话，你就需要使用Host容器。理论上，当你只有一个Context实例时，不需要使用Host实例。但是在Tomcat的实际部署中，总是会使用一个Host容器 Context对应一个独立的Web应用程序，也就是对应我们日常编写的单独Web应用 Context容器的父容器通常是Host容器，也有可能是其他实现，或则如果不必要，就可以不使用父容器 WrapperWrapper封装了一个具体的Servlet 尾言本文主要分析解读了tomcat的总体设计架构，tomcat的源码非常非常的多，如果我们不对其整体架构层次进行分析，直接进行源码阅读，会感觉仿若置身大海，非常的浪费时间。所以若大家有想法阅读tomcat源码，还是有必要先理清其架构体系]]></content>
      <categories>
        <category>web容器</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO Selector 多路复用选择器]]></title>
    <url>%2F2019%2F01%2F20%2FJava-NIO-Selector-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E9%80%89%E6%8B%A9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引言上篇文章我们简单的使用了NIO的Channel通道，本期我们主要来介绍一下选择器（Selector）的使用，Selector是Java NIO核心组件中的一个。在之前介绍5种I/O模型的时候，有介绍过多路复用模型。多路复用模型使得我们可以使用一个线程来管理成千上万的连接，避免了线程上下文切换带来的开销，使得性能得到极大的提升 基本模型选择器Selector使用的基本模式，跟传统BIO处理模型不一样。传统BIO往往我们会使用多线程来提升处理性能，也就是说每接入一个Client，Server端就会为其新开一个线程，以此来提升并发吞吐量，使用这种模式的弊端很明显，因为线程是系统非常重要的资源，当并发量少的时候，感觉不到，一旦并发量上来，就会出现瓶颈。 再来看Selector是如何处理的，首先每接入一个Client，我们可以通过Selector选择器注册感兴趣的事件，然后通过一个线程去不停的轮询检测各个Client是否有感兴趣的事件发生，有则顺序处理该Client就绪的各个事件。 Selector 使用实例我们先来看一个Selector非常常见的使用例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344try &#123; // 打开一个通道 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(8890)); // 打开 选择器 selector Selector selector = Selector.open(); // 设置非阻塞 serverSocketChannel.configureBlocking(false); // 为ServerSocketChannel注册 OP_ACCEPT 事件，返回一个SelectionKey 对象 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; // 返回至少有一个事件就绪的通道数，该方法是阻塞的 int readyNum = selector.select(); if (readyNum == 0) &#123; continue; &#125; // 返回就绪的 SelectionKey集合 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iteratorKeys = selectionKeys.iterator(); // 遍历所有就绪的SelectionKey集合 while (iteratorKeys.hasNext()) &#123; SelectionKey key = iteratorKeys.next(); iteratorKeys.remove(); // 判断就绪的具体事件 if (key.isValid()) &#123; if (key.isAcceptable()) &#123; ServerSocketChannel serverChannel = (ServerSocketChannel) key.channel(); // 接受一个新连接 SocketChannel channel = serverChannel.accept(); channel.configureBlocking(false); // 为该Channel注册可读事件 channel.register(selector, SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; ... &#125; &#125; &#125; &#125;&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 通过查看上面的代码，可知我们通过Selector.open()创建了一个选择器，并且通过SocketChannel的register方法注册了选择器和事件，其中register方法会返回一个SelectionKey对象，该对象其实就是维护了Channel和Selector的对应关系 SelectionKey上文我们提到SelectionKey对象维护了Channel和Selector的对应关系，现在我们来看下SelectionKey对象内部几个非常重要的属性和方法 属性 OP_READ OP_WRITE OP_CONNECT OP_ACCEPT 可注册的四个感兴趣的项目 interestOps 所有感兴趣的集合 readyOps 所有就绪的兴趣集合 方法 boolean isValid() 判断该SelectionKey是否有效 void cancel() 取消该SelectionKey中 通道与其选择器 的注册 int interestOps() 返回该SelectionKey所包含的所有兴趣（可读可写）集合 SelectionKey interestOps(int ops) 设置一个感兴趣的项目 int readyOps() 返回已经就绪的兴趣集合 boolean isWritable() 判断是否可写 boolean isReadable() 判断是否可读 boolean isConnectable() 判断是否可连接 boolean isAcceptable() 判断是否可接受 Object attach(Object ob) 在该SelectionKey中附加一个对象信息 Object attachment() 获取附加对象信息 Selector讲完SelectionKey和Selector的关系之后，我们再次回到Selector类，我们首先需要知道Selector中3个重要的SelectionKey集合 keys：所有注册到Selector的Channel所表示的SelectionKey都会存在于该集合中。keys元素的添加会在Channel注册到Selector时发生。 selectedKeys：该集合中的每个SelectionKey都是其对应的Channel在上一次操作selection期间被检查到至少有一种SelectionKey中所感兴趣的操作已经准备好被处理。该集合是keys的一个子集。 cancelledKeys：执行了取消操作的SelectionKey会被放入到该集合中。该集合是keys的一个子集。 接下来将会介绍上文例子中所用到的几个方法 Selector.open()这个静态方法可以打开一个Selector选择器 123public static Selector open() throws IOException &#123; return SelectorProvider.provider().openSelector();&#125; 通过查看源码可知在Linux系统下默认会使用EpollSelectorImpl来作为Selector实现类，注意各个系统下默认的实现类是不同的。 selector.select()Selector的select()方法会返回事件就绪的SelectionKey数目（也就是就绪的Channel数） 并且该方法会一直阻塞直到至少一个channel被选择(即，该channel注册的事件发生了)为止，除非当前线程发生中断或者selector的wakeup方法被调用 该方法还有一个重载select(long timeout)，可以自定义超时时间 selector.selectNow()该方法与上面方法类似，但该方法不会发生阻塞，即使没有一个channel被选择也会立即返回 selector.selectedKeys()返回已就绪的SelectionKey集合，该方法在执行了selector.select()后调用，因为在执行selector.select()后就表示至少有一个SelectionKey已经就绪 尾言好了，本篇文章就介绍到这里了，篇幅有限加上本人对NIO的理解也有待加深，希望可以在之后更深入的对Java NIO的实现进行分析。]]></content>
      <categories>
        <category>java基础</category>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无参read返回int类型为何要与上0xff]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%97%A0%E5%8F%82read%E8%BF%94%E5%9B%9Eint%E7%B1%BB%E5%9E%8B%E4%B8%BA%E4%BD%95%E8%A6%81%E4%B8%8E%E4%B8%8A0xff%2F</url>
    <content type="text"><![CDATA[引言使用java io 包时，InputStream 类中的有好几个read()方法，并且返回值也都是int类型，这样就使得初学者很容易搞混，其实虽然返回值都是int类型，但所表示的意义确是不一样的 有参 read(byte b[], int off, int len)先看有参的read方法。有参的read比较好理解，将读取到的数据写入字节数组(从字节数组的指定位置开始写入) 三个入参 b[] 存储读取到的数据的字节数组 off 从目标数组b[]的off位开始写入，一般都是从0开始 len 要读取的字节码长度，一般会是存储数组b[]的长度 这里的int类型的返回值是实际读取的字节数，如果检测到无数据可读时会返回 -1 无参 read()123456/** * 从输入流读取下一个字节的数据。返回值为`int类型`，值范围在`0-255`之间。如果由于到达流 * 的末尾而没有可用的字节，则返回`-1`。此方法将一直阻塞，直到输入数据可用、检测到流的结 * 尾或引发异常为止 */public abstract int read() throws IOException; 从输入流读取下一个字节的数据。返回值为int类型，值范围在0-255之间。如果由于到达流的末尾而没有可用的字节，则返回-1。此方法将一直阻塞，直到输入数据可用、检测到流的结尾或引发异常为止 我们再来看一下这个方法的具体实现 1234567891011public int read() throws IOException &#123; if (eof) &#123; return -1; &#125; temp = new byte[1]; int n = read(temp, 0, 1); if (n &lt;= 0) &#123; return -1; &#125; return temp[0] &amp; 0xff;&#125; 到这里就很奇怪了，这个方法是返回下一个字节的数据，可是为什么要返回一个int类型，而不直接返回 byte 类型？并且返回int类型时还有一个&amp; 0xff操作，为什么还要执行这个与操作呢？下面就让我们好好分析一下，为何要返回int类型，而不直接返回byte类型，以及为何会先执行一个&amp; 0xff操作 为何要返回int类型在读取字节时，我们肯定需要一个标识来表示已经读到了字节流末尾，一般会返回-1来标识，但是如果是返回byte类型，就无法标识是否到了文件末尾。所以单凭这点，这里就不能返回byte类型 为何要执行与操作&amp; 0xff再返回int类型上面解释了为何要返回int类型，可是貌似返回int类型也并没有解决问题.. 看这么一个情况，万一返回的单个字节以二进制表示是1111 1111，转换成int类型会高位补符号位1，也就是1111 1111 1111 1111 1111 1111 1111 1111，刚好是-1(Java中数字是以补码形式存储的)，所以这里就会产生混乱，我们无法区分返回-1是不是到了字节流的末尾 那么这个问题该怎么解决呢？这里要解决的问题其实就是当还没有读到字节流末尾时不能返回-1，并且二进制字节流也不能改变所以这里就加入了&amp; 0xff操作，我们再来看前面返回-1的例子1111 1111高位自动补1后与上0xff(0000 0000 0000 0000 0000 0000 1111 1111) 11111 1111 1111 1111 1111 1111 1111 1111 &amp; 0000 0000 0000 0000 0000 0000 1111 1111 = 0000 0000 0000 0000 0000 0000 1111 1111 可知执行了&amp; 0xff操作后，相当于永远不会返回负数了，也就不会存在返回-1和到字节流末尾返回-1冲突的情况，并且实际的二进制结构也没有改变，可以说是完美的解决了这个问题。 上面的1111 1111会自动高位补符号位的原因是，当Java检测到byte要转化或将要转换成高位类型时，会自动补高位符号位 补符号位这里再解释一下补符号位我们知道byte占一个字节8位，而int类型占4个字节32位，所以byte类型向上转换成int类型时需要补符号位，正数补0，负数补1。我们补符号位的目的是为了类型转换后大小和符号位都保持不变。 总结本篇文章虽然是从IO的read方法接入，其实还是跟Java内部的编码格式有关，如数字在Java内存中是以补码存储的，数字类型转换会高位补符号位等等，要彻底搞懂还是要花些时间的。]]></content>
      <categories>
        <category>java基础</category>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>JDK源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO Channel 通道]]></title>
    <url>%2F2019%2F01%2F10%2FJava-NIO-Channel-%E9%80%9A%E9%81%93%2F</url>
    <content type="text"><![CDATA[引言上一篇文章主要介绍了Java NIO Buffer的使用及内部实现原理，本期我们将会认识到Java NIO 另一个非常重要的特性Channel（通道） 对比传统IO流在认识Java NIO Channel通道之前，我们有必要对比一下NIO Channel与传统I/O流的区别，以及它的优势在哪里: 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。 通道可以异步地读写。（不会阻塞进程） 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入(面向缓冲区)。 Channel 分类下面列举的是JAVA NIO Channel的一些主要实现： FileChannel 文件通道 SocketChannel 通过TCP读写网络中的数据。 ServerSocketChannel TCP服务端，可以读写网络中的数据，可以监听新进来的TCP连接 DatagramChannel 通过UDP读写网络中的数据 接下来我将主要对文件通道和Socket通道的使用做分析 文件通道 FileChannel我们无法直接打开一个FileChannel，需要通过使用一个InputStream、OutputStream或RandomAccessFile来获取一个FileChannel实例。并且FileChannel无法设置为非阻塞模式，它总是运行在阻塞模式下,也就是说FileChannel的read write方法都是阻塞的。 读写数据下面是通过RandomAccessFile打开FileChannel进行数据读写的示例： 写数据至指定文件12345678910111213RandomAccessFile file = new RandomAccessFile(&quot;hello.txt&quot;, &quot;rw&quot;);FileChannel fileChannel = file.getChannel();ByteBuffer buffer = ByteBuffer.allocate(512);// 将要写的数据写入缓冲区buffer.put(&quot;见到你真好&quot;.getBytes(&quot;utf-8&quot;));// 切换缓冲区至可读模式buffer.flip();// 开始写入文件fileChannel.write(buffer); // 返回当前写入的字节数file.close();fileChannel.close(); 从文件中读取数据12345678910111213RandomAccessFile file = new RandomAccessFile(&quot;hello.txt&quot;, &quot;rw&quot;);FileChannel fileChannel = file.getChannel();ByteBuffer buffer = ByteBuffer.allocate(512);fileChannel.read(buffer);// 切换缓冲区至可写模式buffer.flip();byte data [] = new byte[buffer.limit()];// 将数据写至 byte数组buffer.get(data);System.out.println(new String(data));file.close();fileChannel.close(); Socket 通道同样，相对于传统BIO的Socket，ServerSocket。NIO也提供了对TCP/IP协议封装的套接字通道： SocketChannel ServerSocketChannal 下面我们来看一下它们的基本使用 SocketChannel 打开通道12345// 打开一个通道SocketChannel channel = SocketChannel.open();// 与Server建立连接channel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8890)); ServerSocketChannel 打开通道接受连接123456// 打开通道ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();// 绑定端口serverSocketChannel.socket().bind(new InetSocketAddress(8890));// 接受一个Socket连接 默认是阻塞模式SocketChannel channel = serverSocketChannel.accept(); 要点SocketChannel,ServerSocketChannel 也可以设置成非阻塞模式，设置成非阻塞模式的话，accept，read，write 方法会立即返回， 因此需要我们在代码不断的轮询去判断连接和数据是否就绪 尾言本篇文章主要介绍了Java NIO中Channel(通道)的使用，其使用与传统I/O流相比其实更加的易用。下期将会介绍Java NIO的核心Selector选择器的基本使用]]></content>
      <categories>
        <category>java基础</category>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的乱码问题]]></title>
    <url>%2F2018%2F12%2F30%2FJava%E4%B8%AD%E7%9A%84%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[引言在写Java代码的时候，大家应该都遇到过各种乱码问题，然后开始查资料，结果原因无非是编码格式不一致所导致的乱码，解决方式也是千篇一律，统一使用UTF-8就OK了。 是的这么做乱码问题肯定可以解决，可我们似乎还不太清除是哪一步编码转化除了问题呢？ 阅读本篇文章前建议先阅读 浅析计算机字符集和编码，能够对编码有一个大概的了解 Java如何处理编码问题我们知道Java是使用了Unicode字符集，并且字符在内存中是以UTF-16编码格式来存储的，什么意思呢，就是纵然外部有各种Unicode编码格式，我Java内部使用UTF-16编码是不会变的。 以下例子证明字符在内存中是以UTF-16编码的 12345678char c = &apos;\u738b&apos;; // 王的UTF-16编码是 738bSystem.out.println(c); // 王// 输出c在内存中的16进制数System.out.println(Integer.toHexString(c)); // 738b 既然Java内部编码（内码）格式是UTF-16是不会变的，那我们读取不同的编码格式时，必然涉及到了转化过程，下面我们来看个例子 123456String s = &quot;王&quot;;byte [] bytes = s.getBytes();System.out.println(bytes.length); // 输出 3 上面的例子，可以看到相同的字符王，存储在char中两个字节，转换成字节流输出后变成占用3个字节了。问题来了，这个过程发生了什么了？ 上面代码中getBytes()方法其实我们使用了默认的UTF-8编码格式，其实完整的写法应该是byte [] bytes = s.getBytes(&quot;UTF-8&quot;)，这里其实就是获取了UTF-8编码格式的字节流。那么这里又是如何获取到字节王的UTF-8编码的呢？ 看下图，可知任何编码转换都会经由Unicode字符集中转。例如我们读取UTF-8编码的字符，会先转化成Unicode字符，然后再转成UTF-16编码在内存中存储。反过来也是类似 乱码问题出现在哪一步现在我们再来看引言里所说提到的乱码问题，看看乱码问题一般是出现在了哪一步。上文提到，我们读取字符时，会先将内存中以UTF-16编码的字符转换成我们需要的编码格式，如Java默认就是UTF-8，那么当我们以特定的编码格式传输字节流时，接收端也必然需要以同样的编码格式去接收，不然就无法解析出正确的Unicode字符，进而也无法转换成正确的UTF-16编码在JVM内存中存储，那么必然会出现乱码问题。 总结写本篇文章的目的是为了加深自己对Java内部编码的认识，乱码问题也是很多初学者非常痛恨和恐惧的，希望本篇文章也可以对有疑惑的同学有所帮助]]></content>
      <categories>
        <category>java基础</category>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO Buffer 分析]]></title>
    <url>%2F2018%2F12%2F28%2FJava-NIO-Buffer-%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[引言JDK 1.4 之后引入了NIO（New IO或 Non Blocking IO），我觉的可以称其为New IO，因为NIO基本重写所有标准IO的API，完全可以替代标准的Java IO API。并且NIO支持面向缓冲区(Buffer)的、基于通道(Channel)的IO操作，可以以更加高效的方式进行文件的读写操作。 NIO的核心主要包括3部分 Buffer 缓冲区 Channel 通道 文件通道 Socket通道 Selector 选择器 本篇文章会对NIOBuffer缓冲区的使用及实现原理做分析 体系Java NIO 提供了以下几种Buffer类型可供使用 ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 这些Buffer的名字已经非常清晰的指明了这些Buffer所各自承载的不同数据类型 下面的分析我都将以ByteBuffer为例子 基本使用ByteBuffer的使用比较简单，但若不理解其内部实现原理，也非常容易搞混。我们先来介绍其简单的使用 创建缓冲区创建缓冲区主要有两种常用方式 allocate 开辟指定大小的缓冲区 wrap 使用字节数组开辟新的缓冲区，对缓冲区的修改将导致数组被修改。新缓冲区的容量（position）和限制（limit）将为该数组的长度 123456// 通过 allocate 创建ByteBuffer byteBuffer = ByteBuffer.allocate(1024);// 通过 wrap 创建byte [] buf = new byte[1024];ByteBuffer.wrap(buf); 读写数据使用ByteBuffer读写数据比较简单 写数据往Buffer中写数据只需要调用put方法，该方法有多个重载，可以以不同的方式写数据这里只列举3个 put(byte b) 在当前位置将给定字节写入此缓冲区 put(int i， byte b) 在指定位置将给定字节写入此缓冲区 put(byte[] src, int offset, int length) 将字节从给定源数组传输到此缓冲区。如果从数组复制的字节比数大于剩余的缓冲区容量，会抛出BufferOverflowException异常 读数据从Buffer中读取数据只需要调用get方法，该方法同样有多个重载，可以以不同的方式读数据 get() 获取当前位置的单个字节 get(int i) 获取指定位置的单个字节 get(byte[] dst, int offset, int length) 从此缓冲区中获取字节并传输到给定的目标数组中，如果缓冲区中的剩余字节少于满足请求所需的字节数，会抛出BufferUnderflowException异常 下面是一个抛出BufferUnderflowException的例子 123456ByteBuffer byteBuffer = ByteBuffer.allocate(1024);String s = &quot;hello&quot;;byteBuffer.put(s.getBytes());byteBuffer.flip(); // 翻转 下文会提到byte [] bufs = new byte[9]; // 缓冲区实际只有5个字节大小，大于此大小就会抛出异常byteBuffer.get(bufs); // 抛出异常 flip 方法上文抛出BufferUnderflowException的例子，不知道大家有没发现，我们的代码在读写转换时用了flip方法来进行读写操作的转换，缓冲区在进行读写转换的时候必须调用flip方法，那么为何要这么做呢？下面我将会对flip方法的内部实现原理进行分析，在分析之前，我们有必要先认识一下Buffer的capacity position limit mark四个变量属性 capacity 表示缓冲区的容量，大小不可变且不可为负 position 下一个要读取或写入的元素的位置索引 limit 下一个不应该被读取或写入的元素的位置索引 mark 标记位，可以通过这个标记位返回此位置 四者的大小关系 mark &lt;= position &lt;= limit &lt;= capacity 知道了这四个变量的含义之后，我们再来根据例子来看看一步一步往下分析吧 一. 首先，我们通过ByteBuffer.allocate(6)开辟一个大小为6的缓冲区 123456789101112// 通过allocate 开辟缓冲区public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125;// HeapByteBuffer 初始化HeapByteBuffer(int cap, int lim) &#123; // package-private // 这里前四个参数依次是 mark position limit capacity super(-1, 0, lim, cap, new byte[cap], 0);&#125; 通过查看allocate方法的源码，可知其内部初始结构如下图(Buffer内部其实是数组实现，下标从0开始) mark = -1 position = 0 limit = capacity = 6 二. 然后我们现在通过put方法加入1个字节数据此时的内部结构如下图 mark = -1 position = 1 limit = capacity = 6 三. 加一个太少了，我们再添加3个字节数据至缓冲区中此时的内部结构如下图 mark = -1 position = 4 limit = capacity = 6 四. 现在数据已经全部加完了，我们准备读数据了，必须要调用flip方法先来看看flip方法的内部实现 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; flip内部其实是将 position的值赋给了limit，并将position位置归0，如下图显示 五. 成功翻转之后，就可以往外读数据了，假设往外读4个数据此时内部结构如下图，并且 position = limit了，达到了最大可读字节数 mark = -1 position = 4 limit = 4 capacity = 6 通过上面这个例子，对flip方法的翻转逻辑已经进行了非常详细的分析，并且可以得出结论capacity的是绝对不变的，不会随着读写操作而改变。mark变量的值会在下文reset mark 方法中用到 reset mark 方法顾名思义，mark就是打标记的意思，reset表示重置的意思。这两个操做是紧密联系的，由mark()方法在当前position位置做标记，然后在需要重置到标记位置的时候，调用reset方法重置 看一下这两个方法的内部实现 1234567891011public final Buffer mark() &#123; mark = position; return this;&#125;public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; 方法的内部实现非常简单，通过对变量mark的编辑来标记当前位置，在需要重置的时候，把变量mark的值赋给当前下标索引position来达到重置的目的。 clearclear方法比较简单，将position = 0，limit = capacity，mark = -1。有点类似初始化时的操作 compact最后再来介绍一下compact方法，首先我们先来看一个场景 12345 while (in.read(buf) &gt;= 0 || buf.position != 0) &#123; buf.flip(); out.write(buf); buf.clear();&#125; 上面这个例子，在非阻塞模式下是会有问题的，因为write方法我们并不知道一次性可以写多少个字节，所以有可能还有未写入的字节数据，这时候我们却又重新读取了新的数据，就会导致覆盖了原有还未写入的数据。 只需要改成以下的方式即可，该方法的作用是将position与limit之间的数据复制到buffer的开始位置，复制后position = limit -position,limit = capacity 12345 while (in.read(buf) &gt;= 0 || buf.position != 0) &#123; buf.flip(); out.write(buf); buf.compact();&#125; 总结本编文章比较详细的分析了Java NIOBuffer的基本使用及内部实现原理。Buffer的内部实现其实比较简单，需要着重理解的其实就是capacity position limit mark这四个变量属性。]]></content>
      <categories>
        <category>基础</category>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/O模型简介]]></title>
    <url>%2F2018%2F12%2F27%2FI-O%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[引言在深入学习netty之前，还是有必要先回顾下I/O模型，I/O模型理解起来会比较抽象，第一次理解需要借助图片以及实际例子去让自己加深印象 模型分类在开始介绍之前，我们先列举一下Unix下可用的5种I/O模型 阻塞式I/O 非阻塞式I/O I/O复用 信号驱动I/O 异步I/O 接下来的模型介绍都是以UDP做为例子，原因是UDP是以数据报的方式进行数据传输，概念比较简单（整个数据要么收到要么没有收到），便于我们去理解I/O模型的核心概念 阻塞式I/O 我们最熟悉的I/O模型就是阻塞式I/O模型，在上图中，应用进程系统调用recvfrom接收数据，但是此时内核缓冲区中数据报还未准备好，所以应用进程会一直阻塞直到内核缓冲区有数据报到达且被复制到应用进程缓冲区 这里我们提一下这里的内核缓冲区和应用进程缓冲区所处的阶段一个输入操作通常包括两个不同的阶段: 等待数据报准备好 (通常是等待数据从网络上到达，当所等待的分组数据到达后，会被复制到内核的某个缓冲区中) 从内核向进程复制数据 (把数据从内核缓冲区复制到应用进程缓冲区中) 例子商场排队吃饭，只能老老实实排队，并且排队的时候不能做其他事情 非阻塞式I/O如果不想进程一直阻塞在那里的话，我们可以设置本次套接字连接为非阻塞的 查看上图可知，在设置连接为非阻塞时，当应用进程系统调用recvfrom没有数据返回时，内核会立即返回一个EWOULDBLOCK错误，而不会一直阻塞到数据准备好。如上图在第四次调用时有一个数据报准备好了，所以这时数据会被复制到应用进程缓冲区，于是recvfrom成功返回数据 当一个应用进程这样循环调用recvfrom时，我们称之为轮询polling。这么做往往会耗费大量CPU时间，实际使用很少 例子还是商场吃饭，只是现在可以取号了。不过仍然需要时不时的去看一下有没有叫到号 I/O 复用 Linux I/O复用模型提供了select poll epoll三组系统调用可做选择，进程通过将一个或多个文件描述符(fd)传递给select或poll或epoll系统调用，通过它们来监测多个fd是否处于就绪状态。select或poll是顺序扫描fd是否就绪，而且支持的fd数量有限，因此使用上有制约。epoll调用基于事件驱动，因此性能更高，当fd就绪时会立即回调rollback 解释一下文件描述符 Linux 内核将所有外部设备都看做一个文件来操作，对一个文件的读写操作会调用内核提供的系统命令，返回一个file descriptor(fd 文件描述符)。而对一个socket的读写也会有相应的描述符，称为socket fd。 现在再来看一下上图，上图以select为例。不难发现进程会阻塞于select调用，直到所关注的某一个文件描述符(套接字)变为可读状态 例子还是商场吃饭，但是现在你可以在手机APP上同时叫多个号了，只要多个号里面有一个号好了就会通知你了 信号驱动I/O 信号驱动I/O的意思就是我们现在不用傻等着了，也不用去轮询。而是让内核在数据就绪时，发送信号通知我们。调用的步骤是，我们通过系统调用sigaction，并注册一个信号处理的回调函数，该调用会立即返回，但是当内核数据就绪时，内核会为该进程产生一个SIGIO信号，并回调我们注册的信号回调函数，这样我们就可以在信号回调函数中系统调用recvfrom获取数据 例子商场吃饭，只要取了号，你也不用去一直看看大屏幕有没有好了，要是叫到号了，会主动发消息告诉你了 异步I/O 异步I/O 与 信号驱动I/O最大区别在于，信号驱动是内核通知我们何时开始一个I/O操作，而异步I/O是由内核通知我们I/O操作何时完成，两者有本质区别 例子都不用去商场吃饭了，直接点个外卖，把等待上菜的时间也给省了 总结本篇文章主要介绍了5种I/O模型，例子也是参考了网上个人觉得比较合理的解释，希望能对此有疑惑的同学有所帮助。另外文章主要参考了Unix 网络编程这本书，有兴趣的同学也可以深入了解]]></content>
      <categories>
        <category>基础</category>
        <category>IO</category>
      </categories>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC 源码解析 （循环依赖的解决）]]></title>
    <url>%2F2018%2F12%2F21%2FSpring-IOC-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%EF%BC%88%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%9A%84%E8%A7%A3%E5%86%B3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言之前的几篇对Spring IOC源码分析的文章，大体上把IOC容器内部实现做了分析，但在有些细节上并没有很深入的去分析。本篇文章主要是分析Spring IOC容器对Bean之间的循环依赖是如何解决的 什么是循环依赖那么什么是循环依赖呢？简单的理解一下，A依赖B，B又依赖A，这就构成了一个最简单的循环依赖，为了帮助大家理解，新建两个互相依赖的类（儿子和爸爸互相依赖没有错吧 ..） 123456789public class Father &#123; private String name; private Son son;&#125;public class Son &#123; private String name; private Father father;&#125; 这两个bean交给Spring管理 123456789&lt;bean id=&quot;son&quot; class=&quot;com.wangjn.demo.impl.Son&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;son&quot;&gt;&lt;/property&gt; &lt;property name=&quot;father&quot; ref=&quot;father&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;father&quot; class=&quot;com.wangjn.demo.impl.Father&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;father&quot;&gt;&lt;/property&gt; &lt;property name=&quot;son&quot; ref=&quot;son&quot;&gt;&lt;/property&gt;&lt;/bean&gt; 启动Spring IOC容器，用getBean方法可以成功获取son对象，并且也注入了father对象，可见Spring为我们解决了循环依赖的问题。可是按照正常创建Bean的流程来说，这个过程将会是一个死循环，因为在创建son对象为son注入father属性时，就会去获取father对象，而在获取father对象赋值son属性的时候，又会去获取son对象，从而就陷入了死循环，然后程序崩溃。 可是结果并不是我们预料的那样，接下来就来分析Spring是如何解决这个问题的 Spring 如何解决循环依赖之前对IOC源码分析的文章中有分析过Bean的创建过程，下面我将对循环依赖实现的某些细节作分析 Spring 用缓存解决循环依赖让我们回到AbstractBeanFactory的doGetBean方法，doGetBean方法就是我们通过容器getBean方法实际调用的逻辑，我们在这里着重关注getSingleton方法，之前的分析中有提到，调用getSingleton(beanName)方法的目的是为了从缓存中直接获取已经创建的Bean，而不必重复去创建。现在让我们进到getSingleton方法里面去看看它都做了啥，从哪个缓存取到了Bean对象 1234567891011protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // 从缓存中获取 bean Object sharedInstance = getSingleton(beanName); ... 省略其他创建bean的代码&#125; getSingleton方法1234567891011121314151617181920212223242526272829public Object getSingleton(String beanName) &#123; // 默认都是允许提前暴露对象 return getSingleton(beanName, true);&#125;protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 从创建完成的bean缓存中获取bean Object singletonObject = this.singletonObjects.get(beanName); // 判断该bean是否仍在创建中，意思是Bean已经完成实例化，但还不完整。属性还未完全注入 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 从提前暴露的Bean缓存容器（earlySingletonObjects）中获取 singletonObject = this.earlySingletonObjects.get(beanName); // 仍未获取到则从singletonFactories缓存中获取 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); // 加入到提前暴露Bean缓存（earlySingletonObjects）中 this.earlySingletonObjects.put(beanName, singletonObject); // 从singletonFactories缓存中移除 this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; // 返回对象，这里返回的不一定是完全创建的对象 return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125; 从getSingleton方法中我们需要着重关注几个Bean的缓存，标题已经说了，缓存是解决循环依赖的关键，下面我介绍一下上面代码中提到了三种缓存 12345678/** Cache of singleton objects: bean name --&gt; bean instance */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);/** Cache of singleton factories: bean name --&gt; ObjectFactory */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);/** Cache of early singleton objects: bean name --&gt; bean instance */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16); singletonObjects 用于存放创建完成的单例对象 singletonFactories 用于存放对象工厂类，这里是解决循环依赖的 earlySingletonObjects 用于存放提前暴露的单例对象。指的是已经完成Bean的实例化，但还未完成属性注入的不完整对象 再来说上面代码中取缓存的步骤，首先肯定是从singletonObjects中获取完全创建完成的Bean对象，如果获取不到，则从提前暴露对象缓存（earlySingletonObjects）中获取，还获取不到再到singletonFactories中获取 到这里为止，我们只分析了取Bean缓存的过程，所以接下来我们要分析的就是放缓存的过程代码 提前暴露Bean现在让我们去到创建Bean的过程。如果缓存没取到，会执行创建Bean的逻辑，找到AbstractAutowireCapableBeanFactory类的doCreateBean方法，这个方法在之前的文章中有做过分析，但没有对Bean缓存处理做分析。这里我们着重看中间解决循环依赖的那部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // Instantiate the bean. // 封装bean的容器 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 这里是创建 BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null); Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null); mbd.resolvedTargetType = beanType; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Post-processing of merged bean definition failed&quot;, ex); &#125; mbd.postProcessed = true; &#125; &#125; // 判断是否需要提前暴露对象的引用，用于解决循环依赖 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Eagerly caching bean &apos;&quot; + beanName + &quot;&apos; to allow for resolving potential circular references&quot;); &#125; addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; // 这里会与AOP相关 return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; // 依赖注入的主逻辑 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; // 执行一些初始化的方法 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, &quot;Bean with name &apos;&quot; + beanName + &quot;&apos; has been injected into other beans [&quot; + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + &quot;] in its raw version as part of a circular reference, but has eventually been &quot; + &quot;wrapped. This means that said other beans do not use the final version of the &quot; + &quot;bean. This is often the result of over-eager type matching - consider using &quot; + &quot;&apos;getBeanNamesOfType&apos; with the &apos;allowEagerInit&apos; flag turned off, for example.&quot;); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex); &#125; return exposedObject;&#125; 通过看代码，可知在Bean完成实例化之后，注入属性之前，Spring就将这个不完整的Bean放到了singletonFactories缓存中，从而让这个Bean提前进行了暴露。这样子在后续的属性注入操作中，如果存在循环依赖，就会从缓存中获取到这个提前暴露的Bean，从而可以顺利完成依赖注入。但是要注意这时候注入的对象是不完整的，但是因为依赖方已经持有它的引用，所以后续对象的完整性是可以保证的 总结本篇文章主要从Spring对Bean的缓存层面分析了其对循环依赖的解决，虽然是Spring帮我们解决了这个问题，但是对于实现的逻辑我们仍然应该去了解，譬如，通过查看源码可知Spring仅仅对单例类型的循环依赖进行解决，对于有状态的BeanSpring并没有去做处理，而是直接跑出异常，这些都是需要注意的。]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池分析]]></title>
    <url>%2F2018%2F12%2F20%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[引言在并发编程中，我们经常会使用到线程池，当然我们也可以手动一个一个创建线程，那么为何我们还是推崇大家使用线程池进行并发编程呢？借用《Java并发编程的艺术》提到的来说一下使用线程池的优点有3个 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 ThreadPoolExecutor类在日常使用中，大多数情况我们都会使用JDK提供的Executors去创建线程池，Executors利用工厂模式向我们提供了4种线程池实现方式，但是最新的阿里Java开发手册中明确说明了不建议使用Executors去创建线程池，原因是使用Executors创建线程池会使用很多默认值，默认使用的参数有时候是不合理，但是开发者往往会忽略。所以我们应该尽量使用ThreadPoolExecutor类来显示的创建线程池。 下面我们先来看下ThreadPoolExecutor类的继承结构 ￼ Executor接口只含有一个execute(Runnable command)方法，加入一个新的线程 ExecutorService接口相比Executor多个几个方法 123456789101112131415161718192021 public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 我们直接看ThreadPoolExecutor所提供的构造方法 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 现在我们来解释一下各个参数的含义 corePoolSize 核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系 maximumPoolSize 线程池最大线程数 keepAliveTime 空闲线程的存活时间，默认只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用 unit 参数keepAliveTime的时间单位 workQueue 一个阻塞队列，用来存储等待执行的任务 threadFactory 线程工厂，主要用来创建线程 handler 表示当拒绝处理任务时的策略，有以下四种取值 1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 下面再简单再介绍一下ThreadPoolExecutor中几个重要的方法 execute 这个方法其实就是对Executor接口的实现，也是最核心的方法，用于向线程池中提交一个任务执行 submit 该方法也是用于向线程池里提交任务，区别在于submit提交可以有返回值，会返回一个Futrue类型来异步获取执行结果 shutdown 用于关闭线程池 shutdownNow 也是关闭线程池，与shutdown区别在于shutdownNow会尝试关闭正在执行的线程任务 通过源码分析 ThreadPoolExecutor上文我们简单的分析了ThreadPoolExecutor，下面我们将根据源码来进一步分析ThreadPoolExecutor核心功能的实现 先从其核心方法execute开始解读 12345678910111213141516171819202122232425262728293031public void execute(Runnable command) &#123; // 如果传入空对象 则抛出空指针异常 if (command == null) throw new NullPointerException(); int c = ctl.get(); /** * 如果当前正在执行任务的线程数小于 corePoolSize */ if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; /** * 如果当前正在执行任务的线程数大于corePoolSize，且workQueue未满 */ if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 重复检查一次，防止正好此时线程池被shutdown int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; /** * 如果当前正在执行的任务线程数大于corePoolSize，且workQueue已满，则使用 * maximumPoolSize参数创建线程，如果已经到了maximumPoolSize最大值，则启用拒绝 * 策略 */ else if (!addWorker(command, false)) reject(command);&#125; 上面的代码简单总结一下就是 当前正在执行任务的线程数小于corePoolSize时，正常加入执行 当前正在执行任务的线程数大于corePoolSize，且workQueue未满时，则将任务加入等待队列workQueue中 如果当前正在执行的任务线程数大于corePoolSize，且workQueue已满，则会临时扩充线程数，根据maximumPoolSize最大线程数值 如果当前正在执行的任务线程数大于maximumPoolSize 这时已经超出最大可承受的线程数值了，会启用拒绝策略，也就是上文所配置的四种策略之一，默认是抛出异常，加入任务失败 workQueue 任务队列上文有提到任务队列，也就是在等待执行的任务队列。workQueue的本质是一种阻塞队列BlockingQueue，列举三种常用类型 基于数组的先进先出队列，此队列创建时必须指定大小 基于链表的先进先出队列 同步队列 该队列不存储元素，每个插入操作必须等待另一个线程调用移除操作，否则插入操作会一直阻塞 核心功能分析上文中我们通过查看源码知道了新任务加入线程池的策略，下面我们继续往下看，再分析之前，我们可以先思考几个问题 任务等待队列是在何时被执行？ 线程是如何实现重复利用的？，毕竟这是线程池最重要的功能了 空闲线程根据keepAliveTime参数是在哪里被回收的？ 接下来我们继续通过源码来解读这三个问题根据上文execute方法源码，可以看到调用了addWorker方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 这里判断当前线程数是否大于最大值，大于了则返回false if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 新建了一个 Worker w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; // 加锁 mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 把当前这个工作线程加入到 workers 集合中 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 开始执行此worker t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 根据参数core 判断当前线程数是否已经大于corePoolSize或maximumPoolSize，大于则直接返回false 初始化了一个Worker对象，并且加入到了workers集合中，workers是一个Set类型的集合 启动当前这个Worker线程任务 经过上面的分析，可能大概会有疑惑，Worker对象是做啥的？下面我们就来看下Worker类的实现 1234567891011121314151617181920212223242526272829private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; ...&#125; Worker实现了Runnable接口 构造方法中通过ThreadFactory初始化了一个新的线程对象 run()方法调用了ThreadPoolExecutor的runWorker() 重点在runWorker方法中 线程池重复利用机制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获取第一个任务 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 从任务队列中循环获取任务执行 getTask方法有可能会阻塞 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 空实现，可以通过继承`ThreadPoolExecutor`重写此方法 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 执行 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 代码解析到这里，基本可以回答上文所提出的三个问题了 加入到任务队列的任务会在这里被执行，因为Worker对象执行完一个任务后，并不会立刻结束，而是会通过循环调用getTask()方法从任务队列中获取最新任务来执行，这样子就实现了线程的重复利用，而不必每次都重新创建一个Worker对象 当getTask()方法无法获取到最新的任务后，该Worker线程才会被回收。所以第三个问题keepAliveTime的机制必然是在getTask()中实现的 getTask 超时策略123456789101112131415161718192021222324252627282930313233343536373839private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // workers大于corePoolSize，或则允许corePoolSize设置空闲超时时间 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 当前线程数已经大于maximumPoolSize或则已经超时过一次，则直接返回null if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 获取任务，如果timed为true，则等待一定时间（keepAliveTime）未返回的话，会返回null，如果timed未设置为true，则会一直阻塞，直到有数据 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null 判断当前线程池的线程数是否已经大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用workQueue.poll(time,timeUnit)来取任务，这个方法会阻塞等待一定的时间，如果取不到任务就返回null，否则则会调用workQueue.take()来取任务，这个方法会wait释放CPU一直阻塞。 总结一下，只有当我们设置allowCoreThreadTimeOut（核心池线程空闲超时时间）或则当前线程数大于corePoolSize时，keepAliveTime机制才会生效 整个流程到这里大概就分析完了，下图基本绘制了线程池提交任务，执行任务的整个流程 Executors 中几个常用的线程池虽然阿里Java开发规约中不建议我们使用Executors类直接创建线程池，但还是有必要简单介绍几个其中常用的方法 Executors.newCachedThreadPool() 创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE. 将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，workQueue使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程 Executors.newSingleThreadExecutor() 创建容量为1的缓冲池，将corePoolSize和maximumPoolSize都设置为1，workQueue使用的LinkedBlockingQueue Executors.newFixedThreadPool(int) 创建固定容量大小的缓冲池，空闲线程不会销毁。corePoolSize和maximumPoolSize值是相等的，workQueue使用的是LinkedBlockingQueue 总结本篇文章主要从对线程池的配置使用，以及源码实现做了分析，总体上比较全面的分析了Java线程池的实现。]]></content>
      <categories>
        <category>java基础</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP 源码解析三（代理对象的创建）]]></title>
    <url>%2F2018%2F12%2F15%2FSpring-AOP-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%89%EF%BC%88%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言上期我们对AOP核心概念及接口做了粗浅的分析，这期我们主要来探讨一下代理对象的创建过程。在开始之前，先问自己几个问题 Spring是如何帮我们去选择合适的Advice的？找到了又是通过何种方式创建代理对象的？ 好了，现在我们开始分析代理对象的创建过程，首先，先来看一下AspectJAwareAdvisorAutoProxyCreator.class类的继承体系 可以看到AspectJAwareAdvisorAutoProxyCreator.class主要实现了这几个接口 Aware Bean创建时注入一些容器属性等 BeanPostProcessor IOC 扩展点 AopInfrastructureBean 标识此类是AOP系统类，不能被代理 这里我们仅需要关注BeanPostProcessor接口的实现，因为代理的创建是在BeanPostProcessor接口的postProcessAfterInitialization方法执行时创建的，postProcessAfterInitialization方法的具体实现逻辑是在抽象父类AbstractAutoProxyCreator中实现的 入口上文中提到AspectJAwareAdvisorAutoProxyCreator.class是BeanPostProcessor接口的实现，现在就让我们打开它的入口源码慢慢分析 12345678910public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; // 返回用做缓存的key键 Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125; 1234567891011121314151617181920212223242526272829protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (beanName != null &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // 判断当前的Bean是否是AOP本身的系统类，是的话则跳过，不做代理操作 if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 为该Bean找到一个合适的 advisor Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); // 返回不为空 if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理对象 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; // 没有找到合适的 advisor 则直接返回原始Bean this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 看完wrapIfNecessary方法，这里就是创建代理对象的全过程。其实在这个方法中一共就做了两件事情: getAdvicesAndAdvisorsForBean方法 筛选合适的Advisor对象，其实就是为当前目标对象找到合适的通知(Advice) createProxy方法 根据筛选到的切面（Advisor）集合为目标对象创建代理 下面我们分别对这两件事情作分析 寻找合适的 AdvisorfindEligibleAdvisors方法是在父类AbstractAdvisorAutoProxyCreator中，且直接调用了findEligibleAdvisors 方法 123456 List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; &#125; return advisors.toArray();&#125; 1234567891011protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 找到容器中的全部通知 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 筛选合适通知对象集合 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 这里也是分开做了两件事情 首先从Spring 容器中获取到全部Advisors集合 执行筛选逻辑，获取符合条件的Advisors集合 找到Spring容器中全部 Advisor这里是调用了BeanFactoryAdvisorRetrievalHelper.class的方法去获取到Spring 容器中全部Advisor集合的，这里需要注意BeanFactoryAdvisorRetrievalHelper.class类的初始化是在setBeanFactory方法中进行的 123protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; return this.advisorRetrievalHelper.findAdvisorBeans();&#125; BeanFactoryAdvisorRetrievalHelper的findAdvisorBeans方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public List&lt;Advisor&gt; findAdvisorBeans() &#123; // Determine list of advisor bean names, if not cached already. String[] advisorNames = null; synchronized (this) &#123; // 尝试从缓存中获取 Advisor 类型的Bean名称 advisorNames = this.cachedAdvisorBeanNames; // if (advisorNames == null) &#123; // 从BeanFactory中获取 Advisor 类型的全部Bean名称集合，并设置缓存 advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors( this.beanFactory, Advisor.class, true, false); this.cachedAdvisorBeanNames = advisorNames; &#125; &#125; if (advisorNames.length == 0) &#123; return new LinkedList&lt;Advisor&gt;(); &#125; List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;(); // 遍历 Advisor类型 BeanName 集合 for (String name : advisorNames) &#123; // 判断是否合法，这里返回都是true if (isEligibleBean(name)) &#123; // 判断该Bean是否正在创建中，创建中则直接跳过 if (this.beanFactory.isCurrentlyInCreation(name)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Skipping currently created advisor '" + name + "'"); &#125; &#125; else &#123; try &#123; // 根据BeanName和Advisor类型从BeanFactory中获取Bean advisors.add(this.beanFactory.getBean(name, Advisor.class)); &#125; catch (BeanCreationException ex) &#123; Throwable rootCause = ex.getMostSpecificCause(); if (rootCause instanceof BeanCurrentlyInCreationException) &#123; BeanCreationException bce = (BeanCreationException) rootCause; if (this.beanFactory.isCurrentlyInCreation(bce.getBeanName())) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Skipping advisor '" + name + "' with dependency on currently created bean: " + ex.getMessage()); &#125; // Ignore: indicates a reference back to the bean we're trying to advise. // We want to find advisors other than the currently created bean itself. continue; &#125; &#125; throw ex; &#125; &#125; &#125; &#125; return advisors;&#125; findAdvisorBeans方法的的目的非常明确，就是找到容器中全部的Advisor 先尝试从缓存中获取Advisor集合 缓存中不存在，则执行获取逻辑 获取到了所有类型为Advisor的Bean的名称 根据获取到的BeanName获取Bean 为当前Bean匹配合适的 Advisor在以上的步骤中，我们已经拿到了容器中所有的Advisor对象集合，也就是说我们已经拿到了容器中所有已配置的AOP切面。接下里的事情就是为当前的目标对象筛选出适合的Advisor集合，现在我们开始分析AbstractAdvisorAutoProxyCreator.class的findAdvisorsThatCanApply方法 123456789101112protected List&lt;Advisor&gt; findAdvisorsThatCanApply( List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123; // 调用 AopUtils.findAdvisorsThatCanApply 为当前Bean筛选合适的 Advisor return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123; ProxyCreationContext.setCurrentProxiedBeanName(null); &#125;&#125; findAdvisorsThatCanApply方法里调用了工具类AOPUtils的findAdvisorsThatCanApply方法 123456789101112131415161718192021222324public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) &#123; if (candidateAdvisors.isEmpty()) &#123; return candidateAdvisors; &#125; List&lt;Advisor&gt; eligibleAdvisors = new LinkedList&lt;Advisor&gt;(); // 先找出 IntroductionAdvisor 类型的Advisor for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; boolean hasIntroductions = !eligibleAdvisors.isEmpty(); // 再从余下的Advisor中继续匹配 for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor) &#123; // already processed continue; &#125; if (canApply(candidate, clazz, hasIntroductions)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; return eligibleAdvisors;&#125; 以上代码逻辑会先筛选出IntroductionAdvisor类型的Advisor，再筛选余下的其他Advisor 123public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass) &#123; return canApply(advisor, targetClass, false);&#125; 12345678910111213public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; if (advisor instanceof IntroductionAdvisor) &#123; return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); &#125; else if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pca = (PointcutAdvisor) advisor; return canApply(pca.getPointcut(), targetClass, hasIntroductions); &#125; else &#123; // It doesn&apos;t have a pointcut so we assume it applies. return true; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, &quot;Pointcut must not be null&quot;); // 先判断类型是否匹配 if (!pc.getClassFilter().matches(targetClass)) &#123; return false; &#125; // 获取切点方法匹配器 MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; // No need to iterate the methods if we&apos;re matching any method anyway... return true; &#125; IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;Class&lt;?&gt;&gt;(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); classes.add(targetClass); for (Class&lt;?&gt; clazz : classes) &#123; // 获取当前目标class的所有方法 Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); for (Method method : methods) &#123; // 调用 methodMatcher.matches 判断当前方法是否匹配该切点 if ((introductionAwareMethodMatcher != null &amp;&amp; introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions)) || methodMatcher.matches(method, targetClass)) &#123; return true; &#125; &#125; &#125; return false;&#125; canApply是用于筛选核心方法，在上期分析连接点Pointcut接口时，我们知道Pointcut持有ClassFilter和MethodMatcher对象，具体的筛选逻辑就是由它们完成的，至于在它们具体的macthes方法是是如何实现筛选的，这里我也没有进行过深入分析，感兴趣的可以在其实现类AspectJExpressionPointcut.class中继续查看 生成代理对象在上文的分析结束后，我们已经筛选出来了合适的 Advisor，Advisor持有Advice(通知)，接下来的操作就是根据我们配置的Advice为目标对象创建代理对象了 123456789101112131415161718192021222324252627282930313233343536protected Object createProxy( Class&lt;?&gt; beanClass, String beanName, Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; // 首先创建一个代理创建工厂类，之后的操作都是为此工厂配置属性 ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); // 判断配置属性proxy-target-class 是否等于False if (!proxyFactory.isProxyTargetClass()) &#123; // 判断目标 BeanDefinition是否配置preserveTargetClass 为 ture，是的话配置CGLIB动态代理 if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; else &#123; // 设置目标类接口到proxyFactory，如果没有实现接口则使用CGLIB代理 evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); // proxyFactory 设置 advisors proxyFactory.addAdvisors(advisors); // 设置目标对象资源 proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; // 创建代理 return proxyFactory.getProxy(getProxyClassLoader()); 创建代理对象前，会新建一个代理工厂创建类，并为此工厂类配置相关属性，例如proxy-target-class的配置，虽然默认配置是false会使用JDK动态代理，但如果没有实现接口，也会自动设置proxy-target-class为true使用CGLIB创建代理对象 完成ProxyFactory的配置之后，就可以通过它创建代理对象了123456/** * 创建代理对象 */public Object getProxy(ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader);&#125; 调用父类ProxyCreatorSupport的createAopProxy方法，获取到代理创建工厂，工厂类(DefaultAopProxyFactory)是在父类的构造方法中创建的 1234567protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; // 获取代理创建工厂类 （DefaultAopProxyFactory.class）创建代理对象 return getAopProxyFactory().createAopProxy(this);&#125; 最终在DefaultAopProxyFactory工厂类createAopProxy中创建代理对象 12345678910111213141516171819public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; // 这里主要是判断 proxy-target-class 属性是否为true。默认是false if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; + &quot;Either an interface or a target is required for proxy creation.&quot;); &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; // 使用CGLIB动态代理 return new ObjenesisCglibAopProxy(config); &#125; else &#123; // 默认使用JDK动态打理 return new JdkDynamicAopProxy(config); &#125;&#125; 最终的代理的创建是在ObjenesisCglibAopProxy或JdkDynamicAopProxy中完成的，至于更具体的创建逻辑，因为这一系列的源码分析只是为了能够对AOP的整体逻辑有清晰的认识，所以这里就不做更详细的分析了。 尾言本篇文章分析了AOP代理创建的整个过程，纵观整篇文章，篇幅有限，其中还有很多的点没有详细展开分析，只是粗略的分析了AOP代理的创建过程，惭愧 … 。分析有误的地方，希望大家可以指出。]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP 源码解析二 （AOP核心概念及接口分析）]]></title>
    <url>%2F2018%2F12%2F10%2FSpring-AOP-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BA%8C-%EF%BC%88AOP%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E5%8F%8A%E6%8E%A5%E5%8F%A3%E5%88%86%E6%9E%90%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言上期对Spring AOP的配置入口做了一个很简单的源码解读，相当于一道开胃菜，有些概念也并没有细说。这期我们主要来理一下AOP的整体概念，以及相关的接口分析 AOP概念面向切面编程AOP其实是对OOP编程方式的一种补充，OOP中模块化的关键单元是类，而在AOP中，模块化单元则是Aspect，我们又把它叫做切面。对于Spring IOC来说，Spring AOP是对IOC的强有力增强。 接下来我们将对AOP的核心接口做详细的分析 AOP核心接口Pointcut 切点切入点，顾名思义，就是我们要切入某个点的具体位置，对于切入点的位置选择，我们常用aspect表达式来进行定位。我们先来看一下Pointcut接口，看看它定义了哪些东西 1234567891011121314151617public interface Pointcut &#123; /** * 返回一个类型过滤器 * @return the ClassFilter (never &#123;@code null&#125;) */ ClassFilter getClassFilter(); /** * 返回一个方法匹配器 * @return the MethodMatcher (never &#123;@code null&#125;) */ MethodMatcher getMethodMatcher(); Pointcut TRUE = TruePointcut.INSTANCE;&#125; 可以看到Pointcut接口定义了两个方法，一个用于返回一个类型过滤器，一个返回了一个方法选择器，我们可以再具体的看一下这两个接口的内容 12345678910111213141516171819202122232425262728293031public interface ClassFilter &#123; /** * 判断切入点于给定的接口或目标类是否类型匹配 */ boolean matches(Class&lt;?&gt; clazz); ClassFilter TRUE = TrueClassFilter.INSTANCE;&#125;public interface MethodMatcher &#123; /** * 检查是否有此方法的静态匹配 */ boolean matches(Method method, Class&lt;?&gt; targetClass); /** * 是否运行时 */ boolean isRuntime(); /** * 检查是否有此方法的运行时(动态)匹配 */ boolean matches(Method method, Class&lt;?&gt; targetClass, Object... args); MethodMatcher TRUE = TrueMethodMatcher.INSTANCE;&#125; 可以看到，上面两个接口的核心都是matches方法，都是用于判断目标类型或目标方法与此切入点是否匹配。在上一篇文章中我们有提到一个Pointcut接口的具体实现，（AspectJExpressionPointcut.class），这个是我们最常用的Pointcut接口实现，里面封装了对aspect表达式用于匹配切入点方法的具体实现 Advice 通知Advice 通知，翻译成中文是建议的意思，在上面我们知道了pointcut是用来选择切入点的，那选定了切入点之后自然就是要执行具体织入的AOP逻辑，并且还要在一个合适的位置去执行，而这个合适的位置就是我们常说的在目标方法前 目标方法后或则环绕通知执行，好了，还是让我们看一下Advice接口，看看Spring为我们定义了哪几种通知类型 Advice 是一个空接口，具体的类型在实现中123public interface Advice &#123;&#125; 上篇文章有提到Advice的具体实现类型，这里我就直接把每种类型通知对应的实现类列出来了 前置通知 AspectJMethodBeforeAdvice.class 在目标方法执行前执行 后置通知 AspectJAfterAdvice.class 在目标方法执行后执行（无论是否抛异常都会执行） 环绕通知 AspectJAroundAdvice.class 在目标方法执行前后执行 异常通知 AspectJAfterThrowingAdvice.class 目标方法执行异常时执行 后置正常返回通知 AspectJAfterReturningAdvice.class 目标方法正常返回结果后执行 Aspect 切面Aspect切面，但看这个单词其实不好理解，但是当我们知道了Pointcut和Advice的作用之后，理解切面就会清晰很多。简单的理解切面就是Pointcut和Advice两者的结合，把切入点和通知连接起来就组成了一个切面。而在Spring代码中的体现，切面指的就是Advisor接口及其实现，来看一下Advisor接口的内容 12345public interface Advisor &#123; Advice getAdvice(); boolean isPerInstance();&#125; Advisor接口getAdvice()方法返回了该切面对应的通知 12345678public interface PointcutAdvisor extends Advisor &#123; /** * Get the Pointcut that drives this advisor. */ Pointcut getPointcut();&#125; PointcutAdvisor接口继承了Advisor接口，并且新增了getPointcut()`方法，通过这个接口，就把切入点和通知两者连接了起来，完成了切面的配置 Weaving 织入当完成了以上工作之后，我们可以说是万事俱备，只欠东风，剩下的事情，就是把具体的切面逻辑织入到我们的切入点中去，那么Spring对于AOP代理逻辑织入是怎么做的，又是在何时做的呢？ 这时候就是Spring IOC 容器大展身手的时候，我们在之前分析Spring IOC容器的时候有提到过扩展点BeanPostProcessor接口，上篇文章我们也有提到一个代理创建的核心类AspectJAwareAdvisorAutoProxyCreator，我们来看一下这个类的结构 通过查看该类的接口，可以知道AspectJAwareAdvisorAutoProxyCreator是BeanPostProcessor接口的具体实现，所以我们知道代理类创建必定是在Bean创建前后被创建的。具体的创建逻辑是在Bean完成初始化，执行BeanPostProcessor接口的postProcessAfterInitialization方法时执行 总结本篇文章我们主要从接口层面分析了AOP的实现，并没有涉及到很多的AOP源码，但是这些基本的接口是AOP实现的核心，理解这些对于AOP源码分析有很大的帮助。下篇文章我将会对代理的创建(AspectJAwareAdvisorAutoProxyCreator.class)做分析]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP 源码解析一 （AOP入口浅谈）]]></title>
    <url>%2F2018%2F11%2F30%2FSpring-AOP-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%80-%EF%BC%88AOP%E5%85%A5%E5%8F%A3%E6%B5%85%E8%B0%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言在进行aop的源码解析之前，我们首先要知道Spring AOP是怎么用的，只有知道怎么用的，我们才能更好的理解aop，才能进行下一步解析 使用AOP好了，废话不多说，我们直接动手来用一下spring的AOP实现 首先新建一个MyPointCut接口，并且实现它 12345678910/** * MyPointCut * * @author wangjn * @date 2018/12/7 */public interface MyPointCut &#123; void sayHello();&#125; 12345678910111213/** * MyPointCutImpl * * @author wangjn * @date 2018/12/10 */public class MyPointCutImpl implements MyPointCut &#123; @Override public void sayHello() &#123; System.out.println("hello world"); &#125;&#125; 新建一个MyAspect接口，接口里的方法是我们之后要切入的aop逻辑方法 12345678/** * MyAspect */public interface MyAspect &#123; void logBefore(); void logAfter();&#125; 123456789101112131415/** * MyAspectImpl */public class MyAspectImpl implements MyAspect &#123; @Override public void logBefore() &#123; System.out.println(&quot;log before&quot;); &#125; @Override public void logAfter() &#123; System.out.println(&quot;log after&quot;); &#125;&#125; spring xml 配置 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;bean id=&quot;myPointCut&quot; class=&quot;com.wangjn.demo.impl.MyPointCutImpl&quot;&gt;&lt;/bean&gt; &lt;bean id=&quot;aspectTest&quot; class=&quot;com.wangjn.demo.MyAspectImpl&quot;/&gt; &lt;aop:config&gt; &lt;aop:aspect id=&quot;log&quot; ref=&quot;aspectTest&quot;&gt; &lt;aop:pointcut id=&quot;addAllMethod&quot; expression=&quot;execution(* com.wangjn.demo.MyPointCut.*(..))&quot; /&gt; &lt;aop:before method=&quot;logBefore&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt; &lt;aop:after method=&quot;logAfter&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 写个main方法 12345678910111213/** * Start */public class Start &#123; public static void main(String[] args) throws IOException &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;&quot;spring.xml&quot;&#125;); context.start(); // 取得bean myPointCut MyPointCut myPointCut = (MyPointCut)context.getBean(&quot;myPointCut&quot;); myPointCut.sayHello(); &#125;&#125; 执行结果输出，可知myPointCut的方案前后都额外执行了aop要织入的逻辑，这就是aop的神奇之处，可以在原代码毫无感知的情况下执行额外逻辑 123log beforehello worldlog after 通过上面代码简单的演示，我们大致知道了aop是怎么使用的，不过显然知道怎么用并不是我们所要追求的，接下来就我们从aop的源码入口一步一步的解析它的实现原理 AOP源码入口要想知道aop的实现原理，我们首先要了解的就是spinng ioc容器是怎么解析我们的aop配置的，这里我们暂且只看xml形式的配置解析 好了，回到上面的spring配置文件1234567&lt;aop:config&gt; &lt;aop:aspect id=&quot;log&quot; ref=&quot;aspectTest&quot;&gt; &lt;aop:pointcut id=&quot;addAllMethod&quot; expression=&quot;execution(* com.wangjn.demo.MyPointCut.*(..))&quot; /&gt; &lt;aop:before method=&quot;logBefore&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt; &lt;aop:after method=&quot;logAfter&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; 可以看到都是spring aop的自定义标签，在之前解析spring ioc源码的时候我们已经知道，spring是支持自定义的标签解析的，自定义标签的入口文件在META-INF/spring.handlers中，我们找到spring aopjar包下的这个目录，打开这个文件 1http\://www.springframework.org/schema/aop=org.springframework.aop.config.AopNamespaceHandler 可以看到这里配置了一个aop命名空间的解析器 org.springframework.aop.config.AopNamespaceHandler，现在我们就从这个入口文件来进行源码分析 AopNamespaceHandler1234567891011121314151617181920public class AopNamespaceHandler extends NamespaceHandlerSupport &#123; /** * Register the &#123;@link BeanDefinitionParser BeanDefinitionParsers&#125; for the * &apos;&#123;@code config&#125;&apos;, &apos;&#123;@code spring-configured&#125;&apos;, &apos;&#123;@code aspectj-autoproxy&#125;&apos; * and &apos;&#123;@code scoped-proxy&#125;&apos; tags. */ @Override public void init() &#123; // In 2.0 XSD as well as in 2.1 XSD. registerBeanDefinitionParser(&quot;config&quot;, new ConfigBeanDefinitionParser()); // 支持 @AspectJ 声明式配置 registerBeanDefinitionParser(&quot;aspectj-autoproxy&quot;, new AspectJAutoProxyBeanDefinitionParser()); registerBeanDefinitionDecorator(&quot;scoped-proxy&quot;, new ScopedProxyBeanDefinitionDecorator()); // Only in 2.0 XSD: moved to context namespace as of 2.1 registerBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser()); &#125;&#125; 这里我们可以看到对config属性的解析是由ConfigBeanDefinitionParser完成的。ConfigBeanDefinitionParser是BeanDefinitionParser接口的实现，其中的parse方法封装了对&lt;aop:config&gt;属性标签的解析逻辑 ConfigBeanDefinitionParser的parse方法123456789101112131415161718192021222324252627public BeanDefinition parse(Element element, ParserContext parserContext) &#123; CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), parserContext.extractSource(element)); parserContext.pushContainingComponent(compositeDef); configureAutoProxyCreator(parserContext, element); List&lt;Element&gt; childElts = DomUtils.getChildElements(element); for (Element elt: childElts) &#123; String localName = parserContext.getDelegate().getLocalName(elt); // pointCut标签 if (POINTCUT.equals(localName)) &#123; parsePointcut(elt, parserContext); &#125; // advisor标签 else if (ADVISOR.equals(localName)) &#123; parseAdvisor(elt, parserContext); &#125; // aspect标签 else if (ASPECT.equals(localName)) &#123; parseAspect(elt, parserContext); &#125; &#125; parserContext.popAndRegisterContainingComponent(); return null;&#125; 可以清晰的看到，这里分别对pointcut,advisor,aspect三种标签进行解析 configureAutoProxyCreator(parserContext, element)这里配置了代理创建类，调用了AopNamespaceUtils.registerAspectJAutoProxyCreatorIfNecessary方法完成配置 123private void configureAutoProxyCreator(ParserContext parserContext, Element element) &#123; AopNamespaceUtils.registerAspectJAutoProxyCreatorIfNecessary(parserContext, element);&#125; 我们来看下 AopNamespaceUtils.registerAspectJAutoProxyCreatorIfNecessary的实现 1234567891011public static void registerAspectJAutoProxyCreatorIfNecessary( ParserContext parserContext, Element sourceElement) &#123; // 获取代理创建类 AspectJAwareAdvisorAutoProxyCreator并命名为org.springframework.aop.config.internalAutoProxyCreator BeanDefinition beanDefinition = AopConfigUtils.registerAspectJAutoProxyCreatorIfNecessary( parserContext.getRegistry(), parserContext.extractSource(sourceElement)); // 判断是否使用 CGLIB 创建代理，指定proxy-target-class=true则使用CGLIB，否则使用JDK动态代理 useClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement); // 往 spring ioc 容器注册AspectJAwareAdvisorAutoProxyCreator代理创建器 registerComponentIfNecessary(beanDefinition, parserContext);&#125; 可以看到这段代码主要做了两件事情 注册代理创建器 AspectJAwareAdvisorAutoProxyCreator，这个类很重要，是 aop的核心实现类 指定创建代理的方式，其中如果&lt;aop:config&gt;节点配置了proxy-target-class=true，则使用CGLIB创建代理，否则默认使用JDK 动态代理 parsePointcut解析aop的切入点配置，对应 &lt;aop:pointcut&gt;标签12345678910111213141516171819202122232425262728293031323334private AbstractBeanDefinition parsePointcut(Element pointcutElement, ParserContext parserContext) &#123; // 获取我们配置的 pointCut 切入点 id String id = pointcutElement.getAttribute(ID); // 获取要切入的 expression 表达式 String expression = pointcutElement.getAttribute(EXPRESSION); AbstractBeanDefinition pointcutDefinition = null; try &#123; // 记录当前处理节点 this.parseState.push(new PointcutEntry(id)); // 创建 AspectJExpressionPointcut 类型的 beanDefinition，并且把expression属性赋给此bean pointcutDefinition = createPointcutDefinition(expression);// 设置源数据 pointcutDefinition.setSource(parserContext.extractSource(pointcutElement)); // 设置 bean的id名称 String pointcutBeanName = id; if (StringUtils.hasText(pointcutBeanName)) &#123; // 注册beanDefinution 至spring容器 parserContext.getRegistry().registerBeanDefinition(pointcutBeanName, pointcutDefinition); &#125; else &#123; pointcutBeanName = parserContext.getReaderContext().registerWithGeneratedName(pointcutDefinition); &#125; parserContext.registerComponent( new PointcutComponentDefinition(pointcutBeanName, pointcutDefinition, expression)); &#125; finally &#123; this.parseState.pop(); &#125; return pointcutDefinition;&#125; 这里主要是配置了aop切入点的bean AspectJExpressionPointcut parseAspect1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private void parseAspect(Element aspectElement, ParserContext parserContext) &#123; // 获取切面id String aspectId = aspectElement.getAttribute(ID); // 获取切面要执行的具体逻辑类 这个是必须设置的属性 String aspectName = aspectElement.getAttribute(REF); try &#123; this.parseState.push(new AspectEntry(aspectId, aspectName)); List&lt;BeanDefinition&gt; beanDefinitions = new ArrayList&lt;BeanDefinition&gt;(); List&lt;BeanReference&gt; beanReferences = new ArrayList&lt;BeanReference&gt;(); List&lt;Element&gt; declareParents = DomUtils.getChildElementsByTagName(aspectElement, DECLARE_PARENTS); for (int i = METHOD_INDEX; i &lt; declareParents.size(); i++) &#123; Element declareParentsElement = declareParents.get(i); beanDefinitions.add(parseDeclareParents(declareParentsElement, parserContext)); &#125; // We have to parse &quot;advice&quot; and all the advice kinds in one loop, to get the // ordering semantics right. // 解析advice标签 NodeList nodeList = aspectElement.getChildNodes(); boolean adviceFoundAlready = false; for (int i = 0; i &lt; nodeList.getLength(); i++) &#123; Node node = nodeList.item(i); // 判断 advice 的类型是否是限定的几种（after before around） if (isAdviceNode(node, parserContext)) &#123; if (!adviceFoundAlready) &#123; adviceFoundAlready = true; // 如果没有配置 ref 属性，抛出异常 if (!StringUtils.hasText(aspectName)) &#123; parserContext.getReaderContext().error( &quot;&lt;aspect&gt; tag needs aspect bean reference via &apos;ref&apos; attribute when declaring advices.&quot;, aspectElement, this.parseState.snapshot()); return; &#125; beanReferences.add(new RuntimeBeanReference(aspectName)); &#125; // 开始解析advice节点 AbstractBeanDefinition advisorDefinition = parseAdvice( aspectName, i, aspectElement, (Element) node, parserContext, beanDefinitions, beanReferences); beanDefinitions.add(advisorDefinition); &#125; &#125; AspectComponentDefinition aspectComponentDefinition = createAspectComponentDefinition( aspectElement, aspectId, beanDefinitions, beanReferences, parserContext); parserContext.pushContainingComponent(aspectComponentDefinition); // 解析 aspect 标签中的 pointcut List&lt;Element&gt; pointcuts = DomUtils.getChildElementsByTagName(aspectElement, POINTCUT); for (Element pointcutElement : pointcuts) &#123; parsePointcut(pointcutElement, parserContext); &#125; parserContext.popAndRegisterContainingComponent(); &#125; finally &#123; this.parseState.pop(); &#125;&#125; parseAdviceparseAdvice这段代码的主要逻辑其实就是解析 advice标签，并最终包装成advisor。advisor其实相当于整合了advice 通知和pointcut 切点，相当于通过 advisor把切点和要执行的切面逻辑连接了起来 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private AbstractBeanDefinition parseAdvice( String aspectName, int order, Element aspectElement, Element adviceElement, ParserContext parserContext, List&lt;BeanDefinition&gt; beanDefinitions, List&lt;BeanReference&gt; beanReferences) &#123; try &#123; this.parseState.push(new AdviceEntry(parserContext.getDelegate().getLocalName(adviceElement))); // create the method factory bean // 创建切面增强方法对应的 methodDefinition，并设置 methodName targetBeanName属性 RootBeanDefinition methodDefinition = new RootBeanDefinition(MethodLocatingFactoryBean.class); methodDefinition.getPropertyValues().add(&quot;targetBeanName&quot;, aspectName); methodDefinition.getPropertyValues().add(&quot;methodName&quot;, adviceElement.getAttribute(&quot;method&quot;)); methodDefinition.setSynthetic(true); // create instance factory definition // 创建切面类 FactoryBean RootBeanDefinition aspectFactoryDef = new RootBeanDefinition(SimpleBeanFactoryAwareAspectInstanceFactory.class); aspectFactoryDef.getPropertyValues().add(&quot;aspectBeanName&quot;, aspectName); aspectFactoryDef.setSynthetic(true); // register the pointcut // 选择合适的 advice 并注册 pointcut AbstractBeanDefinition adviceDef = createAdviceDefinition( adviceElement, parserContext, aspectName, order, methodDefinition, aspectFactoryDef, beanDefinitions, beanReferences); // configure the advisor // 配置 advisor，对应的类型是 AspectJPointcutAdvisor.class RootBeanDefinition advisorDefinition = new RootBeanDefinition(AspectJPointcutAdvisor.class); advisorDefinition.setSource(parserContext.extractSource(adviceElement)); advisorDefinition.getConstructorArgumentValues().addGenericArgumentValue(adviceDef); if (aspectElement.hasAttribute(ORDER_PROPERTY)) &#123; advisorDefinition.getPropertyValues().add( ORDER_PROPERTY, aspectElement.getAttribute(ORDER_PROPERTY)); &#125; // register the final advisor parserContext.getReaderContext().registerWithGeneratedName(advisorDefinition); return advisorDefinition; &#125; finally &#123; this.parseState.pop(); &#125;&#125; 这里划一下上面代码提到的几个重要的类: Pointcut 对应 AspectJExpressionPointcut.class Advice 对应 AspectJMethodBeforeAdvice,AspectJAfterAdvice， AspectJAfterReturningAdvice, AspectJAfterThrowingAdvice,AspectJAroundAdvice, 五种通知类型 Advisor 对应 AspectJPointcutAdvisor.class 总结到这里，对AOP的配置信息已经解析完成，并成功的放入Spring容器中。看到这里也许大家对aop的实现还是很模糊，并没有一个整体的概念。那是因为我们对Aspect， Pointcut ，Advice，Advisor这几个aop的主要概念还没有一个系统的认识，下篇文章我将会对这几个概念好好的聊一下。]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC 源码解析五（非延迟加载bean的初始化）]]></title>
    <url>%2F2018%2F11%2F23%2FSpring-IOC-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BA%94%EF%BC%88%E9%9D%9E%E5%BB%B6%E8%BF%9F%E5%8A%A0%E8%BD%BDbean%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言 上期分析了refresh方法中大部分，这期我们只分析finishBeanFactoryInitialization(beanFactory)这一个方法，分析这个方法的过程中我们会顺藤摸瓜把bean初始化的整个流程都分析一遍 finishBeanFactoryInitialization(beanFactory)提前初始化一些非延迟加载的单例类型的bean，这里主要看最后一行 beanFactory.preInstantiateSingletons(),这里是初始化非延迟加载单例的入口 123456789101112131415161718192021222324252627282930313233343536protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // 初始化类型转化的bean if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. // 注册默认的值解析器 if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; return getEnvironment().resolvePlaceholders(strVal); &#125; &#125;); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons();&#125; preInstantiateSingletons方法在DefaultListableBeanFactory中，用于初始化所有非延迟加载的单例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public void preInstantiateSingletons() throws BeansException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Pre-instantiating singletons in " + this); &#125; // 所有注册完成的 beanDefinitionNames List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); // 遍历所有非延迟加载的单例类型 for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; // 判断类型是否为 FactoryBean if (isFactoryBean(beanName)) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; @Override public Boolean run() &#123; return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit(); &#125; &#125;, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; // 是否需要立即加载 if (isEagerInit) &#123; getBean(beanName); &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; 可以看到这段代码主要做了2个事情 判断bean的类型是否是factoryBean，如果是的话判断类型是不是SmartFactoryBean，再获取是否需要立即加载的isEagerInit属性，执行getBean方法 在单例bean都初始化完成后，循环判断bean的类型是否是SmartInitializingSingleton，是的话会在这时候执行afterSingletonsInstantiated方法 接下来就是获取bean的流程代码 getBeangetBean方法最终都是走的doGetBean方法 123public Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125; doGetBean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // 首先检查缓存是否有，有则直接取 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; // 这里是取FactoryBean bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; // 缓存里没有 第一次初始化Bean else &#123; // 判断是不是处于循环依赖当中，有则直接报错 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // 检查父容器是否存在此Bean的定义 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. // 返回原始的名称 加上FactoryBean符号 String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; // 把Bean的状态改为已创建，并从mergedBeanDefinitions 中移除 markBeanAsCreated(beanName); &#125; try &#123; // 合并BeanDefinition转化成RootBeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 获取配置的 depends-On 依赖,优先加载 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; registerDependentBean(dep, beanName); try &#123; // 递归获取 getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", ex); &#125; &#125; &#125; // Create bean instance. // 如果是单例 if (mbd.isSingleton()) &#123; // 这里会把创建完成的bean加入缓存 sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; // 创建bean的主逻辑 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // 判断类型 prototype 有状态的bean else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; // 其他类型的scope String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider " + "defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. // 如果有指定的类型，则检查是否与实际bean实例的类型匹配 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean;&#125; 看完上面的代码，我们作总结：首先，创建bean之前会检查单例缓存里有没有，有的话会直接返回。然后会检查父容器是否有这个bean的定义，一直找到最顶层的父容器（有点类型双亲委派），最后会在父容器执行这个bean的获取，之后获取depends-On如果有配置的话会优先获取（递归获取直到依赖的所有depends-On），最后才是根据scope调用AbstractAutowireCapableBeanFactory的createBean方法 createBean12345678910111213141516171819202122232425262728293031323334353637383940414243protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 扩展点，可以通过实现InstantiationAwareBeanPostProcessor 接口一个返回代理而不是目标bean实例 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance;&#125; 这段代码主要看一下resolveBeforeInstantiation(beanName, mbdToUse)，这里是spring提供的一个扩展点，可以通过实现InstantiationAwareBeanPostProcessor接口在这里返回bean的代理然后就可以直接看最后的doCreateBean(beanName, mbdToUse, args)方法 doCreateBean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // Instantiate the bean. // 封装bean的容器 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 这里是创建 BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null); Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null); mbd.resolvedTargetType = beanType; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // 判断是否需要提前暴露对象的引用，用于解决循环依赖 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; // 依赖注入的主逻辑 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; // 执行一些初始化的方法 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; return exposedObject;&#125; 这段代码主要看这三个方法 createBeanInstance(beanName, mbd, args) 创建bean populateBean(beanName, mbd, instanceWrapper) 组装bean的依赖 initializeBean(beanName, exposedObject, mbd) 调用bean的一些初始化方法，以及扩展接口 接下来我们着重来看这三个方法 createBeanInstance123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123; // Make sure bean class is actually resolved at this point. // 获取bean class Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); // 不是 pullic 直接抛异常 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Bean class isn't public, and non-public access not allowed: " + beanClass.getName()); &#125; // 使用工厂方法实例化bean if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // Shortcut when re-creating the same bean... // 判断bean是否创建过 boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; // 如果已经加载过 if (resolved) &#123; if (autowireNecessary) &#123; // 有参构造方法 return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; // 使用无参构造 return instantiateBean(beanName, mbd); &#125; &#125; // Need to determine the constructor... // 寻找一个合适的构造方法 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args); &#125; // No special handling: simply use no-arg constructor. return instantiateBean(beanName, mbd);&#125; 这个方法的主要逻辑其实就是在找一个合适的初始化方法 首先判断RootBeanDefinition是否含有factory-method配置，有的话使用工厂方法实例化bean 之后的逻辑就是寻找一个合适的构造方法用于bean的实例化 如果判断是有参的构造方法，则通过autowireConstructor实例化，初始化的过程很繁琐，其中对构造方法参数的依赖也是通过递归getBean()来实现的 无参的则使用instantiateBean实例化 到这里执行完bean已经创建了(spring默认是使用CGLIB)，但是这时候的bean是不完整的，相关的依赖项还并没有被注入 populateBean(beanName, mbd, instanceWrapper)组装bean的逻辑都在这里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; // 获取的配置的property依赖 PropertyValues pvs = mbd.getPropertyValues(); if (bw == null) &#123; if (!pvs.isEmpty()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; // 扩展点 执行实现了InstantiationAwareBeanPostProcessors接口方法 // 在设置属性依赖之前可以有机会修改bean的属性配置 boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; // 判断是否需要继续组装bean属性 if (!continueWithPropertyPopulation) &#123; return; &#125; // 判断自动配的类型（按名称和按类型） if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. // 按bean的名称注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. // 按bean的类型注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; // 判断是否需要依赖检查 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; // 检查依赖 checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; // 组装属性 applyPropertyValues(beanName, mbd, bw, pvs);&#125; 通过查看代码，可知上面不止做了组装bean这一件事，主要做了下面几件事情: 获取spring配置项中配置的property属性依赖 执行实现了InstantiationAwareBeanPostProcessors接口的方法，该接口可以在属性被注入前做一些修改，并且可以直接返回，不执行下面的属性注入逻辑 判断是否有配置自动注入，有的话会按配置执行按名称（autowireByName方法）或类型（autowireByType方法）注入 判断是否执行依赖检查（按配置的依赖检查等级check） 最后执行bean属性的最终装配 （applyPropertyValues(beanName, mbd, bw, pvs)） 我们可以简单看一下 autowireByName的实现 autowireByName123456789101112131415161718192021222324protected void autowireByName( String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) &#123; // 返回需要自动依赖注入的属性名称 String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw); for (String propertyName : propertyNames) &#123; if (containsBean(propertyName)) &#123; Object bean = getBean(propertyName); // 将获取的依赖bean放回 待装配 pvs.add(propertyName, bean); registerDependentBean(propertyName, beanName); if (logger.isDebugEnabled()) &#123; logger.debug("Added autowiring by name from bean name '" + beanName + "' via property '" + propertyName + "' to bean named '" + propertyName + "'"); &#125; &#125; else &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Not autowiring property '" + propertyName + "' of bean '" + beanName + "' by name: no matching bean found"); &#125; &#125; &#125;&#125; 可知如果是按name注入的话，首先会先获取需要自动依赖注入的bean名称，然后是通过getBean(beanName)获取依赖项的。同理autowireByType applyPropertyValues在执行applyPropertyValues方法之前，我们已经准备好了所有的依赖项了，接下来的事情就是把这些依赖项装配到bean对应的属性中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &#123; // 待装配的属性为空 直接返回 if (pvs == null || pvs.isEmpty()) &#123; return; &#125; MutablePropertyValues mpvs = null; List&lt;PropertyValue&gt; original; if (System.getSecurityManager() != null) &#123; if (bw instanceof BeanWrapperImpl) &#123; ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); &#125; &#125; // if (pvs instanceof MutablePropertyValues) &#123; mpvs = (MutablePropertyValues) pvs; if (mpvs.isConverted()) &#123; // Shortcut: use the pre-converted values as-is. try &#123; bw.setPropertyValues(mpvs); return; &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125; &#125; original = mpvs.getPropertyValueList(); &#125; else &#123; original = Arrays.asList(pvs.getPropertyValues()); &#125; TypeConverter converter = getCustomTypeConverter(); if (converter == null) &#123; converter = bw; &#125; // 用于加载beanDefinition所对应的值 BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // 创建一个PropertyValue的深拷贝 List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;PropertyValue&gt;(original.size()); boolean resolveNecessary = false; for (PropertyValue pv : original) &#123; if (pv.isConverted()) &#123; deepCopy.add(pv); &#125; else &#123; String propertyName = pv.getName(); Object originalValue = pv.getValue(); // 加载对应属性值 value Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &#123; convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &#125; // Possibly store converted value in merged bean definition, // in order to avoid re-conversion for every created bean instance. if (resolvedValue == originalValue) &#123; if (convertible) &#123; pv.setConvertedValue(convertedValue); &#125; deepCopy.add(pv); &#125; else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123; pv.setConvertedValue(convertedValue); deepCopy.add(pv); &#125; else &#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &#125; &#125; &#125; if (mpvs != null &amp;&amp; !resolveNecessary) &#123; mpvs.setConverted(); &#125; // Set our (possibly massaged) deep copy. try &#123; // 设置属性信息 bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125;&#125; 这段代码做的主要事情就是通过配置的属性去加载属性对应的值，真正为bean设置属性的逻辑在bw.setPropertyValues(new MutablePropertyValues(deepCopy))中，这里其实就是通过反射调用set方法进行属性的设置的。代码执行到这里，bean的创建已经基本完整了,populateBean方法的工作已经完成了，下面要做的就是一些初始化的工作 initializeBean(beanName, exposedObject, mbd)123456789101112131415161718192021222324252627282930313233343536373839protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; // 安全管理器 判断执行权限 if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 执行实现了一系列Aware的接口方法 invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 执行BeanPostProcessor接口postProcessBeforeInitialization方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 先执行InitializingBean接口afterPropertiesSet方法 // 再执行自定义配置的初始化方法(init-method) invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, "Invocation of init method failed", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // 执行BeanPostProcessor接口postProcessAfterInitialization方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 上述代码做的都是bean初始化的事情 invokeAwareMethods方法，如果有bean又实现Aware相关的接口，则调用这些接口的方法给bean注入一些信息(beanName，BeanClassLoader，BeanFactory) applyBeanPostProcessorsBeforeInitialization 执行BeanPostProcessor接口postProcessBeforeInitialization方法，BeanPostProcessor接口在上一篇解析中有讲到过，是在refresh方法的registerBeanPostProcessors(beanFactory)中注册的，是spring提供的非常重要的一个自定义扩展点 invokeInitMethods方法，这里是判断是否有实现InitializingBean接口，有则执行afterPropertiesSet初始化方法，并且如果有配置自定义的init-method方法则也一并执行 applyBeanPostProcessorsBeforeInitialization 执行BeanPostProcessor接口postProcessAfterInitialization方法 尾言 随着解析进行到这里，我们已经把bean的整个生命周期都走了个大概。相信大家对spring ioc 的具体实现已经有了个基本的了解了]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC 源码解析四（加载非延迟单例前的操作）]]></title>
    <url>%2F2018%2F11%2F20%2FSpring-IOC-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%9B%9B%EF%BC%88%E5%8A%A0%E8%BD%BD%E9%9D%9E%E5%BB%B6%E8%BF%9F%E5%8D%95%E4%BE%8B%E5%89%8D%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言 上一期讲述了BeanDefinitions的载入和注册，beanDefinition相当于spring对bean的数据抽象定义，这一期我们继续顺着的 refresh 方法往下讲 回到refresh方法上一期其实主要是介绍了obtainFreshBeanFactory() 这一步，这一期我们继续接着往下看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // 创建BeanFactory,并载入BeanDefinitions（重要） ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // 执行 BeanFactoryPostProcessors（实例化bean前修改bean定义信息） invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessors（初始化bean前后执行） registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 国际化相关 initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 初始化主题信息 onRefresh(); // Check for listener beans and register them. registerListeners(); // 提前实例化化全部非延迟加载的单例类型 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; prepareBeanFactory(beanFactory)先看一下prepareBeanFactory的方法实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // 配置容器的 classLoader beanFactory.setBeanClassLoader(getClassLoader()); // 这是一个表达是语言处理器 beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); // 属性编辑器 beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 配置了BeanPostProcessor的一个实现类 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 配置被忽略的依赖项（各种 Aware 实现类） beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); // 修正依赖 beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // Register early post-processor for detecting inner beans as ApplicationListeners. // 注册AOP相关的 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // Detect a LoadTimeWeaver and prepare for weaving, if found. if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // 配置Spring 默认环境变量bean if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; 这个方法做了什么事情呢，我们简单的来看一下 首先是配置了容器的默认 classLoader 配置了一个语言器和一个属性编辑器 注册了一个BeanPostProcessor接口的一个实现类，这个接口的具体用处下面马上会讲到 配置要自动注入时要被忽略的bean类型，可以看到这里配置的都是一些Aware实现类，这些依赖项spring容器会统一设置 注册aop相关的 配置Spring默认环境变量bean(systemProperties, systemEnvironment, environment) postProcessBeanFactory(beanFactory)方法比较简短，通过查看代码，可知也是对beanFactory做一些配置的工作 1234567protected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; beanFactory.addBeanPostProcessor(new ServletContextAwareProcessor(this.servletContext, this.servletConfig)); beanFactory.ignoreDependencyInterface(ServletContextAware.class); beanFactory.ignoreDependencyInterface(ServletConfigAware.class); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, this.servletContext); WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, this.servletContext, this.servletConfig);&#125; invokeBeanFactoryPostProcessors(beanFactory)可以看到主要逻辑在，PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors中，这里其实是spring留的一个扩展点，我们可以通过实现BeanFactoryPostProcessor来实现在 getBean之前的自定义扩展。现在我们就来看看它是在什么时候执行的 12345678910protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor) if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125; 继续查看PostProcessorRegistrationDelegate.class 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // 存放已经执行的 BeanFactoryPostProcessor bean名字 Set&lt;String&gt; processedBeans = new HashSet&lt;String&gt;(); // 判断beanFactory类型是否为BeanDefinitionRegistry，只有BeanDefinitionRegistry类型的才支持BeanDefinitionRegistryPostProcessor的注册 if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; // 存放手动加入的 BeanFactoryPostProcessor List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new LinkedList&lt;BeanFactoryPostProcessor&gt;(); // 存放手动加入的 BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new LinkedList&lt;BeanDefinitionRegistryPostProcessor&gt;(); for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; // 如果是BeanDefinitionRegistryPostProcessor类型 if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; // 执行 postProcessBeanDefinitionRegistry 方法 registryProcessor.postProcessBeanDefinitionRegistry(registry); // 放入待执行容器中，之后会执行BeanFactoryPostProcessor接口的postProcessBeanFactory方法 registryProcessors.add(registryProcessor); &#125; else &#123; // 放入待执行容器中，之后统一执行 regularPostProcessors.add(postProcessor); &#125; &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! // Separate between BeanDefinitionRegistryPostProcessors that implement // PriorityOrdered, Ordered, and the rest. // 用于存放当前需要执行的 BeanDefinitionRegistryPostProcessor list List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;BeanDefinitionRegistryPostProcessor&gt;(); // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered. // 一 先执行类型为 PriorityOrdered 的BeanDefinitionRegistryPostProcessors String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; // 排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 将当前需要执行全部放入 待执行容器 registryProcessors.addAll(currentRegistryProcessors); // 执行 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); // 清空已经执行过的 currentRegistryProcessors.clear(); // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered. // 二 在执行类型为Ordered的BeanDefinitionRegistryPostProcessor postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear. // 最后执行普通的 BeanDefinitionRegistryPostProcessors boolean reiterate = true; // 循环的目的是未了防止执行过程中有新的 postProcessorNames 加入 while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); &#125; // Now, invoke the postProcessBeanFactory callback of all processors handled so far. // 执行待执行容器的中的 BeanFactoryPostProcessor invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. // 直接执行手动加入的 BeanFactoryPostProcessor invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // 以上执行完BeanDefinitionRegistryPostProcessor，现在开始执行BeanFactoryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // 执行顺序和BeanDefinitionRegistryPostProcessor基本一致，先PriorityOrdered，再Ordered，最后普通的 List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); // 存放 PriorityOrdered类型的BeanFactoryPostProcessor List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); // 存放 Ordered类型的BeanFactoryPostProcessor List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // 这里跳过的是已经执行过的 BeanDefinitionRegistryPostProcessor // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. // 先执行 PriorityOrdered sortPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. // 再执行 Ordered List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. // 最后执行普通的 List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache();&#125; 这个方法代码非常的多，夹杂着各种判断，看的眼花缭乱。我们简单理一下逻辑 BeanFactoryPostProcessor有一个子接口叫做BeanDefinitionRegistryPostProcessor，它的优先级是比BeanFactoryPostProcessor高的 方法的入参里有一个List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors，这个是容器通过addBeanFactoryPostProcessor方法手动加入的。这里的BeanDefinitionRegistryPostProcessor类型是优先级最高的 同时BeanFactoryPostProcessor和BeanDefinitionRegistryPostProcessor可以都实现两个接口(PriorityOrdered,Ordered)用来定义执行的顺序，其中PriorityOrdered优先级最高，其次Ordered，最后是没有实现任何Order接口的 综上三点，我们是可以得出上面一大坨代码的执行顺序了 首先是拿到手动加入的BeanFactoryPostProcessor，挑出里面的BeanDefinitionRegistryPostProcessor类型，优先执行。 再拿到容器中的全部BeanDefinitionRegistryPostProcessors，按照实现的排序接口顺序执行 执行BeanDefinitionRegistryPostProcessors父类型BeanFactoryPostProcessor的方法 最后再拿到容器中全部BeanFactoryPostProcessors并过滤到已经执行过的BeanDefinitionRegistryPostProcessors，按照顺序依次执行 registerBeanPostProcessors(beanFactory)这里也是spring的一个扩展点，通过实现BeanPostProcessor接口来实现自定义逻辑，具体的执行时机，会在分析getBaan时讲到，这里的逻辑仅仅是将BeanPostProcessor用户自定义的BeanPostProcessor注册到容器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // Re-register post-processor for detecting inner beans as ApplicationListeners, // moving it to the end of the processor chain (for picking up proxies etc). beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125; 这里的逻辑其实跟上面的逻辑非常的相似，其实也都在一个class中，唯一的区别是这里并没有执行，仅仅只是做了下排序后就注册进了容器中，留到后面的步骤中在执行。这里也简单的列一下这里的要点 BeanPostProcessor有一个子接口MergedBeanDefinitionPostProcessor,这个是最晚被注册进容器的 同样可以实现(PriorityOrdered,Ordered)接口用来定义执行的顺序 initMessageSource()国际化相关，这里就不做仔细分析了 initApplicationEventMulticaster()顾名思义。就是spring用来初始化事情广播器的 12345678910111213141516171819protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isDebugEnabled()) &#123; logger.debug("Using ApplicationEventMulticaster [" + this.applicationEventMulticaster + "]"); &#125; &#125; else &#123; this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isDebugEnabled()) &#123; logger.debug("Unable to locate ApplicationEventMulticaster with name '" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + "': using default [" + this.applicationEventMulticaster + "]"); &#125; &#125;&#125; 看一下这里的代码比较的简单，就是一个 if else，先尝试获取名字为APPLICATION_EVENT_MULTICASTER_BEAN_NAME类型为ApplicationEventMulticaster的 bean，如果没有获取到，则配置一个默认的bean (SimpleApplicationEventMulticaster) onRefresh()这里是留给子类实现的，没有什么逻辑 registerListeners()注册一些监听器 12345678910111213141516171819202122protected void registerListeners() &#123; // Register statically specified listeners first. for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // Publish early application events now that we finally have a multicaster... Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (earlyEventsToProcess != null) &#123; for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; 尾言 下篇会解析finishBeanFactoryInitialization方法，并且会着重讲解初始化bean的整个生命周期]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 源码解析三（BeanDefinitions的载入注册）]]></title>
    <url>%2F2018%2F10%2F20%2FSpring-IOC-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%89%EF%BC%88BeanDefinitions%E7%9A%84%E8%BD%BD%E5%85%A5%E6%B3%A8%E5%86%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言 这期主要是解析BeanDefinitions的载入和注册的整个过程，整个过程看似非常复杂，其实我们可以分成几个部分去看: 1.载入 2.注册和解析如果没有看过前面几期的话，建议先过一下前面几期 为了帮助大家理清整个调用过程，简单的画了一个图 关键类 XmlBeanDefinitionReader AbstractBeanDefinitionReader xml配置形式的BeanDefinition的读取器 XmlReaderContext 解析过程的上下文对象，实际持有BeanFactory对象用于BeanDefinitions的回调注册 DefaultBeanDefinitionDocumentReader 解析xml文件抽象成Docment对象 BeanDefinitionParserDelegate 主要解析过程 DefaultNamespaceHandlerResolver 自定义配置文件解析器加载器 BeanDefinitions的载入loadBeanDefinitions(String… locations) 这个方法是比较简单在AbstractBeanDefinitionReader中，只是提供了一个入口 1234567891011121314public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, "Location array must not be null"); int counter = 0; String[] var3 = locations; int var4 = locations.length; for(int var5 = 0; var5 &lt; var4; ++var5) &#123; String location = var3[var5]; // 开始载入配置信息 counter += this.loadBeanDefinitions(location); &#125; return counter;&#125; loadBeanDefinitions(String location, Set actualResources) 这个方法同样在AbstractBeanDefinitionReader中被调用，看代码可知就是获取持有的ResourceLoader对象并调用getResources方法。返回可以被BeanDefinitionReader解析的Resource类型。 这里要注意持有的ResourceLoader对象是在创建XmlBeanDefinitionReader时所传入的容器本身 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; // 获取 ResourceLoader ResourceLoader resourceLoader = this.getResourceLoader(); if(resourceLoader == null) &#123; throw new BeanDefinitionStoreException("Cannot import bean definitions from location [" + location + "]: no ResourceLoader available"); &#125; else &#123; int loadCount; // 判断 resourceLoader 的类型是否属于ResourcePatternResolver类型 if(!(resourceLoader instanceof ResourcePatternResolver)) &#123; Resource resource = resourceLoader.getResource(location); // 调用子类的 loadBeanDefinitions(resource) 方法 loadCount = this.loadBeanDefinitions((Resource)resource); if(actualResources != null) &#123; actualResources.add(resource); &#125; if(this.logger.isDebugEnabled()) &#123; this.logger.debug("Loaded " + loadCount + " bean definitions from location [" + location + "]"); &#125; return loadCount; &#125; else &#123; try &#123; Resource[] resources = ((ResourcePatternResolver)resourceLoader).getResources(location); // 循环遍历载入 loadCount = this.loadBeanDefinitions(resources); if(actualResources != null) &#123; Resource[] var6 = resources; int var7 = resources.length; for(int var8 = 0; var8 &lt; var7; ++var8) &#123; Resource resource = var6[var8]; actualResources.add(resource); &#125; &#125; if(this.logger.isDebugEnabled()) &#123; this.logger.debug("Loaded " + loadCount + " bean definitions from location pattern [" + location + "]"); &#125; return loadCount; &#125; catch (IOException var10) &#123; throw new BeanDefinitionStoreException("Could not resolve bean definition resource pattern [" + location + "]", var10); &#125; &#125; &#125;&#125; loadBeanDefinitions(EncodedResource encodedResource) 获取到XML文件的inputStream流 1234567891011121314151617181920212223242526272829303132333435363738394041public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, "EncodedResource must not be null"); if (logger.isInfoEnabled()) &#123; logger.info("Loading XML bean definitions from " + encodedResource.getResource()); &#125; Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( "Detected cyclic loading of " + encodedResource + " - check your import definitions!"); &#125; try &#123; // 获取到XML文件的inputStream流 InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 进行具体的xml文件流解析 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( "IOException parsing XML document from " + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; doLoadBeanDefinitions(InputSource inputSource, Resource resource) doLoadDocument(inputSource, resource) 解析返回Document对象 registerBeanDefinitions(doc, resource) 使用 开始注册 BeanDefinitions 的过程 12345678910111213141516171819202122232425262728293031323334class = org.springframework.beans.factory.xml.XmlBeanDefinitionReaderprotected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; // 解析xml并返回Document对象，这里解析由DefaultDocumentLoader完成 Document doc = doLoadDocument(inputSource, resource); // 解析 Document对象并注册 return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), "Line " + ex.getLineNumber() + " in XML document from " + resource + " is invalid", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), "XML document from " + resource + " is invalid", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "Parser configuration exception parsing XML from " + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "IOException parsing XML document from " + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "Unexpected exception parsing XML document from " + resource, ex); &#125;&#125; BeanDefinitions的解析与注册registerBeanDefinitions(doc, resource) 创建 DefaultBeanDefinitionDocumentReader，解析xml资源文件 创建 XmlReaderContext 上下文对象，持有资源本身，持有DefaultNamespaceHandlerResolver对象，用来加载解析凭据（要怎么解析由解析凭据（NamespaceHandler）决定） 123456789101112131415161718192021222324252627282930313233343536class = org.springframework.beans.factory.xml.XmlBeanDefinitionReaderpublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // 创建 DefaultBeanDefinitionDocumentReader 解析xml资源文件 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); // 具体的解析开始 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125;/** * 创建上下文对象 */public XmlReaderContext createReaderContext(Resource resource) &#123; // 创建上下文对象 持有XmlBeanDefinitionReader 对象 return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver());&#125;/** * 创建XMl命名空间解析代理类，解析XML文件的依据。可以解析自定义XML文件 */public NamespaceHandlerResolver getNamespaceHandlerResolver() &#123; if (this.namespaceHandlerResolver == null) &#123; this.namespaceHandlerResolver = createDefaultNamespaceHandlerResolver(); &#125; return this.namespaceHandlerResolver;&#125;/** * 创建默认的命名空间解析代理类 */protected NamespaceHandlerResolver createDefaultNamespaceHandlerResolver() &#123; return new DefaultNamespaceHandlerResolver(getResourceLoader().getClassLoader());&#125; doRegisterBeanDefinitions(Element root) 创建BeanDefinitionParserDelegate 解析器，并加载默认配置（）解析器持有上下文对象 123456789101112131415161718192021222324252627282930313233343536class = org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReaderpublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; this.logger.debug("Loading bean definitions"); Element root = doc.getDocumentElement(); // 解析根节点 this.doRegisterBeanDefinitions(root);&#125;protected void doRegisterBeanDefinitions(Element root) &#123; BeanDefinitionParserDelegate parent = this.delegate; this.delegate = this.createDelegate(this.getReaderContext(), root, parent); // 判断节点所属命名空间是否为spring默认(http://www.springframework.org/schema/beans) if(this.delegate.isDefaultNamespace(root)) &#123; String profileSpec = root.getAttribute("profile"); if(StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, ",; "); if(!this.getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if(this.logger.isInfoEnabled()) &#123; this.logger.info("Skipped XML bean definition file due to specified profiles [" + profileSpec + "] not matching: " + this.getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; // 空实现 this.preProcessXml(root); // 开始解析根节点 this.parseBeanDefinitions(root, this.delegate); // 空实现 this.postProcessXml(root); // 赋值生成的父对象。含有默认配置 this.delegate = parent;&#125; parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) 判断是否为Spring默认的命名空间配置，加载不同的解析方法。默认命名空间会执行parseDefaultElement方法，如果是用户自定义的则会执行 BeanDefinitionParserDelegate的 parseCustomElement方法 1234567891011121314151617181920212223242526class = org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReaderprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 判断是否为默认命名空间 if(delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for(int i = 0; i &lt; nl.getLength(); ++i) &#123; Node node = nl.item(i); if(node instanceof Element) &#123; Element ele = (Element)node; if(delegate.isDefaultNamespace(ele)) &#123; // 默认解析 this.parseDefaultElement(ele, delegate); &#125; else &#123; // 执行自定义解析方法 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; // 执行自定义解析方法 delegate.parseCustomElement(root); &#125;&#125; 默认解析parseDefaultElement spirng默认的解析规则，可以看到这里有很多我们熟悉的标签元素，比如bean, import等，对应这些标签，spring都有专门的解析规则。bean 标签的解析就由processBeanDefinition来完成解析过程，这里我们着重来看下bean的解析 123456789101112131415161718class = org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReaderprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 解析import标签 if(delegate.nodeNameEquals(ele, "import")) &#123; this.importBeanDefinitionResource(ele); &#125; else if(delegate.nodeNameEquals(ele, "alias")) &#123; // 解析alias标签 this.processAliasRegistration(ele); &#125; else if(delegate.nodeNameEquals(ele, "bean")) &#123; // 解析bean标签 this.processBeanDefinition(ele, delegate); &#125; else if(delegate.nodeNameEquals(ele, "beans")) &#123; // 解析beans标签 this.doRegisterBeanDefinitions(ele); &#125;&#125; processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) 解析BeanDefinition并设置到BeanDefinitionHolder中去 注册到beanFactory的BeanDefiniton容器中去(其实是一个map) 12345678910111213141516171819class = org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReaderprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 解析并包装成BeanDefinitionHolder BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if(bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // 向容器注册 BeanDefiniton，XmlReaderContext其实是持有容器的引用的 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, this.getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException var5) &#123; this.getReaderContext().error("Failed to register bean definition with name '" + bdHolder.getBeanName() + "'", ele, var5); &#125; this.getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; parseBeanDefinitionElement 感兴趣的同学也可以继续把parseBeanDefinitionElement看一遍，可以发现大多数都是与Bean定义相关的标签解析 自定义解析 parseCustomElement 从上下文获取 DefaultNamespaceHandlerResolver 加载自定义解析凭据类(NamespaceHandler)，DefaultNamespaceHandlerResolver类通过查看源码可知其会去所有META-INF/spring.handlers目录下加载spring.handlers文件，spring.handlers配置的是对应的不同命名空间的解析类 调用NamespaceHandler的parse解析自定义xml配置 看到这里其实我们知道spring在这里是留了一个扩展点的，可以通过自定义配置文件来进行自定义解析 12345678910111213141516171819class=org.springframework.beans.factory.xml.BeanDefinitionParserDelegatepublic BeanDefinition parseCustomElement(Element ele) &#123; return this.parseCustomElement(ele, (BeanDefinition)null);&#125;public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; // 获取所属的命名空间地址 String namespaceUri = this.getNamespaceURI(ele); // 上下文中获取DefaultNamespaceHandlerResolver 并根据命名空间地址获取对应的 Handler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if(handler == null) &#123; this.error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; else &#123; // 执行解析（this.readerContext 中持有BeanFactory注册对象，可以回调注册BeanDefinition信息） return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); &#125;&#125; 尾言 BeanDefinitions 到这里为止就被注册完成了，下期就是Spring重要的依赖注入了]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库设计要注意的几个点]]></title>
    <url>%2F2018%2F08%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%87%A0%E4%B8%AA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[数据库设计字符集 统一使用utf8mb4，MySQL在5.5.3之后增加了utf8mb4字符编码，简单的说utf8mb4才是真正的utf-8，因为它可以支持4个字节每个字符，ps：当我们要存储emoji表情就必须使用utf8mb4，性能上不会有损失 建表规范 字段名必须使用小写字母 小数类型为decimal，禁止使用float和double（会有精度损失） 如果存储的字符串长度几乎相等，使用char定长字符串类型（与varchar的区别，例如，存储字符串&#39;abc&#39;，对于char (10)，表示你存储的字符将占10个字节(包括7个空字符)，而同样的varchar (10)则只占用3个字节的长度，10只是最大值，当你存储的字符小于10时，按实际长度存储） varchar 是可变长字符串，不会预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索 引效率 表必备三字段:id, date_create, date_update 为避免关连查询，字段允许适当冗余，以高查询性能，但必须考虑数据一致。冗余字段应遵循 不是频繁修改的字段 不是 varchar 超长字段，更不能是 text 字段 合适的字符存储长度，无负数的情况需要使用无符号位存储，扩大表示范围 类型 | 表示范围 — | — unsigned tinyint | 无符号位 0-255 unsigned smallint | 无符号位 0-65535 unsigned int | 无符号位 约 0-42.9亿 unsigned bigint | 无符号位 约 0-10的19次方 索引 在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引 索引建立需要遵循最左匹配原则。例如：建组合索引的时候，区分度最高的在最左边 SQL性能优化的目标：至少要达到range级别，要求是ref级别，如果可以是consts最好。 consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。 ref 指的是使用普通的索引（normal index） 。 range 对索引进行范围检索。 explain来解释执行计划，type列指的是MySQL在表中找到所需行的方式。常见类型如下： ALL | index | range |ref |eq_ref | const,system | NULL — | — | — | — | — | — | — ALL是全表扫描，MySQL要遍历全表来找到匹配的行 | 索引全扫描，MySQL遍历整个索引来找到匹配的行 | 索引范围扫描，一般用于&lt;、&gt;、&lt;=、&gt;=、between操作 | 使用非唯一索引扫描或者唯一索引的前缀扫描，返回匹配单独值的记录行 | 唯一索引，对于每个键值，表中只有一行记录与之匹配 | 单表只有一个匹配行，例如根据主键或者唯一索引记性的查询 范围列可以用到索引 范围条件有：&lt;、&lt;=、&gt;、&gt;=、between等。 范围列可以用到索引，但是范围列后面的列无法用到索引，索引最多用于一个范围列，如果查 询条件中有两个范围列则无法全用到索引。 例如 建有(a,b,c)联合索引 where b&gt;0 and a&lt;9 只有a索引会生效 where b&gt;0 and a=9 a,b 索引生效 where a&lt;0 and b=9 只有a索引生效 where c&lt;0 and b=9 不符合最左原则，索引不生效 分库分表 单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AVL树]]></title>
    <url>%2F2018%2F07%2F25%2FAVL%E6%A0%91%2F</url>
    <content type="text"><![CDATA[引言在介绍二叉平衡树之前，有必要先了解下二叉树，下面是基于维基百科对二叉树的解释 二叉树（英语：Binary tree）是每个节点最多只有两个分支（即不存在分支度大于2的节点）的树结构。通常分支被称作“左子树”或“右子树”。二叉树的分支具有左右次序，不能随意颠倒 二叉树的第i层至多拥有2^(i-1)个节点。深度为k的二叉树至多总共有2^(k+1) - 1个节点（定义根节点所在深度k0 = 0），而总计拥有节点数匹配的，称为满二叉树 深度为k有n个节点的二叉树，当且仅当其中的每一节点，都可以和同样深度k的满二叉树，序号为1到n的节点一对一对应时，称为完全二叉树 二叉查找树（英语：Binary Search Tree），也称为二叉搜索树、有序二叉树（ordered binary tree）或排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低，为O(log n)。但是，一旦这棵二叉查找树演化成了线型树的时候，此时查询的时间复杂度会降至O(n)。 虽然二叉查找树的最坏效率是O(n)，但是他有很多改进版的二叉查找树可以使树高为O(log n)，从而将最坏效率降至O(log n)。如AVL树、红黑树这两种都是平衡二叉树，本期我们写的就是AVL树。 什么是AVL树在计算机科学中，AVL树是最早被发明的自平衡二叉查找树。在AVL树中，任一节点对应的两棵子树的最大高度差为1（这个高度差就是下文要提到的平衡因子），因此它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是O(log n)。增加和删除元素的操作则可能需要借由一次或多次树旋转，以实现树的重新平衡。 平衡因子节点的平衡因子是它的左子树的高度减去它的右子树的高度（有时相反）。带有平衡因子1、0或 -1的节点被认为是平衡的。带有平衡因子-2或2的节点被认为是不平衡的，并需要重新平衡这个树。平衡因子可以直接存储在每个节点中，或从可能存储在节点中的子树高度计算出来 AVL 旋转进行旋转的原因因为AVL树需要维持节点的平衡因子为1，0，-1，固当插入新节点导致平衡因子不满足时需要进行调整以重新维持AVL树的平衡状态，这个调整过程就是旋转 旋转分类 实现简单描述在平衡的二叉排序树BBST (Balancing Binary Search Tree)上插入一个新的数据元素e的递归算法可描述如下： 若BBST为空树，则插入一个数据元素为e的新节点作为BBST的根节点，树的深度增1； 若e的关键字和BBST的根节点的关键字相等，则不进行； 若e的关键字小于BBST的根节点的关键字，而且在BBST的左子树中不存在和e有相同关键字的节点，则将e插入在BBST的左子树上，并且当插入之后的左子树深度增加（+1）时，分别就下列不同情况处理之： BBST的根节点的平衡因子为-1（右子树的深度大于左子树的深度，则将根节点的平衡因子更改为0，BBST的深度不变； BBST的根节点的平衡因子为0（左、右子树的深度相等）：则将根节点的平衡因子更改为1，BBST的深度增1； BBST的根节点的平衡因子为1（左子树的深度大于右子树的深度）：则若BBST的左子树根节点的平衡因子为1：则需进行单向右旋平衡处理，并且在右旋处理之后，将根节点和其右子树根节点的平衡因子更改为0，树的深度不变； 若e的关键字大于BBST的根节点的关键字，而且在BBST的右子树中不存在和e有相同关键字的节点，则将e插入在BBST的右子树上，并且当插入之后的右子树深度增加（+1）时，分别就不同情况处理之。 尾言本文介绍了AVL自平衡二叉树，所有操作的最坏复杂度都是的O(log n)。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 源码解析二（BeanFactory的创建）]]></title>
    <url>%2F2018%2F03%2F09%2FSpring-IOC-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BA%8C%EF%BC%88BeanFactory%E7%9A%84%E5%88%9B%E5%BB%BA%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言 在第二期介绍容器的refresh方法开始之前，首先大家应该对Spring容器的整个继承体系有个大概的了解，不然就会有雾里看花的感觉 为了帮助大家理清整个继承体系，我将接下来所要涉及到的几个重要类及接口的继承关系贴上来，在阅读中如有疑惑的话，可以回过头来看看这几张图 XmlWebApplicationContext由web容器启动的Spring容器类，注意与DefaultListableBeanFactory的区别 DefaultListableBeanFactory实际实现的bean工厂类，获取bean操作的方法都在这里 XmlBeanDefinitionReader读取我们配置文件信息 BeanFactory 接口及其实现由以上图中可以看出，BeanFactory 接口定义了IOC容器最基本的功能规范，是每一个IOC容器都要遵守的基本规范。其中最重要的就是定义了getBean方法，让我们可以从容器中根据名字拿到所需要的bean。 而DefaultListableBeanFactory就是其一个重要实现，与我们接触也是最多的，而XmlWebApplicationContext可以理解为一个更高级的IOC容器，除支持BeanFactory的基本功能外，还提供了很多扩展功能 容器 refresh 方法接着上节继续往下讲refresh 是整个容器启动的核心方法，在AbstractApplicationContext中，其做的事情主要有三个： BeanFactory的创建(DefaultListableBeanFactory) BeanDefinition的Resource定位，载入，和注册 在实例化Bean之前对BeanDefinition进行修改(调用实现了接口BeanFactoryPostProcessor，BeanDefinitionRegistryPostProcessor的类) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // 创建BeanFactory,并载入BeanDefinitions（重要） ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // 执行 BeanFactoryPostProcessors invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessors registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // 提前实例化化全部延迟加载的单例类型 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&apos;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; obtainFreshBeanFactory()obtainFreshBeanFactory() 也在 AbstractApplicationContext类中，主要逻辑在refreshBeanFactory 方法中 12345678protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory;&#125; refreshBeanFactory() (AbstractRefreshableApplicationContext)这里做的事情主要有2个： 1.创建BeanFactory (createBeanFactory())2.载入BeanDefinitions (loadBeanDefinitions(beanFactory)) 123456789101112131415161718protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125;&#125; createBeanFactory()从这里可以知道容器所使用的BeanFactory实现类是 DefaultListableBeanFactory123protected DefaultListableBeanFactory createBeanFactory() &#123; return new DefaultListableBeanFactory(getInternalParentBeanFactory());&#125; loadBeanDefinitions(beanFactory) (XmlWebApplicationContext)这个方法是在XmlWebApplicationContext实现的，Spring随处可见父类调用子类的设计模式（模板方法设计模式） 在解析loadBeanDefinitions方法之前，有必要先了解BeanDefinition在Spring中所表示的概念 （通俗的理解可以说是bean的抽象数据结构，它包括属性参数，构造器参数，以及其他具体的参数，就是我们从配置信息中读出来Bean的抽象数据结构）有兴趣的可以去看看BeanDefinition的数据结构。 123456789101112131415protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // 创建一个XmlBeanDefinitionReader，用来读取配置文件配置的Bean信息，解析成beanDefinition，并配置beanFactory 方便回调 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // 配置XmlBeanDefinitionReader的一些基本配置 beanDefinitionReader.setEnvironment(getEnvironment()); // 配置ResourceLoader（XmlWebApplicationContext 是实现了ResourceLoader接口的，不清楚的可以上图的继承链） beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // 这里没做任何事情 initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader);&#125; loadBeanDefinitions(XmlBeanDefinitionReader reader)XmlBeanDefinitionReader 根据配置文件位置调用 loadBeanDefinitions12345678protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException &#123; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; for (String configLocation : configLocations) &#123; reader.loadBeanDefinitions(configLocation); &#125; &#125;&#125; 尾言 到目前为止，我们知道了IOC容器的创建，以及BeanDefinition是在哪里被加载的。接下来要讲的自然就是配置信息是如何被解析加载的，以及如何注册进BeanFactory的。see =&gt; 下期]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 源码解析一（IOC容器的创建）]]></title>
    <url>%2F2018%2F02%2F28%2FSpring-IOC-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%80%EF%BC%88IOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9B%E5%BB%BA%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言 Spring源码值得每一个程序员去研读，不仅仅因为她是最常用的框架，更因为她所体现的编码思想 本文主要介绍web应用启动时Spring容器的创建过程 Spring 启动监听最终入口 123&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; ContextLoaderListener(org.springframework.web.context.ContextLoaderListener) 这里的contextInitialized 方法会在web容器启动时被调用，从而启动整个spring容器的创建1234@Overridepublic void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext());&#125; ContextLoader(org.springframework.web.context.ContextLoader)主要有 initWebApplicationContext，determineContextClass，createWebApplicationContext，configureAndRefreshWebApplicationContext 这四个方法的执行 initWebApplicationContext初始化过程入口（主要是创建容器的过程）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException( &quot;Cannot initialize context because there is already a root application context present - &quot; + &quot;check whether you have multiple ContextLoader* definitions in your web.xml!&quot;); &#125; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log(&quot;Initializing Spring root WebApplicationContext&quot;); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Root WebApplicationContext: initialization started&quot;); &#125; long startTime = System.currentTimeMillis(); try &#123; // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. if (this.context == null) &#123; this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Published root WebApplicationContext as ServletContext attribute with name [&quot; + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + &quot;]&quot;); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info(&quot;Root WebApplicationContext: initialization completed in &quot; + elapsedTime + &quot; ms&quot;); &#125; return this.context; &#125; catch (RuntimeException ex) &#123; logger.error(&quot;Context initialization failed&quot;, ex); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; logger.error(&quot;Context initialization failed&quot;, err); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125;&#125; createWebApplicationContext创建容器，需要知道我们默认创建的spring容器是哪个？ 在determineContextClass中获取123456789protected WebApplicationContext createWebApplicationContext(ServletContext sc) &#123; // 获取容器class对象 Class&lt;?&gt; contextClass = determineContextClass(sc); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException(&quot;Custom context class [&quot; + contextClass.getName() + &quot;] is not of type [&quot; + ConfigurableWebApplicationContext.class.getName() + &quot;]&quot;); &#125; return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; determineContextClass先尝试从servlet上下文获取容器类名，一般我们都不会去配。所以一般都在这里return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader());获取到实际的容器，这里实际上会去读取配置文件ContextLoader.properties，找到实际启动的容器类为org.springframework.web.context.support.XmlWebApplicationContext12345678910111213141516171819202122protected Class&lt;?&gt; determineContextClass(ServletContext servletContext) &#123; String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM); if (contextClassName != null) &#123; try &#123; return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( &quot;Failed to load custom context class [&quot; + contextClassName + &quot;]&quot;, ex); &#125; &#125; else &#123; contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName()); try &#123; return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( &quot;Failed to load default context class [&quot; + contextClassName + &quot;]&quot;, ex); &#125; &#125;&#125; configureAndRefreshWebApplicationContext看名字，顾名思义。这个方法是在容器创建完成之后，进行相关配置并初始化刷新容器。其中最重要的就是获取我们在web.xml中配置的Spring配置文件信息，然后执行 refresh 方法刷新容器123456789101112131415161718192021222324252627282930313233protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; // The application context id is still set to its original default value // -&gt; assign a more useful id based on available information String idParam = sc.getInitParameter(CONTEXT_ID_PARAM); if (idParam != null) &#123; wac.setId(idParam); &#125; else &#123; // Generate default id... wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); // 找到配置文件 我们在web.xml中配置的Spring配置文件位置 String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (configLocationParam != null) &#123; wac.setConfigLocation(configLocationParam); &#125; // The wac environment&apos;s #initPropertySources will be called in any case when the context // is refreshed; do it eagerly here to ensure servlet property sources are in place for // use in any post-processing or initialization that occurs below prior to #refresh ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(sc, null); &#125; customizeContext(sc, wac); wac.refresh();&#125; 尾言 到这里为止，我们知道了Spring 启动的容器类是 XmlWebApplicationContext，在下一节我们会着重解析容器的 refresh 方法，这个方法是整个spring ioc容器的精髓所在]]></content>
      <categories>
        <category>java框架</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析计算机字符集和编码]]></title>
    <url>%2F2017%2F09%2F14%2F%E6%B5%85%E6%9E%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%97%E7%AC%A6%E9%9B%86%E5%92%8C%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[什么是字符集呢？我们知道，在计算机内部，所有信息都是二进制表示的，二进制对于计算机来说是极为重要的，可以想象成一个开关的闭开信号，只有 0 1两种状态。计算机中 8个二进制（8位）代表一个字节，也就是说一个字节可以代表256种可能，于是上个世纪60年代，美国制定了一套字符集，对英语字符与二进制位之间的关系，做了统一规定。这被称为ASCII码，一直沿用至今，ASCII码一共规定了128个字符的编码，比如空格”SPACE”是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。 英语用128个字符就够了，但是世界上还有各种各样的语言字符，如中文，就有上万个。这样子，即使是256个也不够用，而且也无法统一。比如，一个二进制数可能会对应着各个国家不同的符号，这样子我们打开一个文件，如果不知道这个文件的编码方式，那就会乱码，完全看不懂。 这样子，Unicode 字符集就出现了，它将世界上所有的字符都纳入其中了，在unicode字符集中，每一个符号都对应着一个独一无二的编码,如4E25表示汉字严 Unicode的问题需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。比如，汉字严的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。这里就有两个严重的问题： 第一个问题是，如何才能区别Unicode和ASCII？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？ 第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果Unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。 它们造成的结果是： 出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。 Unicode在很长一段时间内无法推广，直到互联网的出现。 编码和字符集的区别如上文所说，符号集只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储，而编码则可以说是指定字符集的具体实现方式，如 UTF-8，UTF-16就是Unicode字符集的实现方式 UTF-8互联网的普及，强烈要求出现一种统一的编码方式。UTF-8就是在互联网上使用最广的一种Unicode的实现方式。其他实现方式还包括UTF-16（字符用两个字节或四个字节表示）和UTF-32（字符用四个字节表示），不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。UTF-8的编码规则很简单，只有二条： 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。 对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。 下表总结了编码规则，字母x表示可用编码的位。 Unicode符号范围(十六进制) UTF-8编码方式（二进制） 0000 0000-0000 007F 0xxxxxxx 0000 0080-0000 07FF 110xxxxx 10xxxxxx 0000 0800-0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx 0001 0000-0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 跟据上表，解读UTF-8编码非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。下面，还是以汉字严为例，演示如何实现UTF-8编码。已知严的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此严的UTF-8编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，严的UTF-8编码是11100100 10111000 10100101，转换成十六进制就是E4B8A5。 Little endian和Big endianUnicode码可以采用两个字节格式直接存储。以汉字严为例，Unicode码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25。存储的时候，4E在前，25在后，就是Big endian方式；25在前，4E在后，就是Little endian方式。因此，第一个字节在前，就是&quot;大头方式&quot;（Big endian），第二个字节在前就是&quot;小头方式&quot;（Little endian）。那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？Unicode规范中定义，每一个文件的最前面分别加入一个表示编码顺序的字符（BOM头），这个字符的名字叫做”零宽度非换行空格”（ZERO WIDTH NO-BREAK SPACE），用FEFF表示。这正好是两个字节，而且FF比FE大1。如果一个文本文件的头两个字节是FE FF，就表示该文件采用大头方式；如果头两个字节是FF FE，就表示该文件采用小头方式。]]></content>
      <categories>
        <category>java基础</category>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS 单点登录原理解析]]></title>
    <url>%2F2017%2F05%2F19%2FCAS-%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[引言CAS是耶鲁大学发起的一个开源单点登录项目，也是用的最为广泛的开源项目。对于学习SSO有非常好的参考价值 什么是单点登录单点登录（Single Sign On），简称为 SSO。多用于多系统共存的环境下，用户在一处登录后，就不用在其他系统中登录，最简单的单点登入实现可以完全基于cookie，通过往浏览器写带有登入信息的token来达到多点登入的目的，有兴趣的可以自己动手实现一个 CAS单点登入的实现先盗个图 ： 从结构上看，分成了三部分：CAS Client，CAS Server，浏览器 CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护 Web 应用的受保护资源，过滤从客户端过来的每一个Web请求 下面我将分为两部分（用户第一次登录验证和之后的登录验证）详细解析其登入原理 用户第一次登录过程原理 CAS Client 会先根据JSESSIONID（存在浏览器cookie中） 来判断当前访问用户是否已经登录，如果没有JSESSIONID 会继续分析 HTTP 请求中是否包含请求 Service Ticket( ST 上图中的 Ticket) ，如果没有，则说明该用户是没有经过认证的；于是 CAS Client 会重定向用户请求到 CAS Server ，并传递 Service （要访问的目的资源地址） 这时还没有登录过CAS Server，进入用户认证过程（返回登入界面） 如果用户认证成功，CAS Server 将随机产生一个相当长度、唯一、不可伪造的 Service Ticket ，并缓存以待将来验证，并且重定向用户到 Service 所在地址（附带刚才产生的 Service Ticket ） , 并为客户端浏览器设置一个Ticket Granted Cookie（ TGC，该Cookie设置的是SSO Server的域名） CAS Client 在拿到 Service 和新产生的 Ticket 过后，与 CAS Server 通过拿到的Ticket进行身份核实，以确保 Service Ticket 的合法性。 以上是第一次验证时基本流程 当第二次验证时分两种情况 同一个服务再次登录这里浏览器cookie中会有 sessionid，凭借这个sessionid就不再需要去CAS Server 继续认证 另外一个未登录过的服务登录在上面步骤中的第二歩，因为之前已经在CAS Server 登录成功过，CAS Server 会读取浏览器中的 TGC （cookie），表明已经登入过，就不需要去返回登录界面了，直接返回CAS Client 一个唯一 票据（ticket），并进入第三歩。这样就实现了单点登录，多点无需再次手动登录 关于跨域的实现跨域的关键在于浏览器端的Cookie:TGC，因为这个Cookie是设置在SSO Server端的，也就保证了统一票据和Client端域名无关。 总结cas 单点登录核心就是 单个cookie， N个session 单个cookie（TGC）在cas为各应用登录时使用，实现了只须一次录入用户密码，此cookie只于cas server相关，这也是cas可以实现跨域的关键 N个session各应用会创建自己的session表示是否登录，如已登录，就不会去CAS Server 去验证TGC 在该协议中，所有与 CAS Server 的交互均采用 SSL 协议，以确保 ST 和 TGC 的安全性。]]></content>
      <categories>
        <category>第三方框架</category>
        <category>SSO</category>
      </categories>
      <tags>
        <tag>SSO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于xml文件 xsi:schemaLocation]]></title>
    <url>%2F2017%2F05%2F09%2F%E5%85%B3%E4%BA%8Exml%E6%96%87%E4%BB%B6-xsi-schemaLocation%2F</url>
    <content type="text"><![CDATA[相信很多人对xml 头上一大堆得东西都是拿来主义，copy过来就行了，并不理解那是什么意思 先来一段1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.pikaq&quot;/&gt; &lt;bean id=&quot;xxx&quot; class=&quot;xxx.xxx.xxx.Xxx&quot;&gt; &lt;property name=&quot;xxx&quot; value=&quot;xxxx&quot;/&gt;&lt;/bean&gt;&lt;/beans&gt; 首先看到的就是 xmlns， xmlnsXML 是Namespace的缩写，可译为“XML命名空间” 为什么需要xmlns？因为xml文件有成千上万，谁也不能保证你的标签是独一无二的，总是会冲突的，这时就需要xmlns了！ 怎么使用xmlns 呢？使用语法： xmlns:namespace-prefix=&quot;namespaceURI&quot;。其中namespace-prefix为自定义前缀，只要在这个XML文档中保证前缀不重复即可；namespaceURI是这个前缀对应的XML Namespace的定义。例如： xmlns:context=”http://www.springframework.org/schema/context&quot; 这里的元素就来自别名为context的XML Namespace，也就是在http://www.springframework.org/schema/context中定义的。其实我们完全可以将前缀定义为abc： xmlns:abc=”http://www.springframework.org/schema/context&quot; 好了，看到这里，你也许会问 那 xmlns 和xmlns:context 有什么区别呢？ xmlns 没有带别名，就是表示那是默认的，如 这里的bean 属性就出自这个默认命名空间 xsi:schemaLocation 是干嘛的？看到这里也许你已经知道了它是干嘛的了schemaLocation不就是 xsi 命名空间的一个属性吗，如果之前我们把xmlns:xsi=”http://www.w3.org/2001/XMLSchema-instance&quot; 的别名改成xmlns:sb=”http://www.w3.org/2001/XMLSchema-instance&quot; 这里其实就变成 sb:schemaLocation，这里讲一下这个属性是干嘛的，这个属性的值由一个或多个URI引用对组成，两个URI之间以空白符分隔（空格和换行均可）它定义了XML Namespace和对应的 XSD（Xml Schema Definition）文档的位置的关系，意思就是 这个命名空间对应的具体模板是哪个 例如我们打开 http://www.springframework.org/schema/mvc/ 这个 命名空间，可以看到有很多选择xsi:schemaLocation 这个属性就是跟他说我要选择哪一个]]></content>
      <categories>
        <category>基础</category>
        <category>xml</category>
      </categories>
      <tags>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全面解析JS面向对象 原型链]]></title>
    <url>%2F2017%2F05%2F04%2F%E5%85%A8%E9%9D%A2%E8%A7%A3%E6%9E%90JS%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E5%8E%9F%E5%9E%8B%E9%93%BE%2F</url>
    <content type="text"><![CDATA[对javascript 这门语言来说，相信大家都不会陌生，但最近发现其实好多人对JS对象的概念很模糊，甚至会惊异于JS竟然也有对象 其实JS是完全基于对象的语言，我们所能看到的都是基于对象，包括 js 方法其实也是一个对象 但是js的面向对象与像java的面向对象相比,又是有着极大的不同，java，C#完全面向对象的语言 中有类这个概念，而js对象则是依靠 构造器constructor利用 原型prototype构造出来的。 简单的理解下，类的概念相当于 模板，原型相当于 各个对象组成新的对象 先来总结一下创建对象的3种方式 创建对象的三种方式：1.通过JSON符号创建1234567var dog = &#123; name: 'singledog', wangwang: function()&#123; console.log(this.name+"旺旺！"); &#125; &#125;; dog.wangwang();// singledog旺旺！ 2.通过new 关键字创建12345678function Dog(name)&#123; this.name = name; &#125;; Dog.prototype.wangwang = function() &#123; console.log(this.name+"wangwang!!"); &#125;; var dog = new Dog("SingleDog:"); dog.wangwang();//SingleDog:wangwang!! 3.通过 ES5新引进的 Object.create() 方法创建 12345678var dog = &#123; name: 'singledog', wangwang: function()&#123; console.log(this.name+"旺旺！"); &#125; &#125;; var jDog = Object.create(dog);//创建一个新的对象 jDog 并继承 dog 对象 jDog.wangwang();//singledog旺旺！ 原型（prototype）prototype（原型）是js面向对象中非常重要的一个概念，是深入学习js是必须要理解的一个概念每个方法 都有一个prototype属性，我们可以利用这个属性来大做文章之前介绍了，我们生成一个需要用到 new 关键字，那么这个new 关键字与JAVA中的new一样吗？ 答案是完全不一样 可以看一个例子：12345678910111213function Car(name)&#123; this.name = name &#125;; Car.prototype = &#123;//指定 Car的原型 对象 driver: function()&#123; console.log(this.name+" driver!!"); &#125; &#125;; var obj = new Object(); obj.__proto__ = Car.prototype; Car.call(obj,"Benz"); obj.driver(); //Benz driver!! 在上面的代码中，我们发现 var car = new Car();这句被我们替换成了这三句： 123var obj = new Object(); obj.__proto__ = Car.prototype; Car.call(obj,"Benz"); 以上代码中，我们先新建了一个空的Object对象 obj，然后将Car的原型赋给了 obj对象的__proto__，这样子obj对象就继承了Car的原型对象，最后一步，在obj对象上执行构造方法Car，这样子 obj 对象就相当于拿来了 Car方法中 全部this. 属性或方法 这三步其实等于new 操作 基于原型，我们可以实现原型链的继承，因为每一个 prototype 都是一个对象，每个对象都隐式的拥用一个 prototype 引用 __proto__ 属性，这样子当调用一个对象的方法的时候，就会顺着__proto__属性一层一层往上找，直到找到为止。 说起来似乎很难理解，看个例子帮助大家理解：1234567891011121314151617181920212223242526272829303132333435function Car()&#123; &#125;; Car.prototype = &#123;//指定 Car的原型 对象 name : 'car', driver: function()&#123; console.log(this.name+" driver!!"); &#125; &#125;; function QqCar()&#123; this.name = 'QQ' &#125;; QqCar.prototype = new Car(); //指定 QqCar的原型为 new Car() var qqCar = new QqCar();//继承了driver 方法 qqCar.driver(); // QQ driver!! function BigQqCar()&#123; this.name = 'BigQQ' &#125;; BigQqCar.prototype = qqCar; //指定 BigQQCar的原型为 qqCar var bigQqCar = new BigQqCar(); bigQqCar.driver = function()&#123;//重写了driver方法 console.log(this.name+" flying!!"); &#125;; bigQqCar.driver();//BigQQ flying!! console.log(bigQqCar.__proto__===BigQqCar.prototype); //true console.log(BigQqCar.prototype === qqCar); //true console.log(BigQqCar.prototype.__proto__ === QqCar.prototype); //true // 以上代码就是一个简单的原型链,每个构造方法生成的对象都有一个 __proto__ 指向 其构造方法的prototype 属性 以上也只是个人对JS面向对象的理解，欢迎留言补充]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React + ES6 + webpack 快速搭建开发环境]]></title>
    <url>%2F2017%2F02%2F27%2FReact-ES6-webpack-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[近期，由用到了react.js来写前端代码，搭建开发环境对于从来没有写过react的同学来说有点复杂，这里简单记录一下搭建过程（本人也是前端渣渣，写错的地方还望大家指出） 安装webpack 需要Node 环境 全局安装 cnpm install -g webpack 本项目安装 cnpm install webpack –save-dev 安装 react + es6 loaders cnpm install –save-dev babel-core babel-loader babel-preset-es2015 babel-preset-react 还有css loader cnpm install css-loader style-loader –save-dev 配置webpack.config.js 文件123456789101112131415161718192021222324var path = require(&apos;path&apos;);module.exports = &#123; entry: &apos;./app/src/main.jsx&apos;, output: &#123; path: path.resolve(__dirname, &apos;./app/web&apos;), // 输出文件的保存路径 filename: &apos;bundle.js&apos; // 输出文件的名称 &#125;, module: &#123; loaders: [&#123; test: /\\.jsx?$/, loaders: &apos;babel-loader&apos;, query: &#123; presets: [&apos;react&apos;, &apos;es2015&apos;] &#125; &#125;, &#123; test: /\\.css$/, loader: &apos;style-loader!css-loader&apos; &#125; ]&#125;&#125;; 到这里基本开发环境搭建好了 安装react 和react-dom cnpm i react-dom –savecnpm i react –save 安装完之后会发现package.json下多了这两个依赖项 在app/src 下新建一个main.jsx入口文件，简单写下内容 1234567import React from &apos;react&apos;;import ReactDOM from &apos;react-dom&apos;;ReactDOM.render( &lt;h1&gt;Hello, world!&lt;/h1&gt;, document.getElementById(&apos;example&apos;)); 然后在app/web下新建index.html ，里面需要引用bundle.js文件 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;webpack 教程&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;example&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=&quot;bundle.js&quot;&gt;&lt;/script&gt;&lt;/html&gt; 完成搭建执行命令 webpack 执行成功，发现在app/web 目录下多了个bundle.js文件 在浏览器打开index.html 文件。正确显示hello world! cnpm install 【name】–save-dev 与 cnpm install 【name】–save的区别，都是安装一些模块，唯一的区别是加有dev的是在开发时所依赖的模块，而不加的是运行时需要的基本模块。 那么怎么实时调试呢？ cnpm install –save-dev webpack-dev-server react-hot-loaderwebpack.config.js 的内容更新如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152var path = require(&apos;path&apos;);var webpack = require(&apos;webpack&apos;);module.exports = &#123; entry: &#123; index: [ &apos;./app/src/main.jsx&apos; ] &#125;, output: &#123; path: path.resolve(__dirname, &apos;./app/web&apos;), // 输出文件的保存路径 filename: &apos;bundle.js&apos; // 输出文件的名称 &#125;, module: &#123; loaders: [&#123; test: /\\.jsx?$/, loaders: &apos;babel-loader&apos;, query: &#123; presets: [&apos;react&apos;, &apos;es2015&apos;] &#125; &#125;, &#123; test: /\\.css$/, loader: &apos;style-loader!css-loader&apos; &#125;, &#123; test: /\\.js?$/, loaders: [&apos;react-hot&apos;], include: [path.join(__dirname, &apos;app/src&apos;)] &#125; ] &#125;, plugins: [ new webpack.HotModuleReplacementPlugin(), new webpack.NoErrorsPlugin(), new webpack.LoaderOptionsPlugin(&#123; options: &#123; postcss: function () &#123; return [precss, autoprefixer]; &#125;, devServer: &#123; historyApiFallback:true, hot:true, inline:true, progress:true &#125; &#125; &#125;)]&#125;; package.json 文件需要添加以下 执行 npm run dev 访问 localhost:8080 即可 写的很粗浅 惭愧，以后有时间会重新研究一下前端的构建及打包]]></content>
      <categories>
        <category>前端技术</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven的生命周期及插件绑定]]></title>
    <url>%2F2016%2F12%2F21%2FMaven%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%8F%8A%E6%8F%92%E4%BB%B6%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[######何为生命周期？ 一个完整的项目构建过程通常包括清理、编译、测试、打包、集成测试、验证、部署等步骤，Maven从中抽取了一套完善的、易扩展的生命周期。Maven的生命周期是抽象的，其中的具体任务都交由插件来完成。Maven为大多数构建任务编写并绑定了默认的插件，如针对编译的插件：maven-compiler-plugin。用户也可自行配置或编写插件。 Maven的生命周期是抽象的，意味着生命周期本身不做任何实际工作，在Maven的设计中，实际的工作都交由插件来完成 Maven定义了三套生命周期：clean、default、site，每个生命周期都包含了一些阶段（phase）。三套生命周期相互独立，但各个生命周期中的phase却是有顺序的，且后面的phase依赖于前面的phase。执行某个phase时，其前面的phase会依顺序执行，但不会触发另外两套生命周期中的任何phase。 1 . 1 clean生命周期 1 . 2 default生命周期 1 . 3 site生命周期 ######（阶段）phase （目标）goalPhase 之前说过，指的就是生命周期的各个阶段Goal 指便是 插件的目标（通俗的说就是插件所具有的功能） ######自定义插件配置]]></content>
      <categories>
        <category>构建工具</category>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 学习总结]]></title>
    <url>%2F2016%2F12%2F20%2FMaven-%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[#Maven 简介Maven是什么？ Maven 这个词可以翻译为“知识的积累”，也可以翻译为“专家”或“内涵”。本文将介绍maven这一跨平台的项目管理使用工具。做为apache组织中一个颇为成功的开源项目，maven主要服务于基于java平台的项目构建，依赖管理和项目信息管理，无论是小型的开源类库项目，还是大型的企业级应用；无论是传统的瀑布式开发，还是流行的敏捷模式，Maven都能大显身手 – maven实战 #何为构建除了编写源代码，我们每天有相当一部分时间花在了编译、运行单元测试、生成文档、打包和部署等烦琐且不起眼的工作上，这就是构建如果我们现在还手工这样做，那成本也太高了，于是有人用软件的方法让这一系列工作完全自动化，使得软件的构建可以像全自动流水线一样，只需要一条简单的命令，所有烦琐的步骤都能够自动完成，很快就能得到最终结果 #maven不仅仅是构建工具依赖管理 #与ant的区别我看到很多项目的ant脚本中的命名基本上都是一致的，比如：编译一般叫build或者compile；打包一般叫jar或war；生成文档一般命名为 javadoc或javadocs；但其实最常用的就2，3个：比如javac javadoc jar等。 这是因为Ant所提供的可重用的task粒度太小，虽然灵活性很强，但是我们需要纠缠很多细节的东西ANT是没有依赖管理的，而对于Maven用户来说，依赖管理是理所当然的，Maven不仅内置了依赖管理，更有一个可能拥有全世界最多Java开源软件包的中央仓库，Maven用户无须进行任何配置就可以直接享用。 ##Maven的优点： 1.拥有约定，知道你的代码在哪里，放到哪里去2.拥有一个生命周期，例如执行 mvn install就可以自动执行编译，测试，打包等构建过程3.只需要定义一个pom.xml,然后把源码放到默认的目录，Maven帮你处理其他事情4.拥有依赖管理，仓库管理 #Maven 的安装配置 首先官网下载 http://maven.apache.org/download.cgi 说明需要JDK 1.7及以上，这里我们使用JDK1.8 这里我下载的是maven 3.3.9 1.将安装文件解压到指定的目录中，如： D:\maven\apache-maven-3.3.9 2.设置环境变量 将D:\maven\apache-maven-3.3.9\bin 设进环境变量中 打开cmd 执行 mvn -v 注意事项 设置MAVEN_OPTS环境变量，通常需要设置MAVEN_OPTS的值为-Xms128m-Xmx512m，因为Java默认的最大可用内存往往不能够满足Maven运行的需要，比如在项目较大时，使用Maven生成项目站点需要占用大量的内存，如果没有该配置，则很容易得到java.lang.OutOfMemeoryError。因此，一开始就配置该变量是推荐的做法。 #maven使用入门一、编写pom文件就像Make的Makefile、Ant的build.xml一样，Maven项目的核心是pom.xml。POM（Project Object Model，项目对象模型）定义了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。现在先为Hello World项目编写一个最简单的pom.xml。 12345678910&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.pikaq&lt;/groupId&gt; &lt;artifactId&gt;maventest&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;maventest&lt;/name&gt;&lt;/project&gt; 这段代码中最重要的是包含groupId、artifactId和version的三行。这三个元素定义了一个项目基本的坐标，在Maven的世界，任何的jar、pom或者war都是以基于这些基本的坐标进行区分的。groupId定义了项目属于哪个组，这个组往往和项目所在的组织或公司存在关联。譬如在googlecode上建立了一个名为myapp的项目，那么groupId就应该是com.googlecode.myapp，如果你的公司是mycom，有一个项目为myapp，那么groupId就应该是com.mycom.myapp。本书中所有的代码都基于groupId com.juvenxu.mvnbook。本书其他章节代码会分配其他的artifactId。而在前面的groupId为com.googlecode.myapp的例子中，你可能会为不同的子项目（模块）分配artifactId，如myapp-util、myapp-domain、myapp-web等顾名思义，version指定了Hello World项目当前的版本——1.0-SNAPSHOT。SNAPSHOT意为快照，说明该项目还处于开发中，是不稳定的版本。随着项目的发展，version会不断更新，如升级为1.0、1.1-SNAPSHOT、1.1、2.0等。6.5节会详细介绍SNAPSHOT，第13章会介绍如何使用Maven管理项目版本的升级发布。最后一个name元素声明了一个对于用户更为友好的项目名称，虽然这不是必须的，但还是推荐为每个POM声明name，以方便信息交流。 ##编写主代码 123456789101112package com.pikaq.maventest;public class Helloworld&#123; public String sayHello()&#123; return &quot;hello&quot;; &#125; public static void main(String [] args)&#123; System.out.println(new Helloworld().sayHello()); &#125; &#125; 这里需要注意，在大多数情况下，我们应该遵循maven约定把代码放在src/main/java 目录下，无需其他配置，maven就会自动去搜寻主代码，代码编写完之后，使用 mvn clean compile 编译 ##编写测试代码 和编写主代码类似，测试代码的目录对应的应该在 src/test/java 下，因此应该先创建目录，修改项目 pom 文件，增加Junit依赖 1234567891011121314151617181920&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.pikaq&lt;/groupId&gt; &lt;artifactId&gt;maventest&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;maventest&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.7&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 编写测试类 1234567891011121314package com.pikaq.maventest;import static org.junit.Assert.assertEquals;import org.junit.Test;public class HelloworldTest&#123; @Test public void testSayHello()&#123; Helloworld h = new Helloworld(); String result = h.sayHello(); assertEquals(&quot;hello&quot;,result); &#125; &#125; 运行 mvn clean test #打包和运行 mvn clean package maven 在打包之前执行了编译和测试操作 但是如何让其他maven 项目引用这个jar包呢： mvn clean install 通过执行install 命令将jar 安装到了本地仓库中 #使用Archetype 生成项目骨架 前面我们只是为了我们进一步熟悉maven，真正用的时候我们当然不会这么复杂，一个一个目录的去创建，这显然是重复劳动！我们只需要一个简单的命令就能生成我们约定好的项目骨架！ mvn archetype:generate 注意这里极有可能会卡主，因为这个命令会默认去远程请求所有的骨架 所以我们这里可以选择 &gt;mvn archetype:generate -DarchetypeCatalog=internal 这个命令执行只会列出常用的10个我们只需要按照提示选择一个即可，并依次输入groupID等 提示创建成功，我们发现已经生成了一个maven项目，是不是非常简单！ ####maven 的依赖管理问题 maven会自动选择路径最短的]]></content>
      <categories>
        <category>构建工具</category>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 使用补码运算的前世今生]]></title>
    <url>%2F2016%2F10%2F20%2Fjava-%E4%BD%BF%E7%94%A8%E8%A1%A5%E7%A0%81%E8%BF%90%E7%AE%97%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%2F</url>
    <content type="text"><![CDATA[前世今生众所周知，java是使用补码来表示数字的（不包括字符型），数字的运算也是以补码形式进行的，那么为什么要用补码表示呢？要了解补码，我们首先要知道计算机可以用原码 反码 补码这三种编码方式表示一个数先来看看我们是如何定义这三种编码的 正数的原码 反码 补码都是一样的 负数的反码是除了符号位其他取反，补码是在反码上加1 所以对于正数三码合一没啥可说的，这里主要来聊一下负数，因为计算机在进行计算的时候，并不会像人脑一样识别原码的第一位为符号位，进而会去根据符号位对真值进行加或减。所以我们要让计算机的运算变的尽可能的简单，比如两个数相减我们可以看成是加上一个负数，并且让符号位也参与运算 原码的减法 1210 + (-9) = 0000 1010(原) + 1000 1001(原) = 1001 0011(原) = -19// 正解应该是 1， -19显然是错误的 例子中正解应该是 1， -19显然是错误的。这就引申出了反码，负数的反码是除了符号位，其他位取反 反码的减法 12310 + (-9) = 0000 1010(原) + 1000 1001(原) = 0000 1010(反) + 1111 0110(反) = 0000 0001(反) = 0000 0001(原)// 结果是正确的 = 1 看似反码貌似解决了符号位参与运算的问题，其实不然，让我们再看一个特殊的例子 1231 + (-1) = 0000 0001(原) + 1000 0001(原) = 0000 0001(反) + 1111 1110(反) = 1111 1111(反) = 1000 0000(原) = -0// ps: 反码相加符号位参与运算，且若最高位相加后产生进位，最后得到的结果要加1// 结果看似是正确的，但是显然不符合我们的预期，0 和 -0 应该是一个数字 于是补码就这样出现了 补码的减法 1231 + (-1) = 0000 0001(原) + 1000 0001(原) = 0000 0001(反) + 1111 1110(反) = 0000 0001(补) + 1111 1111(补) = 0000 0000(原) = 0// ps: 补码运算最高位进位会舍去// 结果完全正确 且 -0 不存在了 还有一点需要注意的是 1000 0000(补) 并没有相应的原码和反码，仅用来表示 -128 最后再附张幼儿班常用数字进制表 &lt;(￣▽￣)/ 2进制 10 进制 16 进制 0000 0001 1 0x1 0000 0010 2 0x2 0000 0011 3 0x3 0000 0100 4 0x4 0000 0101 5 0x5 0000 0110 6 0x6 0000 0111 7 0x7 0000 1000 8 0x8 0000 1001 9 0x9 0000 1010 10 0xa 0000 1011 11 0xb 0000 1100 12 0xc 0000 1101 13 0xd 0000 1110 14 0xe 0000 1111 15 0xf 0001 0000 16 0x10 0001 0100 20 0x14 0001 1110 20 0x1e 0100 0000 64 0x40 0111 1111 127 0x7f 1111 1111 255 0xff]]></content>
      <categories>
        <category>java基础</category>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
        <tag>补码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS 绝对定位 ,浮动,清除浮动]]></title>
    <url>%2F2016%2F09%2F21%2FCSS-%E7%BB%9D%E5%AF%B9%E5%AE%9A%E4%BD%8D-%E6%B5%AE%E5%8A%A8-%E6%B8%85%E9%99%A4%E6%B5%AE%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[首先：我们需要知道div元素（块级元素）独占一行12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;1&quot; style=&quot;background:red;height:200px;padding:5px;position:relative&quot;&gt; &lt;div id=&quot;2&quot; style=&quot;background:green;height:50px;&quot;&gt;box1&lt;/div&gt; &lt;!-- div元素独占一行 --&gt; &lt;div id=&quot;3&quot; style=&quot;background:pink;height:50px;&quot;&gt;box2&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 如下图所示，box1和box2独占一行，可见如果每个div都独占一行，我们根本无法进行布局，所以我们就需要绝对定位和浮动来帮助我们布局！ 绝对定位的参照关系绝对定位会以最近的设置了position属性的父级为参照物进行定位，如下图box2就以id为1 的div为父级参照进行定位 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;0&quot; style=&quot;background:blue;padding:20px&quot;&gt;&lt;div id=&quot;1&quot; style=&quot;background:red;height:200px;padding:5px;position:relative&quot;&gt; &lt;div id=&quot;2&quot; style=&quot;background:black;width:50px;height:50px;&quot;&gt;box1&lt;/div&gt; &lt;!-- 绝对定位的父级参照物是最近的设置了position的值的父级元素，这里为 参照物为1 --&gt; &lt;div id=&quot;3&quot; style=&quot;background:pink;width:50px;height:50px;position:absolute;left:50px;top:0px&quot;&gt;box2&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 浮动 无论多么复杂的布局，其基本出发点均是：如何在一行显示多个div元素。显然标准流已经无法满足需求，这就要用到浮动。浮动可以理解为让某个div元素脱离标准流，漂浮在标准流之上，和标准流不是一个层次。 正常的div布局应该是像下图一样的 123456789&lt;body&gt;&lt;div id=&quot;1&quot; style=&quot;background:gray;height:500px;margin-top:5px&quot;&gt; &lt;div id=&quot;5&quot; style=&quot;background:blue;width:100px;height:50px;&quot;&gt;box1&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:yellow;width:60px;height:50px&quot;&gt;box2&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:green;width:70px;height:70px;&quot;&gt;box3&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:yellow;width:200px;height:50px;&quot;&gt;box4&lt;/div&gt;&lt;/div&gt;&lt;/body&gt; 假如我们将box2设置浮动 style中加上属性 float:left 向左浮动我们可以发现如下图的样子 其中box2漂浮在了box3上面，从而覆盖了一部分的box3，从而我们可以知道浮动的元素是脱离了标准流的！ 之后我们将box3也设置为向左浮动，可以发现box3和box2并排了，并排在box2之后，而且box2和box3都漂浮在box4之上 123456&lt;div id=&quot;1&quot; style=&quot;background:gray;height:500px;margin-top:5px&quot;&gt; &lt;div id=&quot;5&quot; style=&quot;background:blue;width:100px;height:50px;&quot;&gt;box1&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:yellow;width:60px;height:50px;float:left&quot;&gt;box2&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:green;width:70px;height:70px;float:left&quot;&gt;box3&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:pink;width:200px;height:90px;&quot;&gt;box4&lt;/div&gt;&lt;/div&gt; clear 清除浮动清除浮动的关键字clear : none | left | right | both什么时候需要清除浮动呢？ 以上面的例子 ，如果我们希望box4不被这些漂浮的元素所覆盖，需要怎么做呢？这时候就需要清除浮动了 clear了只需要在box4 添加CSS属性 clear:left ,就可以清除其左边的浮动元素影响，不被他们所覆盖 123456&lt;div id=&quot;1&quot; style=&quot;background:gray;height:500px;margin-top:5px&quot;&gt; &lt;div id=&quot;5&quot; style=&quot;background:blue;width:100px;height:50px;&quot;&gt;box1&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:yellow;width:60px;height:50px;float:left&quot;&gt;box2&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:green;width:70px;height:70px;float:left&quot;&gt;box3&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:pink;width:200px;height:90px;clear:left&quot;&gt;box4&lt;/div&gt;&lt;/div&gt; 还有当我们浮动的元素不希望跟在其他浮动元素之后时，也可以使用clear 属性来另起一行 12345&lt;div id=&quot;1&quot; style=&quot;background:gray;height:500px;margin-top:5px&quot;&gt; &lt;div id=&quot;5&quot; style=&quot;background:blue;width:100px;height:50px;&quot;&gt;box1&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:yellow;width:60px;height:50px;float:left&quot;&gt;box2&lt;/div&gt; &lt;div id=&quot;5&quot; style=&quot;background:green;width:70px;height:70px;float:left;clear:left&quot;&gt;box3&lt;/div&gt;&lt;/div&gt;]]></content>
      <categories>
        <category>前端技术</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
</search>
